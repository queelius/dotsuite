{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the Dot Notation Universe \u00b6 The dotsuite ecosystem provides a comprehensive, pedagogically-designed suite of tools for manipulating nested data structures using dot notation. Project Status: v0.9-beta \u00b6 \u2705 Feature Complete : All 15 core tools implemented across 4 pillars \u2705 Comprehensive Testing : 367 tests passing with 100% coverage \u2705 Type Hints : Full type annotations for IDE support \u2705 CLI Support : All tools accessible from command line \u2705 DSL Parser : Human-friendly query syntax for dotquery Quick Overview \u00b6 The ecosystem is organized around three fundamental pillars plus collections: \ud83c\udfaf Depth Pillar : Finding and extracting data ( dotget , dotstar , dotselect , dotpath ) \u2705 Truth Pillar : Boolean logic and validation ( dotexists , dotequals , dotany , dotall , dotquery ) \ud83d\udd04 Shape Pillar : Data transformation ( dotmod , dotbatch , dotpipe , dotpluck ) \ud83d\udcda Collections : Relational operations ( dotfilter , dotrelate ) Get Started \u00b6 Getting Started - Installation and first steps Philosophy - Design principles and motivation Ecosystem Overview - Complete tool reference Why dotsuite? \u00b6 Pedagogical Design : Learn data manipulation concepts through clear, focused tools Composability : Unix philosophy - each tool does one thing well Mathematical Foundation : Built on solid theoretical principles Safe by Default : Immutable operations, graceful handling of missing data Progressive Enhancement : Start simple, add complexity as needed Example \u00b6 from depth.dotget import get from truth.dotquery import Query from collections.dotfilter import dotfilter data = [ { \"user\" : { \"name\" : \"Alice\" , \"age\" : 30 , \"role\" : \"admin\" }}, { \"user\" : { \"name\" : \"Bob\" , \"age\" : 25 , \"role\" : \"user\" }} ] # Filter admins over 25 admins = dotfilter ( data , Query ( \"(user.role equals admin) and (user.age greater 25)\" )) # Extract names names = [ get ( doc , \"user.name\" ) for doc in admins ] # [\"Alice\"] Related Projects \u00b6 jsonl-algebra - Production-ready relational operations for JSONL JAF - JSON Array Filter with advanced capabilities Contributing \u00b6 We welcome contributions! See our GitHub repository for: - Source code - Issue tracking - Development guidelines - Test suite (367 tests!) \"What started as a single, humble function evolved into a complete, coherent ecosystem for manipulating data structures.\"","title":"Home"},{"location":"#welcome-to-the-dot-notation-universe","text":"The dotsuite ecosystem provides a comprehensive, pedagogically-designed suite of tools for manipulating nested data structures using dot notation.","title":"Welcome to the Dot Notation Universe"},{"location":"#project-status-v09-beta","text":"\u2705 Feature Complete : All 15 core tools implemented across 4 pillars \u2705 Comprehensive Testing : 367 tests passing with 100% coverage \u2705 Type Hints : Full type annotations for IDE support \u2705 CLI Support : All tools accessible from command line \u2705 DSL Parser : Human-friendly query syntax for dotquery","title":"Project Status: v0.9-beta"},{"location":"#quick-overview","text":"The ecosystem is organized around three fundamental pillars plus collections: \ud83c\udfaf Depth Pillar : Finding and extracting data ( dotget , dotstar , dotselect , dotpath ) \u2705 Truth Pillar : Boolean logic and validation ( dotexists , dotequals , dotany , dotall , dotquery ) \ud83d\udd04 Shape Pillar : Data transformation ( dotmod , dotbatch , dotpipe , dotpluck ) \ud83d\udcda Collections : Relational operations ( dotfilter , dotrelate )","title":"Quick Overview"},{"location":"#get-started","text":"Getting Started - Installation and first steps Philosophy - Design principles and motivation Ecosystem Overview - Complete tool reference","title":"Get Started"},{"location":"#why-dotsuite","text":"Pedagogical Design : Learn data manipulation concepts through clear, focused tools Composability : Unix philosophy - each tool does one thing well Mathematical Foundation : Built on solid theoretical principles Safe by Default : Immutable operations, graceful handling of missing data Progressive Enhancement : Start simple, add complexity as needed","title":"Why dotsuite?"},{"location":"#example","text":"from depth.dotget import get from truth.dotquery import Query from collections.dotfilter import dotfilter data = [ { \"user\" : { \"name\" : \"Alice\" , \"age\" : 30 , \"role\" : \"admin\" }}, { \"user\" : { \"name\" : \"Bob\" , \"age\" : 25 , \"role\" : \"user\" }} ] # Filter admins over 25 admins = dotfilter ( data , Query ( \"(user.role equals admin) and (user.age greater 25)\" )) # Extract names names = [ get ( doc , \"user.name\" ) for doc in admins ] # [\"Alice\"]","title":"Example"},{"location":"#related-projects","text":"jsonl-algebra - Production-ready relational operations for JSONL JAF - JSON Array Filter with advanced capabilities","title":"Related Projects"},{"location":"#contributing","text":"We welcome contributions! See our GitHub repository for: - Source code - Issue tracking - Development guidelines - Test suite (367 tests!) \"What started as a single, humble function evolved into a complete, coherent ecosystem for manipulating data structures.\"","title":"Contributing"},{"location":"dot-formalism/","text":"The dot Ecosystem \u2014 A Formal Blueprint \u00b6 Premise. Manipulating semi-structured data is easiest when every operation answers exactly one question and composes cleanly with every other operation. Goal. Provide a minimal yet complete algebra for JSON-like documents and their collections, with clear pedagogical on-ramps. Method. Factor the problem space into three orthogonal pillars (Depth \u2248 Addressing, Truth \u2248 Logic, Shape \u2248 Transformation) and lift them from single documents to collections. 1\u2003The Three Pillars \u00b6 Pillar Core Question Domain Codomain Primitive Depth \u201c Where is the data?\u201d Document Path \u21a6 \ud835\udc49* dotget Truth \u201c Is this assertion true here?\u201d Document \ud835\udd39 dotexists Shape \u201c How should the data be re-shaped?\u201d Document Document dotpluck Notation. A JSON document is an element of $\\mathcal D$. A path is a finite sequence of selectors; evaluation yields either a single value or a multiset $V^{*}$ (to accommodate wildcards). Boolean results live in $\\mathbb B={\\bot,\\top}$. 1.1\u2003Depth \u2014 Addressing Algebra \u00b6 Layer Operator Semantic Type Observations entry dotget $\\mathcal D \\times \\text{Path}_{\\text{exact}}\\to V\\cup{\\emptyset}$ Total if we treat \u201cmissing\u201d as $\\emptyset$. pattern dotstar $\\mathcal D \\times \\text{Path}_{ } \\to V^{ }$ Wildcards induce Kleene-star expansion. workhorse dotselect $\\mathcal D \\times \\text{Path}_{\\text{expr}} \\to V^{*}$ Admits slices, filters \u2194 regular-path queries. engine dotpath Free algebra on selectors; Turing-complete by user-defined reducers. Formally each operator is a morphism in the Kleisli category of the powerset monad, ensuring compositionality: dotstar \u2218 dotselect \u2192 still a set of values. 1.2\u2003Truth \u2014 Predicate Calculus \u00b6 Layer Operator Type Law structure dotexists $\\mathcal D \\times P \\to \ud835\udd39$ exists(p) \u2261 count(dotstar(p)) > 0 . content dotequals $\\mathcal D \\times (P,V) \\to \ud835\udd39$ Reflexive, symmetric only on singleton paths. quantifiers dotany / dotall $\\mathcal D \\times (P, \u03c6) \\to \ud835\udd39$ Lift predicate $\u03c6$ point-wise then aggregate with \u2228 / \u2227. engine dotquery $\\mathcal D \\times \\mathcal L_{BOOL}(\u03c6_i) \\to \ud835\udd39$ $\\mathcal L_{BOOL}$ is propositional logic; distributive laws preserve short-circuit semantics. Boolean algebra closure. Predicates form a Boolean algebra under \u2227, \u2228, \u00ac that is homomorphic to set algebra on result subsets (intersection, union, complement). 1.3\u2003Shape \u2014 Endofunctors on $\\mathcal D$ \u00b6 Layer Operator Type Category-theoretic view extract dotpluck $\\mathcal D \\times P \\to V^{*}$ Not a transform; a projection functor to Sets. surgical dotmod $\\mathcal D \\times \u03b4 \\to \\mathcal D$ \u03b4 = {insert, update, delete}. Lens with put-get law. compositional dotpipe $\\mathcal D \\times F^{*} \\to \\mathcal D$ Kleisli composition of pure functions $F: \\mathcal D\u2192\\mathcal D$. transactional dotbatch $\\mathcal D^{ } \\times \u0394^{ } \\to \\mathcal D^{*}$ Monoid action; supports ACID if \u0394 is sequence-serialisable. 2\u2003Lifting to Collections \u00b6 Let a collection be a finite multiset $C \\subseteq \\mathcal D$. Operations lift via: $$ \\operatorname{map} : (\\mathcal D \\to X) \\to (C \\to X^{*}) \\qquad \\operatorname{filter} : (\\mathcal D \\to \ud835\udd39) \\to (C \\to C) $$ 2.1\u2003Boolean Wing (Filtering) \u00b6 Operator Definition Note dothas $C, P \\mapsto {d\u2208C \\mid \\text{dotexists}(d,P)}$ Primitive filter. dotfind $C, \u03c6 \\mapsto {d\u2208C \\mid \u03c6(d)}$ \u03c6 any Truth-pillar predicate. dotfilter Higher-order: accepts combinators (AND/OR/NOT). Closure under Boolean algebra proven by homomorphism. 2.2\u2003Transforming Wing (Mapping & Relating) \u00b6 Operator Lifted From Semantics dotmod , dotpipe , dotbatch , dotpluck Shape pillar Point-wise map; distributive over union. dotrelate new Binary relation $C_1 \\Join C_2 \\to C_{12}$; isomorphic to relational algebra (\u03c3, \u03c0, \u22c8, \u222a, \u2212). Key guarantee. Every collection operator is a monoid homomorphism w.r.t. multiset union, enabling parallelisation and streaming. 3\u2003Pedagogical Gradient \u00b6 Hello-World phase. dotget , dotexists , dotpluck \u2014 O(1) mental load. Pattern phase. Add dotstar , dotequals , dotmod . Power-user phase. dotselect , dotany/all , dotpipe . Expert / DSL author. dotpath , dotquery , dotbatch , dotrelate . Each stage is conservative : every new construct can be desugared into earlier ones plus a small kernel, preserving learnability. 4\u2003Design Invariants \u00b6 Purity & Immutability. Functions are referentially transparent; concurrency is trivial. Totality by Convention. Missing paths yield $\\emptyset$ rather than exceptions, pushing error handling into the type. Compositionality. Operators form algebras (Boolean, monoidal, Kleisli) guaranteeing that compose \u21d2 reason locally . Orthogonality. No operator belongs to more than one pillar; cross-cutting concerns are expresses as functor lifts, not ad-hoc features. Extensibility. Users can register new selector primitives or predicates; completion is measured against algebraic closure, not feature lists. 5\u2003Big-Picture Fit \u00b6 dot \u2019s Depth\u2013Truth\u2013Shape triad mirrors the CRUD partition (Read, Validate, Update). The collection lift embeds seamlessly into stream processors (e.g., UNIX pipes, Apache Beam) because all lifted ops are monoid homomorphisms. Advanced users can harvest category-theoretic intuition: paths are optics , predicates are subobjects , transforms are endofunctors . The architecture matches database theory: single-document logic \u2248 tuple calculus; dotrelate \u2248 relational algebra; streaming lift \u2248 data-parallel query plans. 6\u2003Next Questions (Skeptical Checklist) \u00b6 Can every JSONPath feature be expressed in dotpath without semantic leaks? Are dotbatch rollbacks composable with streaming sinks? Which algebraic laws break under heterogeneous array mixes, and do we care? How do we reconcile user-defined side-effectful functions with purity guarantees? Can the type system (e.g., gradual typing) enforce pillar boundaries statically? TL;DR \u00b6 dot is not a toolbox; it is a small, law-governed algebra for interrogating and reshaping data. Three orthogonal pillars give you location, truth, and transformation; functorial lifting scales them to streams. Everything else is just syntax sugar. let's think very carefully about how to improve our documents with this formalism. we can also read from proposal-collections-pillar.md for ideas.","title":"Formal Specification"},{"location":"dot-formalism/#the-dot-ecosystem-a-formal-blueprint","text":"Premise. Manipulating semi-structured data is easiest when every operation answers exactly one question and composes cleanly with every other operation. Goal. Provide a minimal yet complete algebra for JSON-like documents and their collections, with clear pedagogical on-ramps. Method. Factor the problem space into three orthogonal pillars (Depth \u2248 Addressing, Truth \u2248 Logic, Shape \u2248 Transformation) and lift them from single documents to collections.","title":"The dot Ecosystem \u2014 A Formal Blueprint"},{"location":"dot-formalism/#1-the-three-pillars","text":"Pillar Core Question Domain Codomain Primitive Depth \u201c Where is the data?\u201d Document Path \u21a6 \ud835\udc49* dotget Truth \u201c Is this assertion true here?\u201d Document \ud835\udd39 dotexists Shape \u201c How should the data be re-shaped?\u201d Document Document dotpluck Notation. A JSON document is an element of $\\mathcal D$. A path is a finite sequence of selectors; evaluation yields either a single value or a multiset $V^{*}$ (to accommodate wildcards). Boolean results live in $\\mathbb B={\\bot,\\top}$.","title":"1 The Three Pillars"},{"location":"dot-formalism/#11-depth-addressing-algebra","text":"Layer Operator Semantic Type Observations entry dotget $\\mathcal D \\times \\text{Path}_{\\text{exact}}\\to V\\cup{\\emptyset}$ Total if we treat \u201cmissing\u201d as $\\emptyset$. pattern dotstar $\\mathcal D \\times \\text{Path}_{ } \\to V^{ }$ Wildcards induce Kleene-star expansion. workhorse dotselect $\\mathcal D \\times \\text{Path}_{\\text{expr}} \\to V^{*}$ Admits slices, filters \u2194 regular-path queries. engine dotpath Free algebra on selectors; Turing-complete by user-defined reducers. Formally each operator is a morphism in the Kleisli category of the powerset monad, ensuring compositionality: dotstar \u2218 dotselect \u2192 still a set of values.","title":"1.1 Depth \u2014 Addressing Algebra"},{"location":"dot-formalism/#12-truth-predicate-calculus","text":"Layer Operator Type Law structure dotexists $\\mathcal D \\times P \\to \ud835\udd39$ exists(p) \u2261 count(dotstar(p)) > 0 . content dotequals $\\mathcal D \\times (P,V) \\to \ud835\udd39$ Reflexive, symmetric only on singleton paths. quantifiers dotany / dotall $\\mathcal D \\times (P, \u03c6) \\to \ud835\udd39$ Lift predicate $\u03c6$ point-wise then aggregate with \u2228 / \u2227. engine dotquery $\\mathcal D \\times \\mathcal L_{BOOL}(\u03c6_i) \\to \ud835\udd39$ $\\mathcal L_{BOOL}$ is propositional logic; distributive laws preserve short-circuit semantics. Boolean algebra closure. Predicates form a Boolean algebra under \u2227, \u2228, \u00ac that is homomorphic to set algebra on result subsets (intersection, union, complement).","title":"1.2 Truth \u2014 Predicate Calculus"},{"location":"dot-formalism/#13-shape-endofunctors-on-mathcal-d","text":"Layer Operator Type Category-theoretic view extract dotpluck $\\mathcal D \\times P \\to V^{*}$ Not a transform; a projection functor to Sets. surgical dotmod $\\mathcal D \\times \u03b4 \\to \\mathcal D$ \u03b4 = {insert, update, delete}. Lens with put-get law. compositional dotpipe $\\mathcal D \\times F^{*} \\to \\mathcal D$ Kleisli composition of pure functions $F: \\mathcal D\u2192\\mathcal D$. transactional dotbatch $\\mathcal D^{ } \\times \u0394^{ } \\to \\mathcal D^{*}$ Monoid action; supports ACID if \u0394 is sequence-serialisable.","title":"1.3 Shape \u2014 Endofunctors on $\\mathcal D$"},{"location":"dot-formalism/#2-lifting-to-collections","text":"Let a collection be a finite multiset $C \\subseteq \\mathcal D$. Operations lift via: $$ \\operatorname{map} : (\\mathcal D \\to X) \\to (C \\to X^{*}) \\qquad \\operatorname{filter} : (\\mathcal D \\to \ud835\udd39) \\to (C \\to C) $$","title":"2 Lifting to Collections"},{"location":"dot-formalism/#21-boolean-wing-filtering","text":"Operator Definition Note dothas $C, P \\mapsto {d\u2208C \\mid \\text{dotexists}(d,P)}$ Primitive filter. dotfind $C, \u03c6 \\mapsto {d\u2208C \\mid \u03c6(d)}$ \u03c6 any Truth-pillar predicate. dotfilter Higher-order: accepts combinators (AND/OR/NOT). Closure under Boolean algebra proven by homomorphism.","title":"2.1 Boolean Wing (Filtering)"},{"location":"dot-formalism/#22-transforming-wing-mapping-relating","text":"Operator Lifted From Semantics dotmod , dotpipe , dotbatch , dotpluck Shape pillar Point-wise map; distributive over union. dotrelate new Binary relation $C_1 \\Join C_2 \\to C_{12}$; isomorphic to relational algebra (\u03c3, \u03c0, \u22c8, \u222a, \u2212). Key guarantee. Every collection operator is a monoid homomorphism w.r.t. multiset union, enabling parallelisation and streaming.","title":"2.2 Transforming Wing (Mapping &amp; Relating)"},{"location":"dot-formalism/#3-pedagogical-gradient","text":"Hello-World phase. dotget , dotexists , dotpluck \u2014 O(1) mental load. Pattern phase. Add dotstar , dotequals , dotmod . Power-user phase. dotselect , dotany/all , dotpipe . Expert / DSL author. dotpath , dotquery , dotbatch , dotrelate . Each stage is conservative : every new construct can be desugared into earlier ones plus a small kernel, preserving learnability.","title":"3 Pedagogical Gradient"},{"location":"dot-formalism/#4-design-invariants","text":"Purity & Immutability. Functions are referentially transparent; concurrency is trivial. Totality by Convention. Missing paths yield $\\emptyset$ rather than exceptions, pushing error handling into the type. Compositionality. Operators form algebras (Boolean, monoidal, Kleisli) guaranteeing that compose \u21d2 reason locally . Orthogonality. No operator belongs to more than one pillar; cross-cutting concerns are expresses as functor lifts, not ad-hoc features. Extensibility. Users can register new selector primitives or predicates; completion is measured against algebraic closure, not feature lists.","title":"4 Design Invariants"},{"location":"dot-formalism/#5-big-picture-fit","text":"dot \u2019s Depth\u2013Truth\u2013Shape triad mirrors the CRUD partition (Read, Validate, Update). The collection lift embeds seamlessly into stream processors (e.g., UNIX pipes, Apache Beam) because all lifted ops are monoid homomorphisms. Advanced users can harvest category-theoretic intuition: paths are optics , predicates are subobjects , transforms are endofunctors . The architecture matches database theory: single-document logic \u2248 tuple calculus; dotrelate \u2248 relational algebra; streaming lift \u2248 data-parallel query plans.","title":"5 Big-Picture Fit"},{"location":"dot-formalism/#6-next-questions-skeptical-checklist","text":"Can every JSONPath feature be expressed in dotpath without semantic leaks? Are dotbatch rollbacks composable with streaming sinks? Which algebraic laws break under heterogeneous array mixes, and do we care? How do we reconcile user-defined side-effectful functions with purity guarantees? Can the type system (e.g., gradual typing) enforce pillar boundaries statically?","title":"6 Next Questions (Skeptical Checklist)"},{"location":"dot-formalism/#tldr","text":"dot is not a toolbox; it is a small, law-governed algebra for interrogating and reshaping data. Three orthogonal pillars give you location, truth, and transformation; functorial lifting scales them to streams. Everything else is just syntax sugar. let's think very carefully about how to improve our documents with this formalism. we can also read from proposal-collections-pillar.md for ideas.","title":"TL;DR"},{"location":"dot-notation-universe/","text":"The Dot Notation Universe: A Journey in API Design \u00b6 It always starts with a simple problem. You have a nested dictionary or a JSON payload, and you need to get a value buried deep inside. You write data['user']['contacts'][0]['email'] and you pray that no key or index is missing along the way, lest your program crash. This leads to brittle, defensive code. The first, obvious solution is a helper function. This is where our story begins. What started as a single, humble function, dotget , evolved through a series of questions and insights into a complete, coherent, and powerful ecosystem for manipulating data structures. This is the story of that evolution\u2014a journey in API design guided by the principles of purity, pedagogy, and the principle of least power. Part I: The Single Document - The Three Pillars of Intelligence \u00b6 Mastering operations inside a single, complex document is the foundation of the entire ecosystem. We discovered that this \"per-document intelligence\" isn't a single path, but rests on three distinct pillars, each answering a different fundamental question. Pillar 1: The Addressing Layer (Retrieval) \u00b6 This is the bedrock. It answers the question: \"WHAT is the value at a given location?\" Its tools are designed purely for finding and returning data. dotget (Exact Addressing): The starting point. It retrieves a single value from a precise, known path (e.g., \"users.0.name\" ). dotstar (Pattern Addressing): Introduces the * wildcard to retrieve multiple values from a structural pattern (e.g., \"users.*.name\" ). dotquery (Conditional Addressing): The master addressing engine. It understands a complete path language, including conditional predicates ( [key=value] ) and descendant wildcards ( ** ), to find and retrieve data from the most complex locations. Pillar 2: The Logic Layer (Assertion) \u00b6 Once we can find data, the next question is not about the data's value, but its veracity. This pillar answers the question: \"IS a statement about this document true?\" Its output is always a boolean. dotexists (Simple Existence): The simplest logical test. It takes a dotget -style exact path and returns True if it resolves to a value. dotany / dotall (Quantifiers): This is the necessary next step for handling paths that return multiple values. It forces the user to be explicit about their intent. dotany checks if at least one returned value meets a condition, while dotall checks if all of them do. dotlogic (Compositional Logic): The final stage. This is a full predicate engine that can compose the results of simpler checks using AND , OR , NOT . It can evaluate complex, self-referential assertions, such as checking if two different lists of values within the document have any intersection. Pillar 3: The Action Layer (Manipulation) \u00b6 This pillar answers the question: \"HOW should this document be changed?\" It uses the Addressing Layer to find where to act. It is built on the principle of immutability\u2014always returning a modified copy. The \"Write\" Branch ( dotmod , dotbatch ): This branch is for direct mutation. dotmod provides the verbs for single changes ( set_ , delete_ ), while dotbatch provides the transactional capability to apply a sequence of changes atomically. Its output is the same document, modified ( Doc -> Doc ). The \"Transform\" Branch ( dotmap ): This branch is for reshaping data. It takes a document and derives a new structure from it, such as a simplified \"view model\" for a UI. Its output can be of any shape ( Doc -> Any ). Part II: Collections of Documents - A World of \"Breadth\" \u00b6 With a complete toolkit for single documents, we can now operate on collections, often represented as a stream of documents like in a JSONL file. This \"Breadth\" axis has two main pillars that use the per-document tools as their internal machinery. dotset : A Boolean Algebra for Collections \u00b6 dotset filters a collection. It answers the question: \"Which documents in this collection match a set of logical rules?\" Its power comes from using the Truth Pillar as its decision engine for each document. A lazy, compositional QuerySet API allows for building complex queries efficiently. # Find all logs that are either a critical server error OR # a database call that was too slow, but EXCLUDING any from a known-buggy service. logs = QuerySet ( log_collection ) # This query is translated into a dotlogic AST and applied to each document. results = logs . filter ( Q ( level = \"error\" , source = \"server\" ) | Q ( source = \"db\" , latency_ms__gt = 500 ) ) . exclude ( service_name = \"buggy-service-alpha\" ) dotrelate : A Relational Algebra for Collections \u00b6 While dotset filters a collection, dotrelate transforms and combines multiple collections. It's the conceptual parallel to dotmap , but for datasets. It answers: \"How can these distinct collections be joined to create new, enriched data?\" The core operation is the join , which combines documents from two collections based on a shared key. # users = [{\"user_id\": 1, \"name\": \"Alice\"}, ...] # orders = [{\"order_id\": 101, \"user_id\": 2, \"item\": \"Book\"}, ...] # Enrich each order with the name of the user who placed it. enriched_orders = dotrelate . join ( left = orders , right = users , on = \"user_id\" ) # -> [{\"order_id\": 101, ..., \"name\": \"Bob\"}, ...] The Big Picture: A Unified Architecture \u00b6 This journey reveals a coherent universe of tools, underpinned by a dual API (programmatic for developers, declarative JSON/string for users) and a philosophy of clean, single-purpose components. graph TD subgraph The_Dot_Universe [\"The Dot Notation Universe\"] subgraph Single_Doc [\"Part I: Per-Document Intelligence ('Depth')\"] direction TB subgraph Addressing_Layer [\"Pillar 1: Addressing (Retrieval)\"] dotget(\"dotget\") --> dotstar(\"dotstar\") --> dotquery(\"dotquery\") end subgraph Logic_Layer [\"Pillar 2: Logic (Assertion)\"] dotexists(\"dotexists\") --> dotanyall(\"dotany/dotall\") --> dotlogic(\"dotlogic\") end subgraph Action_Layer [\"Pillar 3: Action (Manipulation)\"] direction LR write_branch[\"Write Branch<br>(dotmod, dotbatch)\"] transform_branch[\"Transform Branch<br>(dotmap)\"] end end subgraph Collection_Ops [\"Part II: Collection Operations ('Breadth')\"] direction TB subgraph Filter_Branch [\"Filter / Boolean Algebra\"] dotset(\"dotset\") end subgraph Relate_Branch [\"Relate / Relational Algebra\"] dotrelate(\"dotrelate\") end end Addressing_Layer -- \"Provides paths for\" --> Action_Layer Addressing_Layer -- \"Provides paths for\" --> Logic_Layer Logic_Layer -- \"Provides decision engine for\" --> Collection_Ops Action_Layer -- \"(dotmap) provides primitives for\" --> Relate_Branch end","title":"Universe Overview"},{"location":"dot-notation-universe/#the-dot-notation-universe-a-journey-in-api-design","text":"It always starts with a simple problem. You have a nested dictionary or a JSON payload, and you need to get a value buried deep inside. You write data['user']['contacts'][0]['email'] and you pray that no key or index is missing along the way, lest your program crash. This leads to brittle, defensive code. The first, obvious solution is a helper function. This is where our story begins. What started as a single, humble function, dotget , evolved through a series of questions and insights into a complete, coherent, and powerful ecosystem for manipulating data structures. This is the story of that evolution\u2014a journey in API design guided by the principles of purity, pedagogy, and the principle of least power.","title":"The Dot Notation Universe: A Journey in API Design"},{"location":"dot-notation-universe/#part-i-the-single-document-the-three-pillars-of-intelligence","text":"Mastering operations inside a single, complex document is the foundation of the entire ecosystem. We discovered that this \"per-document intelligence\" isn't a single path, but rests on three distinct pillars, each answering a different fundamental question.","title":"Part I: The Single Document - The Three Pillars of Intelligence"},{"location":"dot-notation-universe/#pillar-1-the-addressing-layer-retrieval","text":"This is the bedrock. It answers the question: \"WHAT is the value at a given location?\" Its tools are designed purely for finding and returning data. dotget (Exact Addressing): The starting point. It retrieves a single value from a precise, known path (e.g., \"users.0.name\" ). dotstar (Pattern Addressing): Introduces the * wildcard to retrieve multiple values from a structural pattern (e.g., \"users.*.name\" ). dotquery (Conditional Addressing): The master addressing engine. It understands a complete path language, including conditional predicates ( [key=value] ) and descendant wildcards ( ** ), to find and retrieve data from the most complex locations.","title":"Pillar 1: The Addressing Layer (Retrieval)"},{"location":"dot-notation-universe/#pillar-2-the-logic-layer-assertion","text":"Once we can find data, the next question is not about the data's value, but its veracity. This pillar answers the question: \"IS a statement about this document true?\" Its output is always a boolean. dotexists (Simple Existence): The simplest logical test. It takes a dotget -style exact path and returns True if it resolves to a value. dotany / dotall (Quantifiers): This is the necessary next step for handling paths that return multiple values. It forces the user to be explicit about their intent. dotany checks if at least one returned value meets a condition, while dotall checks if all of them do. dotlogic (Compositional Logic): The final stage. This is a full predicate engine that can compose the results of simpler checks using AND , OR , NOT . It can evaluate complex, self-referential assertions, such as checking if two different lists of values within the document have any intersection.","title":"Pillar 2: The Logic Layer (Assertion)"},{"location":"dot-notation-universe/#pillar-3-the-action-layer-manipulation","text":"This pillar answers the question: \"HOW should this document be changed?\" It uses the Addressing Layer to find where to act. It is built on the principle of immutability\u2014always returning a modified copy. The \"Write\" Branch ( dotmod , dotbatch ): This branch is for direct mutation. dotmod provides the verbs for single changes ( set_ , delete_ ), while dotbatch provides the transactional capability to apply a sequence of changes atomically. Its output is the same document, modified ( Doc -> Doc ). The \"Transform\" Branch ( dotmap ): This branch is for reshaping data. It takes a document and derives a new structure from it, such as a simplified \"view model\" for a UI. Its output can be of any shape ( Doc -> Any ).","title":"Pillar 3: The Action Layer (Manipulation)"},{"location":"dot-notation-universe/#part-ii-collections-of-documents-a-world-of-breadth","text":"With a complete toolkit for single documents, we can now operate on collections, often represented as a stream of documents like in a JSONL file. This \"Breadth\" axis has two main pillars that use the per-document tools as their internal machinery.","title":"Part II: Collections of Documents - A World of \"Breadth\""},{"location":"dot-notation-universe/#dotset-a-boolean-algebra-for-collections","text":"dotset filters a collection. It answers the question: \"Which documents in this collection match a set of logical rules?\" Its power comes from using the Truth Pillar as its decision engine for each document. A lazy, compositional QuerySet API allows for building complex queries efficiently. # Find all logs that are either a critical server error OR # a database call that was too slow, but EXCLUDING any from a known-buggy service. logs = QuerySet ( log_collection ) # This query is translated into a dotlogic AST and applied to each document. results = logs . filter ( Q ( level = \"error\" , source = \"server\" ) | Q ( source = \"db\" , latency_ms__gt = 500 ) ) . exclude ( service_name = \"buggy-service-alpha\" )","title":"dotset: A Boolean Algebra for Collections"},{"location":"dot-notation-universe/#dotrelate-a-relational-algebra-for-collections","text":"While dotset filters a collection, dotrelate transforms and combines multiple collections. It's the conceptual parallel to dotmap , but for datasets. It answers: \"How can these distinct collections be joined to create new, enriched data?\" The core operation is the join , which combines documents from two collections based on a shared key. # users = [{\"user_id\": 1, \"name\": \"Alice\"}, ...] # orders = [{\"order_id\": 101, \"user_id\": 2, \"item\": \"Book\"}, ...] # Enrich each order with the name of the user who placed it. enriched_orders = dotrelate . join ( left = orders , right = users , on = \"user_id\" ) # -> [{\"order_id\": 101, ..., \"name\": \"Bob\"}, ...]","title":"dotrelate: A Relational Algebra for Collections"},{"location":"dot-notation-universe/#the-big-picture-a-unified-architecture","text":"This journey reveals a coherent universe of tools, underpinned by a dual API (programmatic for developers, declarative JSON/string for users) and a philosophy of clean, single-purpose components. graph TD subgraph The_Dot_Universe [\"The Dot Notation Universe\"] subgraph Single_Doc [\"Part I: Per-Document Intelligence ('Depth')\"] direction TB subgraph Addressing_Layer [\"Pillar 1: Addressing (Retrieval)\"] dotget(\"dotget\") --> dotstar(\"dotstar\") --> dotquery(\"dotquery\") end subgraph Logic_Layer [\"Pillar 2: Logic (Assertion)\"] dotexists(\"dotexists\") --> dotanyall(\"dotany/dotall\") --> dotlogic(\"dotlogic\") end subgraph Action_Layer [\"Pillar 3: Action (Manipulation)\"] direction LR write_branch[\"Write Branch<br>(dotmod, dotbatch)\"] transform_branch[\"Transform Branch<br>(dotmap)\"] end end subgraph Collection_Ops [\"Part II: Collection Operations ('Breadth')\"] direction TB subgraph Filter_Branch [\"Filter / Boolean Algebra\"] dotset(\"dotset\") end subgraph Relate_Branch [\"Relate / Relational Algebra\"] dotrelate(\"dotrelate\") end end Addressing_Layer -- \"Provides paths for\" --> Action_Layer Addressing_Layer -- \"Provides paths for\" --> Logic_Layer Logic_Layer -- \"Provides decision engine for\" --> Collection_Ops Action_Layer -- \"(dotmap) provides primitives for\" --> Relate_Branch end","title":"The Big Picture: A Unified Architecture"},{"location":"ecosystem/","text":"The dot Ecosystem: A Tour \u00b6 The dot ecosystem is a suite of small, focused Python libraries for manipulating nested data structures. Each tool follows the Unix philosophy: it does one thing and does it well. They are designed to be composed together, often in a pipeline, to perform complex data transformations in a clear and predictable way. This document provides an overview of each tool, its core philosophy, and its primary use case. The Two Pillars: Addressing and Logic \u00b6 The ecosystem is divided into two pillars, each answering a different fundamental question. 1. The Addressing Pillar: \"What is the data?\" \u00b6 These tools are used to find and retrieve data from your nested structures. They are organized in layers of increasing power, following the \"Principle of Least Power.\" dotget : The simplest tool. Gets a value from a single, exact path. dotstar : Adds wildcard matching ( * ) to find all items that match a structural pattern. dotselect : The most powerful user-facing selector. Adds deep searches ( ** ) and attribute-based filtering ( [key=value] ). dotpath : The underlying, extensible engine that powers dotselect and dotquery . 2. The Truth Pillar: \"Is this statement true?\" \u00b6 These tools are used to ask questions about your data. They don't return the data itself, but rather a boolean result ( True / False ) or an exit code ( 0 / 1 ). dotexists : The simplest logical check. Determines if a single, exact path exists. dotquery : A powerful logic engine that evaluates complex, chainable queries against your data. The Tools: A Detailed Look \u00b6 dotget : Simple, Exact Addressing \u00b6 Pillar: Addressing What it does: Gets a single value from a nested data structure using a precise, dot-separated path. Philosophy: Do one thing well. dotget is intentionally simple, has no dependencies, and its core logic is a single, small function. You are encouraged to \"steal this code\" to avoid adding a dependency for such a simple task. When to use it: When you know the exact path to the data you need, like reading from a config file or a stable API response. from dotget import get data = { \"users\" : [{ \"name\" : \"Alice\" }]} get ( data , \"users.0.name\" ) # => 'Alice' dotstar : Simple Wildcard Addressing \u00b6 Pillar: Addressing What it does: Finds all values in a data structure that match a pattern containing wildcards ( * ). Philosophy: Simple, dependency-free pattern matching. The * wildcard matches all items in a list or all values in a dictionary. Like dotget , it is simple enough to be \"stolen.\" When to use it: When you need to extract all data that conforms to a certain structure, like getting all names from a list of user objects. from dotstar import search data = { \"users\" : [{ \"name\" : \"Alice\" }, { \"name\" : \"Bob\" }]} search ( data , \"users.*.name\" ) # => ['Alice', 'Bob'] dotselect : Advanced Selection \u00b6 Pillar: Addressing What it does: The primary user-facing tool for complex queries. It extends the simple wildcard syntax of dotstar with descendant selectors ( ** ) and predicate filters ( [key=value] ). Philosophy: Provide a powerful and expressive syntax for the 90% of complex queries, built on the dotpath engine. When to use it: When you need to find data based on its value, without knowing its exact location. It is the go-to tool for most advanced data selection tasks. from dotselect import find_first data = { \"spec\" : { \"components\" : [{ \"type\" : \"server\" , \"ports\" : [ 80 , 443 ]}]}} # Find the ports of the 'server' component, wherever it is. find_first ( data , \"**[type=server].ports\" ) # => [80, 443] dotpath : The Master Addressing Engine \u00b6 Pillar: Addressing (Engine) What it does: dotpath is the foundational extensible addressing library for the ecosystem. It provides the engine for parsing and evaluating the complex paths used by dotselect and dotquery . Philosophy: An addressing engine should be an extensible machine. It is the \"Lambda of Paths\": it allows the path language itself to be extended for specialized use cases. When to use it: You will typically use dotpath indirectly. You would interact with it directly only if you need to create your own custom pathing logic or extend the path language with new capabilities. dotexists : Simple Existence Check \u00b6 Pillar: Logic What it does: Checks for the existence of a value at a precise path. Philosophy: The logical counterpart to dotget . It provides the simplest possible truth check: \"Is it there?\" When to use it: To verify that a required key is present in configuration or to guard a dotget call in a script. from dotexists import check data = { \"user\" : { \"name\" : \"Alice\" , \"address\" : None }} check ( data , \"user.name\" ) # => True check ( data , \"user.age\" ) # => False dotquery : The Logic Engine \u00b6 Pillar: Logic What it does: Asks complex, compositional questions about your data and returns a boolean result. Philosophy: Logic is the anatomy of thought. dotquery separates asking a question from retrieving data. It is for validation and conditional logic, not data extraction. When to use it: When you need to validate a document against a set of rules or make decisions in a script based on the content of your data. # In the shell, check if any user is an admin $ cat users.json | dotquery \"any equals role admin\" $ echo $? # => 0 (True) The Transformation Tools \u00b6 Building on the addressing and logic pillars, the transformation tools help you modify, process, and reshape your data. Tool Core Function Philosophy dotmod Perform immutable modifications to data Predictable state change dotbatch Apply a sequence of modifications atomically Transactions for data dotpipe Transform data into a new shape Data transformation as a pipeline dotrelate Perform relational algebra on collections of data Bringing database concepts to JSON","title":"Ecosystem"},{"location":"ecosystem/#the-dot-ecosystem-a-tour","text":"The dot ecosystem is a suite of small, focused Python libraries for manipulating nested data structures. Each tool follows the Unix philosophy: it does one thing and does it well. They are designed to be composed together, often in a pipeline, to perform complex data transformations in a clear and predictable way. This document provides an overview of each tool, its core philosophy, and its primary use case.","title":"The dot Ecosystem: A Tour"},{"location":"ecosystem/#the-two-pillars-addressing-and-logic","text":"The ecosystem is divided into two pillars, each answering a different fundamental question.","title":"The Two Pillars: Addressing and Logic"},{"location":"ecosystem/#1-the-addressing-pillar-what-is-the-data","text":"These tools are used to find and retrieve data from your nested structures. They are organized in layers of increasing power, following the \"Principle of Least Power.\" dotget : The simplest tool. Gets a value from a single, exact path. dotstar : Adds wildcard matching ( * ) to find all items that match a structural pattern. dotselect : The most powerful user-facing selector. Adds deep searches ( ** ) and attribute-based filtering ( [key=value] ). dotpath : The underlying, extensible engine that powers dotselect and dotquery .","title":"1. The Addressing Pillar: \"What is the data?\""},{"location":"ecosystem/#2-the-truth-pillar-is-this-statement-true","text":"These tools are used to ask questions about your data. They don't return the data itself, but rather a boolean result ( True / False ) or an exit code ( 0 / 1 ). dotexists : The simplest logical check. Determines if a single, exact path exists. dotquery : A powerful logic engine that evaluates complex, chainable queries against your data.","title":"2. The Truth Pillar: \"Is this statement true?\""},{"location":"ecosystem/#the-tools-a-detailed-look","text":"","title":"The Tools: A Detailed Look"},{"location":"ecosystem/#dotget-simple-exact-addressing","text":"Pillar: Addressing What it does: Gets a single value from a nested data structure using a precise, dot-separated path. Philosophy: Do one thing well. dotget is intentionally simple, has no dependencies, and its core logic is a single, small function. You are encouraged to \"steal this code\" to avoid adding a dependency for such a simple task. When to use it: When you know the exact path to the data you need, like reading from a config file or a stable API response. from dotget import get data = { \"users\" : [{ \"name\" : \"Alice\" }]} get ( data , \"users.0.name\" ) # => 'Alice'","title":"dotget: Simple, Exact Addressing"},{"location":"ecosystem/#dotstar-simple-wildcard-addressing","text":"Pillar: Addressing What it does: Finds all values in a data structure that match a pattern containing wildcards ( * ). Philosophy: Simple, dependency-free pattern matching. The * wildcard matches all items in a list or all values in a dictionary. Like dotget , it is simple enough to be \"stolen.\" When to use it: When you need to extract all data that conforms to a certain structure, like getting all names from a list of user objects. from dotstar import search data = { \"users\" : [{ \"name\" : \"Alice\" }, { \"name\" : \"Bob\" }]} search ( data , \"users.*.name\" ) # => ['Alice', 'Bob']","title":"dotstar: Simple Wildcard Addressing"},{"location":"ecosystem/#dotselect-advanced-selection","text":"Pillar: Addressing What it does: The primary user-facing tool for complex queries. It extends the simple wildcard syntax of dotstar with descendant selectors ( ** ) and predicate filters ( [key=value] ). Philosophy: Provide a powerful and expressive syntax for the 90% of complex queries, built on the dotpath engine. When to use it: When you need to find data based on its value, without knowing its exact location. It is the go-to tool for most advanced data selection tasks. from dotselect import find_first data = { \"spec\" : { \"components\" : [{ \"type\" : \"server\" , \"ports\" : [ 80 , 443 ]}]}} # Find the ports of the 'server' component, wherever it is. find_first ( data , \"**[type=server].ports\" ) # => [80, 443]","title":"dotselect: Advanced Selection"},{"location":"ecosystem/#dotpath-the-master-addressing-engine","text":"Pillar: Addressing (Engine) What it does: dotpath is the foundational extensible addressing library for the ecosystem. It provides the engine for parsing and evaluating the complex paths used by dotselect and dotquery . Philosophy: An addressing engine should be an extensible machine. It is the \"Lambda of Paths\": it allows the path language itself to be extended for specialized use cases. When to use it: You will typically use dotpath indirectly. You would interact with it directly only if you need to create your own custom pathing logic or extend the path language with new capabilities.","title":"dotpath: The Master Addressing Engine"},{"location":"ecosystem/#dotexists-simple-existence-check","text":"Pillar: Logic What it does: Checks for the existence of a value at a precise path. Philosophy: The logical counterpart to dotget . It provides the simplest possible truth check: \"Is it there?\" When to use it: To verify that a required key is present in configuration or to guard a dotget call in a script. from dotexists import check data = { \"user\" : { \"name\" : \"Alice\" , \"address\" : None }} check ( data , \"user.name\" ) # => True check ( data , \"user.age\" ) # => False","title":"dotexists: Simple Existence Check"},{"location":"ecosystem/#dotquery-the-logic-engine","text":"Pillar: Logic What it does: Asks complex, compositional questions about your data and returns a boolean result. Philosophy: Logic is the anatomy of thought. dotquery separates asking a question from retrieving data. It is for validation and conditional logic, not data extraction. When to use it: When you need to validate a document against a set of rules or make decisions in a script based on the content of your data. # In the shell, check if any user is an admin $ cat users.json | dotquery \"any equals role admin\" $ echo $? # => 0 (True)","title":"dotquery: The Logic Engine"},{"location":"ecosystem/#the-transformation-tools","text":"Building on the addressing and logic pillars, the transformation tools help you modify, process, and reshape your data. Tool Core Function Philosophy dotmod Perform immutable modifications to data Predictable state change dotbatch Apply a sequence of modifications atomically Transactions for data dotpipe Transform data into a new shape Data transformation as a pipeline dotrelate Perform relational algebra on collections of data Bringing database concepts to JSON","title":"The Transformation Tools"},{"location":"getting-started/","text":"Getting Started \u00b6 Installation \u00b6 # Install from PyPI (once published) pip install dotsuite # Or install from source git clone https://github.com/yourusername/dotsuite.git cd dotsuite pip install -e . Quick Example \u00b6 # After pip install dotsuite: from dotsuite.depth.dotget import get from dotsuite.depth.dotstar import search from dotsuite.shape.dotmod import set_ # Or if using source install: # from depth.dotget.core import get # from depth.dotstar.core import search # from shape.dotmod.core import set_ # Your nested data data = { \"users\" : [ { \"name\" : \"Alice\" , \"age\" : 30 , \"role\" : \"admin\" }, { \"name\" : \"Bob\" , \"age\" : 25 , \"role\" : \"user\" } ] } # Get a specific value name = get ( data , \"users.0.name\" ) # \"Alice\" # Search with wildcards all_names = search ( data , \"users.*.name\" ) # [\"Alice\", \"Bob\"] # Modify data (returns new copy) new_data = set_ ( data , \"users.0.role\" , \"superadmin\" ) The Three Pillars \u00b6 Depth - Finding data: dotget - Simple path access dotstar - Wildcard patterns Truth - Validating data: dotexists - Check if path exists dotany / dotall - Quantifiers Shape - Transforming data: dotmod - Immutable modifications dotbatch - Atomic transactions Learn More \u00b6 Ready to dive deeper? Check out: Philosophy - The design principles behind dotsuite Ecosystem - Complete tool overview Examples - Real-world usage For Developers \u00b6 # Development setup with testing tools make install-dev make test make docs-serve # View docs at http://127.0.0.1:8000","title":"Getting Started"},{"location":"getting-started/#getting-started","text":"","title":"Getting Started"},{"location":"getting-started/#installation","text":"# Install from PyPI (once published) pip install dotsuite # Or install from source git clone https://github.com/yourusername/dotsuite.git cd dotsuite pip install -e .","title":"Installation"},{"location":"getting-started/#quick-example","text":"# After pip install dotsuite: from dotsuite.depth.dotget import get from dotsuite.depth.dotstar import search from dotsuite.shape.dotmod import set_ # Or if using source install: # from depth.dotget.core import get # from depth.dotstar.core import search # from shape.dotmod.core import set_ # Your nested data data = { \"users\" : [ { \"name\" : \"Alice\" , \"age\" : 30 , \"role\" : \"admin\" }, { \"name\" : \"Bob\" , \"age\" : 25 , \"role\" : \"user\" } ] } # Get a specific value name = get ( data , \"users.0.name\" ) # \"Alice\" # Search with wildcards all_names = search ( data , \"users.*.name\" ) # [\"Alice\", \"Bob\"] # Modify data (returns new copy) new_data = set_ ( data , \"users.0.role\" , \"superadmin\" )","title":"Quick Example"},{"location":"getting-started/#the-three-pillars","text":"Depth - Finding data: dotget - Simple path access dotstar - Wildcard patterns Truth - Validating data: dotexists - Check if path exists dotany / dotall - Quantifiers Shape - Transforming data: dotmod - Immutable modifications dotbatch - Atomic transactions","title":"The Three Pillars"},{"location":"getting-started/#learn-more","text":"Ready to dive deeper? Check out: Philosophy - The design principles behind dotsuite Ecosystem - Complete tool overview Examples - Real-world usage","title":"Learn More"},{"location":"getting-started/#for-developers","text":"# Development setup with testing tools make install-dev make test make docs-serve # View docs at http://127.0.0.1:8000","title":"For Developers"},{"location":"jaf-comparison/","text":"Dotsuite vs JAF: Pedagogy vs Production \u00b6 This document compares dotsuite with JAF (Just Another Flow) to help you choose the right tool for your needs. Overview \u00b6 Dotsuite : A pedagogical ecosystem teaching data manipulation concepts through simple, composable tools JAF : A production-ready streaming data processing system implementing similar concepts at scale Philosophical Differences \u00b6 Dotsuite - \"Learn by Building\" \u00b6 Goal : Teach concepts through simplicity Philosophy : Unix philosophy - one tool, one purpose Audience : Learners, educators, prototypers Code Style : \"Steal this code\" - simple enough to copy and understand JAF - \"Battle-Tested Solution\" \u00b6 Goal : Production-ready data processing Philosophy : Feature-complete streaming framework Audience : Production systems, data engineers Code Style : Robust, optimized, extensive error handling Feature Comparison \u00b6 Feature Dotsuite JAF Query Language Simple strings: \"equals role admin\" S-expressions: [\"eq?\", \"@role\", \"admin\"] Path System Dot notation: \"user.name\" Advanced AST with regex, fuzzy, wildcards Evaluation Eager (with lazy QuerySet option) Lazy by default with streaming Data Sources In-memory collections Files, directories, stdin, compressed, infinite Set Operations Basic (union, intersection, difference) Index-preserving with collection tracking Pipeline Composition Separate tools (dotpipe) Built-in method chaining Memory Usage Loads data into memory Streaming generators Error Handling Basic Comprehensive with custom exceptions Performance Educational focus Optimized for production Dependencies Minimal Optional advanced libraries Conceptual Alignment \u00b6 Both projects share core concepts but implement them differently: Filtering as Boolean Algebra \u00b6 Dotsuite : dotfilter with QuerySet for lazy evaluation JAF : FilteredStream with comprehensive boolean operations Pipeline Composition \u00b6 Dotsuite : dotpipe for transformation chains JAF : Built-in .filter().map().take() chaining Path Navigation \u00b6 Dotsuite : dotget with simple dot notation JAF : Complex path AST with multiple navigation strategies When to Use Which? \u00b6 Use Dotsuite When: \u00b6 Learning data manipulation concepts Teaching programming or data structures Building prototypes You need simple, understandable code You want to modify/extend the implementation Working with small to medium datasets Use JAF When: \u00b6 Building production systems Processing large datasets or streams Need advanced features (regex paths, fuzzy matching) Require robust error handling Working with multiple data sources Need memory-efficient streaming Learning Path \u00b6 Start with Dotsuite to understand concepts: How path navigation works ( dotget ) Boolean filtering ( dotfilter ) Pipeline composition ( dotpipe ) Set operations on collections Graduate to JAF for production: Apply learned concepts at scale Leverage advanced features Handle real-world edge cases Code Examples \u00b6 Simple Filter Operation \u00b6 Dotsuite: from collections.dotfilter import filter_docs users = [{ \"name\" : \"Alice\" , \"age\" : 30 }, { \"name\" : \"Bob\" , \"age\" : 25 }] adults = filter_docs ( users , \"greater_than age 25\" ) JAF: from jaf import stream adults = stream ( \"users.jsonl\" ) \\ . filter ([ \"gt?\" , \"@age\" , 25 ]) \\ . evaluate () Pipeline Composition \u00b6 Dotsuite: from shape.dotpipe import pipe from collections.dotfilter import filter_docs result = pipe ( data , lambda d : filter_docs ( d , \"equals status active\" ), lambda d : [ dotget ( doc , \"email\" ) for doc in d ] ) JAF: result = stream ( \"users.jsonl\" ) \\ . filter ([ \"eq?\" , \"@status\" , \"active\" ]) \\ . map ( \"@email\" ) \\ . evaluate () Integration \u00b6 Both projects can work together: Learn with Dotsuite : Understand the concepts Prototype with Dotsuite : Quick implementations Production with JAF : Scale when ready Contribute back : Share learnings with both communities Summary \u00b6 Dotsuite and JAF are complementary projects: - Dotsuite teaches the \"why\" and \"how\" through simplicity - JAF provides the \"what\" for production use Together, they form a complete ecosystem from learning to production.","title":"JAF vs Dotsuite"},{"location":"jaf-comparison/#dotsuite-vs-jaf-pedagogy-vs-production","text":"This document compares dotsuite with JAF (Just Another Flow) to help you choose the right tool for your needs.","title":"Dotsuite vs JAF: Pedagogy vs Production"},{"location":"jaf-comparison/#overview","text":"Dotsuite : A pedagogical ecosystem teaching data manipulation concepts through simple, composable tools JAF : A production-ready streaming data processing system implementing similar concepts at scale","title":"Overview"},{"location":"jaf-comparison/#philosophical-differences","text":"","title":"Philosophical Differences"},{"location":"jaf-comparison/#dotsuite-learn-by-building","text":"Goal : Teach concepts through simplicity Philosophy : Unix philosophy - one tool, one purpose Audience : Learners, educators, prototypers Code Style : \"Steal this code\" - simple enough to copy and understand","title":"Dotsuite - \"Learn by Building\""},{"location":"jaf-comparison/#jaf-battle-tested-solution","text":"Goal : Production-ready data processing Philosophy : Feature-complete streaming framework Audience : Production systems, data engineers Code Style : Robust, optimized, extensive error handling","title":"JAF - \"Battle-Tested Solution\""},{"location":"jaf-comparison/#feature-comparison","text":"Feature Dotsuite JAF Query Language Simple strings: \"equals role admin\" S-expressions: [\"eq?\", \"@role\", \"admin\"] Path System Dot notation: \"user.name\" Advanced AST with regex, fuzzy, wildcards Evaluation Eager (with lazy QuerySet option) Lazy by default with streaming Data Sources In-memory collections Files, directories, stdin, compressed, infinite Set Operations Basic (union, intersection, difference) Index-preserving with collection tracking Pipeline Composition Separate tools (dotpipe) Built-in method chaining Memory Usage Loads data into memory Streaming generators Error Handling Basic Comprehensive with custom exceptions Performance Educational focus Optimized for production Dependencies Minimal Optional advanced libraries","title":"Feature Comparison"},{"location":"jaf-comparison/#conceptual-alignment","text":"Both projects share core concepts but implement them differently:","title":"Conceptual Alignment"},{"location":"jaf-comparison/#filtering-as-boolean-algebra","text":"Dotsuite : dotfilter with QuerySet for lazy evaluation JAF : FilteredStream with comprehensive boolean operations","title":"Filtering as Boolean Algebra"},{"location":"jaf-comparison/#pipeline-composition","text":"Dotsuite : dotpipe for transformation chains JAF : Built-in .filter().map().take() chaining","title":"Pipeline Composition"},{"location":"jaf-comparison/#path-navigation","text":"Dotsuite : dotget with simple dot notation JAF : Complex path AST with multiple navigation strategies","title":"Path Navigation"},{"location":"jaf-comparison/#when-to-use-which","text":"","title":"When to Use Which?"},{"location":"jaf-comparison/#use-dotsuite-when","text":"Learning data manipulation concepts Teaching programming or data structures Building prototypes You need simple, understandable code You want to modify/extend the implementation Working with small to medium datasets","title":"Use Dotsuite When:"},{"location":"jaf-comparison/#use-jaf-when","text":"Building production systems Processing large datasets or streams Need advanced features (regex paths, fuzzy matching) Require robust error handling Working with multiple data sources Need memory-efficient streaming","title":"Use JAF When:"},{"location":"jaf-comparison/#learning-path","text":"Start with Dotsuite to understand concepts: How path navigation works ( dotget ) Boolean filtering ( dotfilter ) Pipeline composition ( dotpipe ) Set operations on collections Graduate to JAF for production: Apply learned concepts at scale Leverage advanced features Handle real-world edge cases","title":"Learning Path"},{"location":"jaf-comparison/#code-examples","text":"","title":"Code Examples"},{"location":"jaf-comparison/#simple-filter-operation","text":"Dotsuite: from collections.dotfilter import filter_docs users = [{ \"name\" : \"Alice\" , \"age\" : 30 }, { \"name\" : \"Bob\" , \"age\" : 25 }] adults = filter_docs ( users , \"greater_than age 25\" ) JAF: from jaf import stream adults = stream ( \"users.jsonl\" ) \\ . filter ([ \"gt?\" , \"@age\" , 25 ]) \\ . evaluate ()","title":"Simple Filter Operation"},{"location":"jaf-comparison/#pipeline-composition_1","text":"Dotsuite: from shape.dotpipe import pipe from collections.dotfilter import filter_docs result = pipe ( data , lambda d : filter_docs ( d , \"equals status active\" ), lambda d : [ dotget ( doc , \"email\" ) for doc in d ] ) JAF: result = stream ( \"users.jsonl\" ) \\ . filter ([ \"eq?\" , \"@status\" , \"active\" ]) \\ . map ( \"@email\" ) \\ . evaluate ()","title":"Pipeline Composition"},{"location":"jaf-comparison/#integration","text":"Both projects can work together: Learn with Dotsuite : Understand the concepts Prototype with Dotsuite : Quick implementations Production with JAF : Scale when ready Contribute back : Share learnings with both communities","title":"Integration"},{"location":"jaf-comparison/#summary","text":"Dotsuite and JAF are complementary projects: - Dotsuite teaches the \"why\" and \"how\" through simplicity - JAF provides the \"what\" for production use Together, they form a complete ecosystem from learning to production.","title":"Summary"},{"location":"philosophy/","text":"The Philosophy of the Dot Universe \u00b6 It always starts with a simple problem. You have a nested dictionary or a JSON payload, and you need to get a value buried deep inside. You write data['user']['contacts'][0]['email'] and you pray that no key or index is missing along the way, lest your program crash. This leads to brittle, defensive code. The first, obvious solution is a helper function. This is where our story begins. What started as a single, humble function, dotget , evolved through a series of questions and insights into a complete, coherent, and powerful ecosystem for manipulating data structures. This is the story of that evolution\u2014a journey in API design guided by the principles of purity, pedagogy, and the principle of least power. Part I: The Single Document - The Axis of \"Depth\" \u00b6 Mastering operations inside a single, complex document is the foundation of the entire ecosystem. We discovered that this \"per-document intelligence\" rests on two fundamental axes: Addressing (finding data) and Action (changing data). The Addressing Layer ( dotpath ) \u00b6 This is the bedrock. It answers the question: \"WHAT is the value at a given location?\" The entire addressing layer is consolidated into a single, powerful, and extensible engine: dotpath . It is not just a tool, but a simple, extensible machine. Its intelligence lives within small, self-contained, \"expert\" components ( PathSegment classes) that can be added, removed, or replaced. dotpath provides a rich, JSONPath-inspired syntax with features like: - Exact selectors : users.0.name - Wildcards : users.*.name - Slices : users[0:5] - Recursive descent : **.name - Filters/Predicates : books[?(@.price < 10)] - Extensibility : The engine can be taught new syntax, like fuzzy key matching, by registering new segment parsers. While dotpath is powerful, many tools in the ecosystem intentionally remain simple and self-contained. For example, dotget is just a few lines of code you're encouraged to copy rather than import - embodying the \"steal this code\" philosophy. The Action Layer (Manipulation) \u00b6 This pillar answers the question: \"HOW should this document be changed?\" It uses the Addressing Layer ( dotpath ) to find where to act. It is built on the principle of immutability\u2014always returning a modified copy. dotmod : Provides the verbs for direct, single modifications ( set , delete ). dotbatch : Provides the transactional capability to apply a sequence of dotmod changes atomically. dotpipe : Transforms a document's structure, reshaping it into something new (e.g., creating a simplified \"view model\"). Part II: Collections of Documents - The Axis of \"Breadth\" \u00b6 With a complete toolkit for single documents, we can now operate on collections, often represented as a stream of documents like in a JSONL file. dotquery : A Logic Engine for Collections \u00b6 dotquery filters a collection. It answers the question: \"Which documents in this collection match a set of logical rules?\" Its power comes from using dotpath to extract values and then applying logical conditions to them. It features a lazy, chainable QuerySet API that allows for building complex queries efficiently from the command line. # Find all books that are either cheap (under 10) or written by \"Tolkien\", # and are in stock, then resolve the query to print the matching books. $ dotquery query \"(less price 10 or equals author 'Tolkien')\" books.json \\ | dotquery and \"equals in_stock true\" \\ | dotquery resolve dotrelate : A Relational Algebra for Collections \u00b6 While dotquery filters a collection, dotrelate transforms and combines multiple collections. It answers: \"How can these distinct collections be joined to create new, enriched data?\" The core operation is the join , which combines documents from two collections based on a shared key. It also supports other relational operations like union , diff , and project . # Enrich user data with their orders via a left join $ dotrelate join --left-on = \"id\" --right-on = \"user_id\" --how = \"left\" users.jsonl orders.jsonl The Big Picture: A Unified Architecture \u00b6 This journey reveals a coherent universe of tools, underpinned by a dual API (programmatic for developers, declarative CLI for users) and a philosophy of clean, single-purpose components. graph TD subgraph The_Dot_Universe [\"The Dot Notation Universe\"] subgraph Single_Doc [\"Part I: Per-Document Intelligence ('Depth')\"] direction TB subgraph Addressing_Layer [\"Addressing Layer\"] dotpath(\"dotpath<br>(The Extensible Path Engine)\") end subgraph Action_Layer [\"Action Layer\"] dotmod(\"dotmod / dotbatch<br>(Mutation)\") --> dotpipe(\"dotpipe<br>(Transformation)\") end end subgraph Collection_Ops [\"Part II: Collection Operations ('Breadth')\"] direction TB subgraph Filter_Branch [\"Filtering / Logic\"] dotquery(\"dotquery\") end subgraph Relate_Branch [\"Relating / Combining\"] dotrelate(\"dotrelate\") end end dotpath -- \"Provides paths for\" --> Action_Layer dotpath -- \"Provides paths for\" --> Filter_Branch Filter_Branch -- \"Filters collections for\" --> Relate_Branch end","title":"Philosophy"},{"location":"philosophy/#the-philosophy-of-the-dot-universe","text":"It always starts with a simple problem. You have a nested dictionary or a JSON payload, and you need to get a value buried deep inside. You write data['user']['contacts'][0]['email'] and you pray that no key or index is missing along the way, lest your program crash. This leads to brittle, defensive code. The first, obvious solution is a helper function. This is where our story begins. What started as a single, humble function, dotget , evolved through a series of questions and insights into a complete, coherent, and powerful ecosystem for manipulating data structures. This is the story of that evolution\u2014a journey in API design guided by the principles of purity, pedagogy, and the principle of least power.","title":"The Philosophy of the Dot Universe"},{"location":"philosophy/#part-i-the-single-document-the-axis-of-depth","text":"Mastering operations inside a single, complex document is the foundation of the entire ecosystem. We discovered that this \"per-document intelligence\" rests on two fundamental axes: Addressing (finding data) and Action (changing data).","title":"Part I: The Single Document - The Axis of \"Depth\""},{"location":"philosophy/#the-addressing-layer-dotpath","text":"This is the bedrock. It answers the question: \"WHAT is the value at a given location?\" The entire addressing layer is consolidated into a single, powerful, and extensible engine: dotpath . It is not just a tool, but a simple, extensible machine. Its intelligence lives within small, self-contained, \"expert\" components ( PathSegment classes) that can be added, removed, or replaced. dotpath provides a rich, JSONPath-inspired syntax with features like: - Exact selectors : users.0.name - Wildcards : users.*.name - Slices : users[0:5] - Recursive descent : **.name - Filters/Predicates : books[?(@.price < 10)] - Extensibility : The engine can be taught new syntax, like fuzzy key matching, by registering new segment parsers. While dotpath is powerful, many tools in the ecosystem intentionally remain simple and self-contained. For example, dotget is just a few lines of code you're encouraged to copy rather than import - embodying the \"steal this code\" philosophy.","title":"The Addressing Layer (dotpath)"},{"location":"philosophy/#the-action-layer-manipulation","text":"This pillar answers the question: \"HOW should this document be changed?\" It uses the Addressing Layer ( dotpath ) to find where to act. It is built on the principle of immutability\u2014always returning a modified copy. dotmod : Provides the verbs for direct, single modifications ( set , delete ). dotbatch : Provides the transactional capability to apply a sequence of dotmod changes atomically. dotpipe : Transforms a document's structure, reshaping it into something new (e.g., creating a simplified \"view model\").","title":"The Action Layer (Manipulation)"},{"location":"philosophy/#part-ii-collections-of-documents-the-axis-of-breadth","text":"With a complete toolkit for single documents, we can now operate on collections, often represented as a stream of documents like in a JSONL file.","title":"Part II: Collections of Documents - The Axis of \"Breadth\""},{"location":"philosophy/#dotquery-a-logic-engine-for-collections","text":"dotquery filters a collection. It answers the question: \"Which documents in this collection match a set of logical rules?\" Its power comes from using dotpath to extract values and then applying logical conditions to them. It features a lazy, chainable QuerySet API that allows for building complex queries efficiently from the command line. # Find all books that are either cheap (under 10) or written by \"Tolkien\", # and are in stock, then resolve the query to print the matching books. $ dotquery query \"(less price 10 or equals author 'Tolkien')\" books.json \\ | dotquery and \"equals in_stock true\" \\ | dotquery resolve","title":"dotquery: A Logic Engine for Collections"},{"location":"philosophy/#dotrelate-a-relational-algebra-for-collections","text":"While dotquery filters a collection, dotrelate transforms and combines multiple collections. It answers: \"How can these distinct collections be joined to create new, enriched data?\" The core operation is the join , which combines documents from two collections based on a shared key. It also supports other relational operations like union , diff , and project . # Enrich user data with their orders via a left join $ dotrelate join --left-on = \"id\" --right-on = \"user_id\" --how = \"left\" users.jsonl orders.jsonl","title":"dotrelate: A Relational Algebra for Collections"},{"location":"philosophy/#the-big-picture-a-unified-architecture","text":"This journey reveals a coherent universe of tools, underpinned by a dual API (programmatic for developers, declarative CLI for users) and a philosophy of clean, single-purpose components. graph TD subgraph The_Dot_Universe [\"The Dot Notation Universe\"] subgraph Single_Doc [\"Part I: Per-Document Intelligence ('Depth')\"] direction TB subgraph Addressing_Layer [\"Addressing Layer\"] dotpath(\"dotpath<br>(The Extensible Path Engine)\") end subgraph Action_Layer [\"Action Layer\"] dotmod(\"dotmod / dotbatch<br>(Mutation)\") --> dotpipe(\"dotpipe<br>(Transformation)\") end end subgraph Collection_Ops [\"Part II: Collection Operations ('Breadth')\"] direction TB subgraph Filter_Branch [\"Filtering / Logic\"] dotquery(\"dotquery\") end subgraph Relate_Branch [\"Relating / Combining\"] dotrelate(\"dotrelate\") end end dotpath -- \"Provides paths for\" --> Action_Layer dotpath -- \"Provides paths for\" --> Filter_Branch Filter_Branch -- \"Filters collections for\" --> Relate_Branch end","title":"The Big Picture: A Unified Architecture"},{"location":"proposal-collections-pillar/","text":"Proposal: The Three Pillars of the dot Ecosystem \u00b6 This document proposes a formal, three-pillar structure for the dot ecosystem. This model clarifies the purpose of each tool, establishes a clear pedagogical progression for users, and provides a robust framework for future development. The Core Idea: Depth, Truth, and Breadth \u00b6 The dot ecosystem is organized into three distinct pillars, each answering a fundamental question about data: The Addressing Pillar (Depth): Answers \"Where is the data?\" within a single document . The Truth Pillar: Answers \"Is this true?\" about a single document . The Collections Pillar (Breadth): Operates on a collection of documents to answer \"Which documents?\" or \"What is the new collection?\" . The Ecosystem Diagram \u00b6 This diagram provides a high-level overview of the entire ecosystem, showing the tools within each pillar and their progression from simple to powerful. +-------------------------+ | The `dot` Ecosystem | +-------------------------+ | +----------------------------+----------------------------+ | | | +-----------v-----------+ +-----------v-----------+ +-----------v-----------+ | Pillar 1: Addressing | | Pillar 2: Logic | | Pillar 3: Transform | | (Depth) | | (Truth) | | (Shape) | | \"Where is the data?\" | | \"Is this true?\" | | \"How does it change?\" | +-----------------------+ +-----------------------+ +-----------------------+ | | | Simple: `dotget` `dotexists` `dotpluck` (doc\u2192any) | | | Patterns: `dotstar` `dotequals` +-------------------+ | | | | Advanced: `dotselect` `dotany`/`dotall` `dotmod` (doc\u2192doc) `dotpipe` (doc\u2192any) | | | | Engine: `dotpath` `dotquery` `dotbatch` (batch/txn) Pillar 1: The Addressing Pillar (Depth) \u00b6 This pillar focuses on finding and extracting data from within a single document. dotget (Simple): The entry point. Extracts a value from a single, exact path. dotstar (Patterns): Introduces wildcards ( * ) to find multiple values. dotselect (Advanced): The workhorse. Uses the full dotpath engine to perform complex selections with filters, slices, and descendants. dotpath (Engine): The underlying path-parsing and resolution engine that is extensible and compositional, allowing for custom path segments and logic. The simpler operations ( dotget , dotstar , dotselect ) should not be built on top of dotpath , but implemented as simply as possible to avoid unnecessary complexity. However, conceptually, dotpath is the \"Turing-complete\" addressing engine of the ecosystem, allowing for arbitrary path expressions and logic. Pillar 2: The Truth Pillar \u00b6 This pillar focuses on asking true/false questions about a single document. dotexists (Simple Structure): The simplest question: does a path exist at all? dotequals (Simple Content): If a path exists, does it have a particular value? dotany / dotall (Quantifiers): The bridge to complexity. Applies a simple condition to multiple values found by a dotstar path. dotquery (Engine): The complete logic engine. Allows for building complex, compositional queries with AND/OR/NOT logic. Pillar 3: The Transformation Pillar (Shape) \u00b6 This pillar focuses on transforming the shape of a single document, answering \"How does it change?\" . All operations are immutable and compositional. dotpluck (Simple): Extracts zero or more values from a document. If the path is exact, returns a single value or none; if the path includes wildcards, returns a list of all matches. dotmod (Surgical): Performs a targeted, immutable modification to a document (e.g., set, delete, or update a value at a path). Designed for simple, direct edits\u2014easy for common cases, but limited in scope. dotpipe (Compositional): Composes multiple transformations, allowing for arbitrary mapping, restructuring, and function composition over a document. More general and powerful, but sometimes less ergonomic for simple edits than dotmod . All transformations can be piped, but dotmod and dotpipe are side-by-side: each is best for different user needs. dotbatch (Transactional): Applies a batch of modifications as a single transaction, enabling all-or-nothing guarantees and complex, multi-step updates. dotbatch can leverage both dotmod and dotpipe operations, and may support advanced features like rollback, validation, or atomicity. Collections: Lifting the Pillars to Streams \u00b6 The Collections layer extends the three pillars from single documents to streams or sets of documents (e.g., JSONL). It is divided into two wings: +-----------------------------+ | Collections (Breadth) | +-----------------------------+ | +-------+--------+ | | Boolean Wing Transforming Wing (Filtering) (Mapping/Relating) | | | | v v `dothas` (dotmod, dotpipe, dotbatch, dotpluck, ...) `dotfind` | `dotfilter` | | `dotrelate` (multi-collection, highest abstraction) The Boolean Wing is essential for collections: filtering, searching, and logical operations over sets of documents. Boolean algebra on collections is homomorphic to boolean logic on queries: e.g., the intersection of subsets x\u2081 and x\u2082 (from queries q\u2081 and q\u2082) is the same as applying (q\u2081 AND q\u2082) to the original collection. The Transforming Wing includes repeated application of single-document transforms (dotmod, dotpipe, dotbatch, dotpluck, etc.), but the highest-level operation is dotrelate , which operates over multiple collections and enables relational algebra (joins, unions, etc.). dotpipe in collections is analogous to a \"docview\"\u2014a new way of viewing or mapping your documents, but true database-style views and set operations are the domain of dotrelate . dotbatch at the collection level enables transactional or efficient batch operations across the entire set. Summary Table \u00b6 Pillar Single Document (Depth/Truth/Shape) Collections (Breadth) Addressing dotget, dotstar, dotselect, dotpath dotfind, dothas Logic dotequals, dotexists, dotany, dotall, dotquery dotfilter Transform dotpluck, dotmod, dotpipe, dotbatch dotpluck, dotmod, dotpipe, dotbatch, dotrelate Design Principles \u00b6 Compositionality: All operations can be composed, both within and across pillars. Immutability: All transformations are immutable; original data is never mutated. Pedagogical Progression: Each pillar and wing is organized from simple to advanced, making the ecosystem approachable for beginners and powerful for experts. Lifting: The collections layer is a lifting of the single-document pillars to operate over streams/sets, preserving the same semantics and compositionality. By adopting this formal structure, the dot ecosystem provides a highly consistent, predictable, and teachable set of tools for both single-document and collection-oriented data manipulation.","title":"Collections Pillar"},{"location":"proposal-collections-pillar/#proposal-the-three-pillars-of-the-dot-ecosystem","text":"This document proposes a formal, three-pillar structure for the dot ecosystem. This model clarifies the purpose of each tool, establishes a clear pedagogical progression for users, and provides a robust framework for future development.","title":"Proposal: The Three Pillars of the dot Ecosystem"},{"location":"proposal-collections-pillar/#the-core-idea-depth-truth-and-breadth","text":"The dot ecosystem is organized into three distinct pillars, each answering a fundamental question about data: The Addressing Pillar (Depth): Answers \"Where is the data?\" within a single document . The Truth Pillar: Answers \"Is this true?\" about a single document . The Collections Pillar (Breadth): Operates on a collection of documents to answer \"Which documents?\" or \"What is the new collection?\" .","title":"The Core Idea: Depth, Truth, and Breadth"},{"location":"proposal-collections-pillar/#the-ecosystem-diagram","text":"This diagram provides a high-level overview of the entire ecosystem, showing the tools within each pillar and their progression from simple to powerful. +-------------------------+ | The `dot` Ecosystem | +-------------------------+ | +----------------------------+----------------------------+ | | | +-----------v-----------+ +-----------v-----------+ +-----------v-----------+ | Pillar 1: Addressing | | Pillar 2: Logic | | Pillar 3: Transform | | (Depth) | | (Truth) | | (Shape) | | \"Where is the data?\" | | \"Is this true?\" | | \"How does it change?\" | +-----------------------+ +-----------------------+ +-----------------------+ | | | Simple: `dotget` `dotexists` `dotpluck` (doc\u2192any) | | | Patterns: `dotstar` `dotequals` +-------------------+ | | | | Advanced: `dotselect` `dotany`/`dotall` `dotmod` (doc\u2192doc) `dotpipe` (doc\u2192any) | | | | Engine: `dotpath` `dotquery` `dotbatch` (batch/txn)","title":"The Ecosystem Diagram"},{"location":"proposal-collections-pillar/#pillar-1-the-addressing-pillar-depth","text":"This pillar focuses on finding and extracting data from within a single document. dotget (Simple): The entry point. Extracts a value from a single, exact path. dotstar (Patterns): Introduces wildcards ( * ) to find multiple values. dotselect (Advanced): The workhorse. Uses the full dotpath engine to perform complex selections with filters, slices, and descendants. dotpath (Engine): The underlying path-parsing and resolution engine that is extensible and compositional, allowing for custom path segments and logic. The simpler operations ( dotget , dotstar , dotselect ) should not be built on top of dotpath , but implemented as simply as possible to avoid unnecessary complexity. However, conceptually, dotpath is the \"Turing-complete\" addressing engine of the ecosystem, allowing for arbitrary path expressions and logic.","title":"Pillar 1: The Addressing Pillar (Depth)"},{"location":"proposal-collections-pillar/#pillar-2-the-truth-pillar","text":"This pillar focuses on asking true/false questions about a single document. dotexists (Simple Structure): The simplest question: does a path exist at all? dotequals (Simple Content): If a path exists, does it have a particular value? dotany / dotall (Quantifiers): The bridge to complexity. Applies a simple condition to multiple values found by a dotstar path. dotquery (Engine): The complete logic engine. Allows for building complex, compositional queries with AND/OR/NOT logic.","title":"Pillar 2: The Truth Pillar"},{"location":"proposal-collections-pillar/#pillar-3-the-transformation-pillar-shape","text":"This pillar focuses on transforming the shape of a single document, answering \"How does it change?\" . All operations are immutable and compositional. dotpluck (Simple): Extracts zero or more values from a document. If the path is exact, returns a single value or none; if the path includes wildcards, returns a list of all matches. dotmod (Surgical): Performs a targeted, immutable modification to a document (e.g., set, delete, or update a value at a path). Designed for simple, direct edits\u2014easy for common cases, but limited in scope. dotpipe (Compositional): Composes multiple transformations, allowing for arbitrary mapping, restructuring, and function composition over a document. More general and powerful, but sometimes less ergonomic for simple edits than dotmod . All transformations can be piped, but dotmod and dotpipe are side-by-side: each is best for different user needs. dotbatch (Transactional): Applies a batch of modifications as a single transaction, enabling all-or-nothing guarantees and complex, multi-step updates. dotbatch can leverage both dotmod and dotpipe operations, and may support advanced features like rollback, validation, or atomicity.","title":"Pillar 3: The Transformation Pillar (Shape)"},{"location":"proposal-collections-pillar/#collections-lifting-the-pillars-to-streams","text":"The Collections layer extends the three pillars from single documents to streams or sets of documents (e.g., JSONL). It is divided into two wings: +-----------------------------+ | Collections (Breadth) | +-----------------------------+ | +-------+--------+ | | Boolean Wing Transforming Wing (Filtering) (Mapping/Relating) | | | | v v `dothas` (dotmod, dotpipe, dotbatch, dotpluck, ...) `dotfind` | `dotfilter` | | `dotrelate` (multi-collection, highest abstraction) The Boolean Wing is essential for collections: filtering, searching, and logical operations over sets of documents. Boolean algebra on collections is homomorphic to boolean logic on queries: e.g., the intersection of subsets x\u2081 and x\u2082 (from queries q\u2081 and q\u2082) is the same as applying (q\u2081 AND q\u2082) to the original collection. The Transforming Wing includes repeated application of single-document transforms (dotmod, dotpipe, dotbatch, dotpluck, etc.), but the highest-level operation is dotrelate , which operates over multiple collections and enables relational algebra (joins, unions, etc.). dotpipe in collections is analogous to a \"docview\"\u2014a new way of viewing or mapping your documents, but true database-style views and set operations are the domain of dotrelate . dotbatch at the collection level enables transactional or efficient batch operations across the entire set.","title":"Collections: Lifting the Pillars to Streams"},{"location":"proposal-collections-pillar/#summary-table","text":"Pillar Single Document (Depth/Truth/Shape) Collections (Breadth) Addressing dotget, dotstar, dotselect, dotpath dotfind, dothas Logic dotequals, dotexists, dotany, dotall, dotquery dotfilter Transform dotpluck, dotmod, dotpipe, dotbatch dotpluck, dotmod, dotpipe, dotbatch, dotrelate","title":"Summary Table"},{"location":"proposal-collections-pillar/#design-principles","text":"Compositionality: All operations can be composed, both within and across pillars. Immutability: All transformations are immutable; original data is never mutated. Pedagogical Progression: Each pillar and wing is organized from simple to advanced, making the ecosystem approachable for beginners and powerful for experts. Lifting: The collections layer is a lifting of the single-document pillars to operate over streams/sets, preserving the same semantics and compositionality. By adopting this formal structure, the dot ecosystem provides a highly consistent, predictable, and teachable set of tools for both single-document and collection-oriented data manipulation.","title":"Design Principles"},{"location":"tools/collections/dotfilter/","text":"dotfilter \u00b6 Boolean algebra on document collections - lifting single-document logic to sets Overview \u00b6 dotfilter represents the Collections dimension's core capability: lifting Truth pillar operations to work on collections. It filters documents based on boolean queries while providing lazy evaluation through QuerySet operations. This tool bridges single-document validation (Truth pillar) with collection-level operations, enabling set operations like union, intersection, and difference on filtered results. Installation \u00b6 # As part of dotsuite pip install dotsuite # Or from source cd src/collections/dotfilter pip install -e . Core Functions \u00b6 filter_docs(docs, query_str) \u00b6 Filter a collection of documents using a boolean query. from collections.dotfilter.core import filter_docs docs = [ { \"user\" : \"alice\" , \"role\" : \"admin\" , \"active\" : True }, { \"user\" : \"bob\" , \"role\" : \"user\" , \"active\" : True }, { \"user\" : \"charlie\" , \"role\" : \"admin\" , \"active\" : False } ] # Filter using query strings admins = filter_docs ( docs , \"equals role admin\" ) # Returns: [{\"user\": \"alice\", ...}, {\"user\": \"charlie\", ...}] active_admins = filter_docs ( docs , \"equals role admin and equals active true\" ) # Returns: [{\"user\": \"alice\", ...}] filter_by_path(docs, path, value) \u00b6 Simple filtering by path equality. from collections.dotfilter.core import filter_by_path # Direct path filtering active_users = filter_by_path ( docs , \"active\" , True ) # Returns: [{\"user\": \"alice\", ...}, {\"user\": \"bob\", ...}] admin_users = filter_by_path ( docs , \"role\" , \"admin\" ) # Returns: [{\"user\": \"alice\", ...}, {\"user\": \"charlie\", ...}] QuerySet Class \u00b6 Lazy evaluation with set operations. from collections.dotfilter.core import QuerySet # Create QuerySets (lazy - no evaluation yet) all_docs = QuerySet ( docs ) admins = all_docs . filter ( \"equals role admin\" ) active = all_docs . filter ( \"equals active true\" ) # Set operations (still lazy) active_admins = admins . intersection ( active ) admin_or_active = admins . union ( active ) inactive_admins = admins . difference ( active ) # Evaluate when needed result = list ( active_admins ) # Now it evaluates Command Line Usage \u00b6 # Filter JSON documents cat users.json | dotfilter \"equals role admin\" # Complex queries cat users.json | dotfilter \"equals active true and not equals role guest\" # Simple path filtering cat users.json | dotfilter --path role --value admin # Count results cat users.json | dotfilter \"equals active true\" --count Common Use Cases \u00b6 1. User Management \u00b6 Filter users based on roles and status: users = [ { \"id\" : 1 , \"name\" : \"Alice\" , \"role\" : \"admin\" , \"active\" : True , \"login_count\" : 42 }, { \"id\" : 2 , \"name\" : \"Bob\" , \"role\" : \"user\" , \"active\" : True , \"login_count\" : 5 }, { \"id\" : 3 , \"name\" : \"Charlie\" , \"role\" : \"admin\" , \"active\" : False , \"login_count\" : 0 }, { \"id\" : 4 , \"name\" : \"Diana\" , \"role\" : \"moderator\" , \"active\" : True , \"login_count\" : 15 } ] # Find active admins active_admins = filter_docs ( users , \"equals role admin and equals active true\" ) # Find users who need activation inactive = filter_docs ( users , \"equals active false\" ) # Find power users power_users = filter_docs ( users , \"greater_than login_count 10\" ) 2. Configuration Validation \u00b6 Check configurations across multiple environments: configs = [ { \"env\" : \"prod\" , \"debug\" : False , \"ssl\" : True , \"port\" : 443 }, { \"env\" : \"staging\" , \"debug\" : True , \"ssl\" : True , \"port\" : 443 }, { \"env\" : \"dev\" , \"debug\" : True , \"ssl\" : False , \"port\" : 8080 } ] # Find misconfigured environments issues = filter_docs ( configs , \"equals debug true and equals env prod\" ) if issues : print ( \"WARNING: Debug enabled in production!\" ) # Find secure environments secure = filter_docs ( configs , \"equals ssl true\" ) 3. Log Analysis \u00b6 Filter log entries: logs = [ { \"timestamp\" : \"2024-01-01T10:00:00\" , \"level\" : \"ERROR\" , \"service\" : \"api\" , \"message\" : \"Connection failed\" }, { \"timestamp\" : \"2024-01-01T10:01:00\" , \"level\" : \"INFO\" , \"service\" : \"api\" , \"message\" : \"Request processed\" }, { \"timestamp\" : \"2024-01-01T10:02:00\" , \"level\" : \"ERROR\" , \"service\" : \"db\" , \"message\" : \"Query timeout\" }, { \"timestamp\" : \"2024-01-01T10:03:00\" , \"level\" : \"WARN\" , \"service\" : \"api\" , \"message\" : \"Slow response\" } ] # Find all errors errors = filter_docs ( logs , \"equals level ERROR\" ) # Find API errors specifically api_errors = filter_docs ( logs , \"equals level ERROR and equals service api\" ) # Find non-info logs important = filter_docs ( logs , \"not equals level INFO\" ) 4. Lazy Set Operations \u00b6 Combine filters efficiently: products = QuerySet ([ { \"name\" : \"Laptop\" , \"price\" : 999 , \"category\" : \"electronics\" , \"in_stock\" : True }, { \"name\" : \"Mouse\" , \"price\" : 25 , \"category\" : \"electronics\" , \"in_stock\" : True }, { \"name\" : \"Desk\" , \"price\" : 299 , \"category\" : \"furniture\" , \"in_stock\" : False }, { \"name\" : \"Chair\" , \"price\" : 199 , \"category\" : \"furniture\" , \"in_stock\" : True } ]) # Define filters (lazy) electronics = products . filter ( \"equals category electronics\" ) in_stock = products . filter ( \"equals in_stock true\" ) affordable = products . filter ( \"less_than price 200\" ) # Combine filters (still lazy) available_electronics = electronics . intersection ( in_stock ) budget_items = affordable . intersection ( in_stock ) # Only evaluates when needed for item in available_electronics : print ( f \" { item [ 'name' ] } : $ { item [ 'price' ] } \" ) Query Language \u00b6 dotfilter uses the query language from dotquery : Comparison Operators \u00b6 equals PATH VALUE - Check equality not_equals PATH VALUE - Check inequality greater_than PATH VALUE - Numeric comparison less_than PATH VALUE - Numeric comparison contains PATH VALUE - String/list containment matches PATH PATTERN - Regex matching Logical Operators \u00b6 and - Both conditions must be true or - Either condition must be true not - Negate a condition Examples \u00b6 # Simple equality \"equals status active\" # Multiple conditions \"equals role admin and equals active true\" # Complex logic \"(equals category electronics or equals category computers) and less_than price 1000\" # Negation \"not equals status deleted\" Philosophy \u00b6 dotfilter embodies the Collections dimension philosophy: 1. Homomorphic Lifting : Truth operations on documents lift to set operations on collections 2. Lazy Evaluation : QuerySets defer computation until needed 3. Composability : Set operations combine naturally 4. Simplicity : Complex filtering through simple boolean algebra Comparison with Other Tools \u00b6 Tool Scope Purpose Returns dotquery Single document Boolean evaluation True/False dotfilter Collection Filter by boolean query Filtered documents dotany Collection Existential check True/False dotall Collection Universal check True/False Performance Notes \u00b6 Lazy Evaluation : QuerySets don't evaluate until iteration Short-Circuit : Boolean operators short-circuit when possible Memory Efficient : Streaming evaluation for large collections Set Operations : Optimized for common patterns Production Implementation \u00b6 For a production-ready implementation with advanced features, see JAF (Just Another Flow) , which extends these concepts with: - Streaming evaluation for large datasets - S-expression query language - Advanced path operations (regex, fuzzy matching) - Pipeline composition similar to dotpipe - Index-preserving result sets See Also \u00b6 dotquery - Single-document boolean queries dotany - Check if any document matches dotall - Check if all documents match dotrelate - Relational operations on collections","title":"dotfilter"},{"location":"tools/collections/dotfilter/#dotfilter","text":"Boolean algebra on document collections - lifting single-document logic to sets","title":"dotfilter"},{"location":"tools/collections/dotfilter/#overview","text":"dotfilter represents the Collections dimension's core capability: lifting Truth pillar operations to work on collections. It filters documents based on boolean queries while providing lazy evaluation through QuerySet operations. This tool bridges single-document validation (Truth pillar) with collection-level operations, enabling set operations like union, intersection, and difference on filtered results.","title":"Overview"},{"location":"tools/collections/dotfilter/#installation","text":"# As part of dotsuite pip install dotsuite # Or from source cd src/collections/dotfilter pip install -e .","title":"Installation"},{"location":"tools/collections/dotfilter/#core-functions","text":"","title":"Core Functions"},{"location":"tools/collections/dotfilter/#filter_docsdocs-query_str","text":"Filter a collection of documents using a boolean query. from collections.dotfilter.core import filter_docs docs = [ { \"user\" : \"alice\" , \"role\" : \"admin\" , \"active\" : True }, { \"user\" : \"bob\" , \"role\" : \"user\" , \"active\" : True }, { \"user\" : \"charlie\" , \"role\" : \"admin\" , \"active\" : False } ] # Filter using query strings admins = filter_docs ( docs , \"equals role admin\" ) # Returns: [{\"user\": \"alice\", ...}, {\"user\": \"charlie\", ...}] active_admins = filter_docs ( docs , \"equals role admin and equals active true\" ) # Returns: [{\"user\": \"alice\", ...}]","title":"filter_docs(docs, query_str)"},{"location":"tools/collections/dotfilter/#filter_by_pathdocs-path-value","text":"Simple filtering by path equality. from collections.dotfilter.core import filter_by_path # Direct path filtering active_users = filter_by_path ( docs , \"active\" , True ) # Returns: [{\"user\": \"alice\", ...}, {\"user\": \"bob\", ...}] admin_users = filter_by_path ( docs , \"role\" , \"admin\" ) # Returns: [{\"user\": \"alice\", ...}, {\"user\": \"charlie\", ...}]","title":"filter_by_path(docs, path, value)"},{"location":"tools/collections/dotfilter/#queryset-class","text":"Lazy evaluation with set operations. from collections.dotfilter.core import QuerySet # Create QuerySets (lazy - no evaluation yet) all_docs = QuerySet ( docs ) admins = all_docs . filter ( \"equals role admin\" ) active = all_docs . filter ( \"equals active true\" ) # Set operations (still lazy) active_admins = admins . intersection ( active ) admin_or_active = admins . union ( active ) inactive_admins = admins . difference ( active ) # Evaluate when needed result = list ( active_admins ) # Now it evaluates","title":"QuerySet Class"},{"location":"tools/collections/dotfilter/#command-line-usage","text":"# Filter JSON documents cat users.json | dotfilter \"equals role admin\" # Complex queries cat users.json | dotfilter \"equals active true and not equals role guest\" # Simple path filtering cat users.json | dotfilter --path role --value admin # Count results cat users.json | dotfilter \"equals active true\" --count","title":"Command Line Usage"},{"location":"tools/collections/dotfilter/#common-use-cases","text":"","title":"Common Use Cases"},{"location":"tools/collections/dotfilter/#1-user-management","text":"Filter users based on roles and status: users = [ { \"id\" : 1 , \"name\" : \"Alice\" , \"role\" : \"admin\" , \"active\" : True , \"login_count\" : 42 }, { \"id\" : 2 , \"name\" : \"Bob\" , \"role\" : \"user\" , \"active\" : True , \"login_count\" : 5 }, { \"id\" : 3 , \"name\" : \"Charlie\" , \"role\" : \"admin\" , \"active\" : False , \"login_count\" : 0 }, { \"id\" : 4 , \"name\" : \"Diana\" , \"role\" : \"moderator\" , \"active\" : True , \"login_count\" : 15 } ] # Find active admins active_admins = filter_docs ( users , \"equals role admin and equals active true\" ) # Find users who need activation inactive = filter_docs ( users , \"equals active false\" ) # Find power users power_users = filter_docs ( users , \"greater_than login_count 10\" )","title":"1. User Management"},{"location":"tools/collections/dotfilter/#2-configuration-validation","text":"Check configurations across multiple environments: configs = [ { \"env\" : \"prod\" , \"debug\" : False , \"ssl\" : True , \"port\" : 443 }, { \"env\" : \"staging\" , \"debug\" : True , \"ssl\" : True , \"port\" : 443 }, { \"env\" : \"dev\" , \"debug\" : True , \"ssl\" : False , \"port\" : 8080 } ] # Find misconfigured environments issues = filter_docs ( configs , \"equals debug true and equals env prod\" ) if issues : print ( \"WARNING: Debug enabled in production!\" ) # Find secure environments secure = filter_docs ( configs , \"equals ssl true\" )","title":"2. Configuration Validation"},{"location":"tools/collections/dotfilter/#3-log-analysis","text":"Filter log entries: logs = [ { \"timestamp\" : \"2024-01-01T10:00:00\" , \"level\" : \"ERROR\" , \"service\" : \"api\" , \"message\" : \"Connection failed\" }, { \"timestamp\" : \"2024-01-01T10:01:00\" , \"level\" : \"INFO\" , \"service\" : \"api\" , \"message\" : \"Request processed\" }, { \"timestamp\" : \"2024-01-01T10:02:00\" , \"level\" : \"ERROR\" , \"service\" : \"db\" , \"message\" : \"Query timeout\" }, { \"timestamp\" : \"2024-01-01T10:03:00\" , \"level\" : \"WARN\" , \"service\" : \"api\" , \"message\" : \"Slow response\" } ] # Find all errors errors = filter_docs ( logs , \"equals level ERROR\" ) # Find API errors specifically api_errors = filter_docs ( logs , \"equals level ERROR and equals service api\" ) # Find non-info logs important = filter_docs ( logs , \"not equals level INFO\" )","title":"3. Log Analysis"},{"location":"tools/collections/dotfilter/#4-lazy-set-operations","text":"Combine filters efficiently: products = QuerySet ([ { \"name\" : \"Laptop\" , \"price\" : 999 , \"category\" : \"electronics\" , \"in_stock\" : True }, { \"name\" : \"Mouse\" , \"price\" : 25 , \"category\" : \"electronics\" , \"in_stock\" : True }, { \"name\" : \"Desk\" , \"price\" : 299 , \"category\" : \"furniture\" , \"in_stock\" : False }, { \"name\" : \"Chair\" , \"price\" : 199 , \"category\" : \"furniture\" , \"in_stock\" : True } ]) # Define filters (lazy) electronics = products . filter ( \"equals category electronics\" ) in_stock = products . filter ( \"equals in_stock true\" ) affordable = products . filter ( \"less_than price 200\" ) # Combine filters (still lazy) available_electronics = electronics . intersection ( in_stock ) budget_items = affordable . intersection ( in_stock ) # Only evaluates when needed for item in available_electronics : print ( f \" { item [ 'name' ] } : $ { item [ 'price' ] } \" )","title":"4. Lazy Set Operations"},{"location":"tools/collections/dotfilter/#query-language","text":"dotfilter uses the query language from dotquery :","title":"Query Language"},{"location":"tools/collections/dotfilter/#comparison-operators","text":"equals PATH VALUE - Check equality not_equals PATH VALUE - Check inequality greater_than PATH VALUE - Numeric comparison less_than PATH VALUE - Numeric comparison contains PATH VALUE - String/list containment matches PATH PATTERN - Regex matching","title":"Comparison Operators"},{"location":"tools/collections/dotfilter/#logical-operators","text":"and - Both conditions must be true or - Either condition must be true not - Negate a condition","title":"Logical Operators"},{"location":"tools/collections/dotfilter/#examples","text":"# Simple equality \"equals status active\" # Multiple conditions \"equals role admin and equals active true\" # Complex logic \"(equals category electronics or equals category computers) and less_than price 1000\" # Negation \"not equals status deleted\"","title":"Examples"},{"location":"tools/collections/dotfilter/#philosophy","text":"dotfilter embodies the Collections dimension philosophy: 1. Homomorphic Lifting : Truth operations on documents lift to set operations on collections 2. Lazy Evaluation : QuerySets defer computation until needed 3. Composability : Set operations combine naturally 4. Simplicity : Complex filtering through simple boolean algebra","title":"Philosophy"},{"location":"tools/collections/dotfilter/#comparison-with-other-tools","text":"Tool Scope Purpose Returns dotquery Single document Boolean evaluation True/False dotfilter Collection Filter by boolean query Filtered documents dotany Collection Existential check True/False dotall Collection Universal check True/False","title":"Comparison with Other Tools"},{"location":"tools/collections/dotfilter/#performance-notes","text":"Lazy Evaluation : QuerySets don't evaluate until iteration Short-Circuit : Boolean operators short-circuit when possible Memory Efficient : Streaming evaluation for large collections Set Operations : Optimized for common patterns","title":"Performance Notes"},{"location":"tools/collections/dotfilter/#production-implementation","text":"For a production-ready implementation with advanced features, see JAF (Just Another Flow) , which extends these concepts with: - Streaming evaluation for large datasets - S-expression query language - Advanced path operations (regex, fuzzy matching) - Pipeline composition similar to dotpipe - Index-preserving result sets","title":"Production Implementation"},{"location":"tools/collections/dotfilter/#see-also","text":"dotquery - Single-document boolean queries dotany - Check if any document matches dotall - Check if all documents match dotrelate - Relational operations on collections","title":"See Also"},{"location":"tools/collections/dotrelate/","text":"dotrelate \u00b6 Relational operations for collections of documents Part of the Collections pillar, dotrelate brings fundamental relational algebra operations to JSON-like data structures, enabling SQL-like operations on document collections. Overview \u00b6 dotrelate implements core relational operations that work with collections of documents (dictionaries). It provides a functional, composable approach to combining and transforming data from multiple sources. Core Operations \u00b6 Joins \u00b6 left_join(left, right, left_on, right_on) \u00b6 Performs a left outer join, preserving all items from the left collection. from collections.dotrelate import left_join users = [ { \"id\" : 1 , \"name\" : \"Alice\" }, { \"id\" : 2 , \"name\" : \"Bob\" }, { \"id\" : 3 , \"name\" : \"Charlie\" } ] orders = [ { \"user_id\" : 1 , \"product\" : \"Book\" }, { \"user_id\" : 1 , \"product\" : \"Pen\" } ] result = list ( left_join ( users , orders , \"id\" , \"user_id\" )) # [ # {\"id\": 1, \"name\": \"Alice\", \"user_id\": 1, \"product\": \"Book\"}, # {\"id\": 1, \"name\": \"Alice\", \"user_id\": 1, \"product\": \"Pen\"}, # {\"id\": 2, \"name\": \"Bob\"}, # {\"id\": 3, \"name\": \"Charlie\"} # ] inner_join(left, right, left_on, right_on) \u00b6 Returns only items where matches exist in both collections. from collections.dotrelate import inner_join result = list ( inner_join ( users , orders , \"id\" , \"user_id\" )) # Only Alice appears (she has orders) # [ # {\"id\": 1, \"name\": \"Alice\", \"user_id\": 1, \"product\": \"Book\"}, # {\"id\": 1, \"name\": \"Alice\", \"user_id\": 1, \"product\": \"Pen\"} # ] Projection \u00b6 project(collection, fields) \u00b6 Selects specific fields from each document. from collections.dotrelate import project data = [ { \"id\" : 1 , \"name\" : \"Alice\" , \"age\" : 30 , \"city\" : \"NYC\" }, { \"id\" : 2 , \"name\" : \"Bob\" , \"age\" : 25 , \"city\" : \"LA\" } ] result = list ( project ( data , [ \"name\" , \"age\" ])) # [ # {\"name\": \"Alice\", \"age\": 30}, # {\"name\": \"Bob\", \"age\": 25} # ] Set Operations \u00b6 union(left, right) \u00b6 Concatenates two collections (preserves duplicates). from collections.dotrelate import union set1 = [{ \"id\" : 1 }, { \"id\" : 2 }] set2 = [{ \"id\" : 3 }, { \"id\" : 4 }] result = list ( union ( set1 , set2 )) # [{\"id\": 1}, {\"id\": 2}, {\"id\": 3}, {\"id\": 4}] set_difference(left, right) \u00b6 Returns items in left that don't exist in right. from collections.dotrelate import set_difference all_users = [ { \"id\" : 1 , \"name\" : \"Alice\" }, { \"id\" : 2 , \"name\" : \"Bob\" }, { \"id\" : 3 , \"name\" : \"Charlie\" } ] active_users = [ { \"id\" : 1 , \"name\" : \"Alice\" } ] inactive = list ( set_difference ( all_users , active_users )) # [{\"id\": 2, \"name\": \"Bob\"}, {\"id\": 3, \"name\": \"Charlie\"}] Real-World Examples \u00b6 User Order Analysis \u00b6 Combine user data with their orders and extract relevant fields: users = [ { \"user_id\" : 1 , \"name\" : \"Alice\" , \"email\" : \"alice@example.com\" }, { \"user_id\" : 2 , \"name\" : \"Bob\" , \"email\" : \"bob@example.com\" } ] orders = [ { \"order_id\" : 101 , \"user_id\" : 1 , \"amount\" : 50.00 }, { \"order_id\" : 102 , \"user_id\" : 1 , \"amount\" : 30.00 } ] # Join users with orders user_orders = list ( left_join ( users , orders , \"user_id\" , \"user_id\" )) # Project just the fields we need summary = list ( project ( user_orders , [ \"name\" , \"order_id\" , \"amount\" ])) Data Deduplication \u00b6 Remove duplicates from a dataset: all_records = [ { \"id\" : 1 , \"email\" : \"alice@example.com\" }, { \"id\" : 2 , \"email\" : \"bob@example.com\" }, { \"id\" : 1 , \"email\" : \"alice@example.com\" }, # Duplicate ] seen = [{ \"id\" : 1 , \"email\" : \"alice@example.com\" }] unique = list ( set_difference ( all_records , seen )) Mathematical Foundation \u00b6 dotrelate implements operations from relational algebra: Join (\u22c8) : Combines relations based on common attributes Projection (\u03c0) : Selects columns from a relation Union (\u222a) : Set union of two relations Difference (-) : Set difference between relations These operations form a complete algebra for querying and transforming relational data. Integration with Other Tools \u00b6 dotrelate works seamlessly with other dotsuite tools: from collections.dotrelate import left_join , project from collections.dotfilter import dotfilter from truth.dotquery import Query # Filter users before joining active_users = dotfilter ( users , Query ( \"status equals active\" )) # Join with orders user_orders = left_join ( active_users , orders , \"id\" , \"user_id\" ) # Project specific fields result = project ( user_orders , [ \"name\" , \"product\" , \"amount\" ]) CLI Usage \u00b6 # Join two JSONL files dotrelate join --left users.jsonl --right orders.jsonl \\ --left-on id --right-on user_id > joined.jsonl # Project specific fields dotrelate project --fields name,email < users.jsonl # Union two files dotrelate union file1.jsonl file2.jsonl > combined.jsonl Related Tools \u00b6 dotfilter : Filter collections before joining dotquery : Create complex join conditions jsonl-algebra : Production-ready relational operations Theory and Motivation \u00b6 Relational operations are fundamental to data manipulation. By bringing these operations to document-oriented data, dotrelate bridges the gap between: Structured (SQL) and semi-structured (JSON) data paradigms Set theory and practical data processing Mathematical rigor and developer ergonomics The tool demonstrates that relational algebra's elegance extends beyond traditional databases to any collection of structured documents. For more extensive relational operations and optimizations, see the jsonl-algebra project, which provides a complete implementation of relational algebra for JSONL data.","title":"dotrelate"},{"location":"tools/collections/dotrelate/#dotrelate","text":"Relational operations for collections of documents Part of the Collections pillar, dotrelate brings fundamental relational algebra operations to JSON-like data structures, enabling SQL-like operations on document collections.","title":"dotrelate"},{"location":"tools/collections/dotrelate/#overview","text":"dotrelate implements core relational operations that work with collections of documents (dictionaries). It provides a functional, composable approach to combining and transforming data from multiple sources.","title":"Overview"},{"location":"tools/collections/dotrelate/#core-operations","text":"","title":"Core Operations"},{"location":"tools/collections/dotrelate/#joins","text":"","title":"Joins"},{"location":"tools/collections/dotrelate/#left_joinleft-right-left_on-right_on","text":"Performs a left outer join, preserving all items from the left collection. from collections.dotrelate import left_join users = [ { \"id\" : 1 , \"name\" : \"Alice\" }, { \"id\" : 2 , \"name\" : \"Bob\" }, { \"id\" : 3 , \"name\" : \"Charlie\" } ] orders = [ { \"user_id\" : 1 , \"product\" : \"Book\" }, { \"user_id\" : 1 , \"product\" : \"Pen\" } ] result = list ( left_join ( users , orders , \"id\" , \"user_id\" )) # [ # {\"id\": 1, \"name\": \"Alice\", \"user_id\": 1, \"product\": \"Book\"}, # {\"id\": 1, \"name\": \"Alice\", \"user_id\": 1, \"product\": \"Pen\"}, # {\"id\": 2, \"name\": \"Bob\"}, # {\"id\": 3, \"name\": \"Charlie\"} # ]","title":"left_join(left, right, left_on, right_on)"},{"location":"tools/collections/dotrelate/#inner_joinleft-right-left_on-right_on","text":"Returns only items where matches exist in both collections. from collections.dotrelate import inner_join result = list ( inner_join ( users , orders , \"id\" , \"user_id\" )) # Only Alice appears (she has orders) # [ # {\"id\": 1, \"name\": \"Alice\", \"user_id\": 1, \"product\": \"Book\"}, # {\"id\": 1, \"name\": \"Alice\", \"user_id\": 1, \"product\": \"Pen\"} # ]","title":"inner_join(left, right, left_on, right_on)"},{"location":"tools/collections/dotrelate/#projection","text":"","title":"Projection"},{"location":"tools/collections/dotrelate/#projectcollection-fields","text":"Selects specific fields from each document. from collections.dotrelate import project data = [ { \"id\" : 1 , \"name\" : \"Alice\" , \"age\" : 30 , \"city\" : \"NYC\" }, { \"id\" : 2 , \"name\" : \"Bob\" , \"age\" : 25 , \"city\" : \"LA\" } ] result = list ( project ( data , [ \"name\" , \"age\" ])) # [ # {\"name\": \"Alice\", \"age\": 30}, # {\"name\": \"Bob\", \"age\": 25} # ]","title":"project(collection, fields)"},{"location":"tools/collections/dotrelate/#set-operations","text":"","title":"Set Operations"},{"location":"tools/collections/dotrelate/#unionleft-right","text":"Concatenates two collections (preserves duplicates). from collections.dotrelate import union set1 = [{ \"id\" : 1 }, { \"id\" : 2 }] set2 = [{ \"id\" : 3 }, { \"id\" : 4 }] result = list ( union ( set1 , set2 )) # [{\"id\": 1}, {\"id\": 2}, {\"id\": 3}, {\"id\": 4}]","title":"union(left, right)"},{"location":"tools/collections/dotrelate/#set_differenceleft-right","text":"Returns items in left that don't exist in right. from collections.dotrelate import set_difference all_users = [ { \"id\" : 1 , \"name\" : \"Alice\" }, { \"id\" : 2 , \"name\" : \"Bob\" }, { \"id\" : 3 , \"name\" : \"Charlie\" } ] active_users = [ { \"id\" : 1 , \"name\" : \"Alice\" } ] inactive = list ( set_difference ( all_users , active_users )) # [{\"id\": 2, \"name\": \"Bob\"}, {\"id\": 3, \"name\": \"Charlie\"}]","title":"set_difference(left, right)"},{"location":"tools/collections/dotrelate/#real-world-examples","text":"","title":"Real-World Examples"},{"location":"tools/collections/dotrelate/#user-order-analysis","text":"Combine user data with their orders and extract relevant fields: users = [ { \"user_id\" : 1 , \"name\" : \"Alice\" , \"email\" : \"alice@example.com\" }, { \"user_id\" : 2 , \"name\" : \"Bob\" , \"email\" : \"bob@example.com\" } ] orders = [ { \"order_id\" : 101 , \"user_id\" : 1 , \"amount\" : 50.00 }, { \"order_id\" : 102 , \"user_id\" : 1 , \"amount\" : 30.00 } ] # Join users with orders user_orders = list ( left_join ( users , orders , \"user_id\" , \"user_id\" )) # Project just the fields we need summary = list ( project ( user_orders , [ \"name\" , \"order_id\" , \"amount\" ]))","title":"User Order Analysis"},{"location":"tools/collections/dotrelate/#data-deduplication","text":"Remove duplicates from a dataset: all_records = [ { \"id\" : 1 , \"email\" : \"alice@example.com\" }, { \"id\" : 2 , \"email\" : \"bob@example.com\" }, { \"id\" : 1 , \"email\" : \"alice@example.com\" }, # Duplicate ] seen = [{ \"id\" : 1 , \"email\" : \"alice@example.com\" }] unique = list ( set_difference ( all_records , seen ))","title":"Data Deduplication"},{"location":"tools/collections/dotrelate/#mathematical-foundation","text":"dotrelate implements operations from relational algebra: Join (\u22c8) : Combines relations based on common attributes Projection (\u03c0) : Selects columns from a relation Union (\u222a) : Set union of two relations Difference (-) : Set difference between relations These operations form a complete algebra for querying and transforming relational data.","title":"Mathematical Foundation"},{"location":"tools/collections/dotrelate/#integration-with-other-tools","text":"dotrelate works seamlessly with other dotsuite tools: from collections.dotrelate import left_join , project from collections.dotfilter import dotfilter from truth.dotquery import Query # Filter users before joining active_users = dotfilter ( users , Query ( \"status equals active\" )) # Join with orders user_orders = left_join ( active_users , orders , \"id\" , \"user_id\" ) # Project specific fields result = project ( user_orders , [ \"name\" , \"product\" , \"amount\" ])","title":"Integration with Other Tools"},{"location":"tools/collections/dotrelate/#cli-usage","text":"# Join two JSONL files dotrelate join --left users.jsonl --right orders.jsonl \\ --left-on id --right-on user_id > joined.jsonl # Project specific fields dotrelate project --fields name,email < users.jsonl # Union two files dotrelate union file1.jsonl file2.jsonl > combined.jsonl","title":"CLI Usage"},{"location":"tools/collections/dotrelate/#related-tools","text":"dotfilter : Filter collections before joining dotquery : Create complex join conditions jsonl-algebra : Production-ready relational operations","title":"Related Tools"},{"location":"tools/collections/dotrelate/#theory-and-motivation","text":"Relational operations are fundamental to data manipulation. By bringing these operations to document-oriented data, dotrelate bridges the gap between: Structured (SQL) and semi-structured (JSON) data paradigms Set theory and practical data processing Mathematical rigor and developer ergonomics The tool demonstrates that relational algebra's elegance extends beyond traditional databases to any collection of structured documents. For more extensive relational operations and optimizations, see the jsonl-algebra project, which provides a complete implementation of relational algebra for JSONL data.","title":"Theory and Motivation"},{"location":"tools/depth/dotget/","text":"dotget \u00b6 Simple, exact addressing for nested data The foundational tool of the Depth pillar, dotget safely extracts values from nested data structures using dot notation paths. Overview \u00b6 dotget is the tool that started it all - a simple function to safely navigate nested dictionaries and lists without worrying about KeyErrors or IndexErrors. Basic Usage \u00b6 from depth.dotget import get data = { \"user\" : { \"name\" : \"Alice\" , \"contacts\" : { \"email\" : \"alice@example.com\" , \"phone\" : \"+1-555-0100\" } } } # Get nested values name = get ( data , \"user.name\" ) # \"Alice\" email = get ( data , \"user.contacts.email\" ) # \"alice@example.com\" missing = get ( data , \"user.contacts.fax\" ) # None Safe Navigation \u00b6 Unlike direct dictionary access, dotget never raises exceptions: # This would raise KeyError: # value = data[\"user\"][\"settings\"][\"theme\"] # This returns None safely: value = get ( data , \"user.settings.theme\" ) # None List Access \u00b6 Navigate through lists using numeric indices: data = { \"users\" : [ { \"name\" : \"Alice\" , \"age\" : 30 }, { \"name\" : \"Bob\" , \"age\" : 25 }, { \"name\" : \"Charlie\" , \"age\" : 35 } ] } # Access by index first_user = get ( data , \"users.0.name\" ) # \"Alice\" second_age = get ( data , \"users.1.age\" ) # 25 # Negative indices work too last_user = get ( data , \"users.-1.name\" ) # \"Charlie\" # Out of bounds returns None missing = get ( data , \"users.10.name\" ) # None Mixed Structures \u00b6 Navigate seamlessly through mixed dictionaries and lists: data = { \"company\" : { \"departments\" : [ { \"name\" : \"Engineering\" , \"teams\" : [ { \"name\" : \"Backend\" , \"size\" : 5 }, { \"name\" : \"Frontend\" , \"size\" : 3 } ] } ] } } # Deep navigation team_size = get ( data , \"company.departments.0.teams.1.size\" ) # 3 Real-World Examples \u00b6 API Response Parsing \u00b6 response = { \"data\" : { \"user\" : { \"id\" : 123 , \"profile\" : { \"firstName\" : \"Alice\" , \"lastName\" : \"Smith\" } } }, \"meta\" : { \"timestamp\" : \"2024-01-01T12:00:00Z\" } } user_id = get ( response , \"data.user.id\" ) # 123 full_name = f \" { get ( response , 'data.user.profile.firstName' ) } { get ( response , 'data.user.profile.lastName' ) } \" Configuration Access \u00b6 config = { \"database\" : { \"primary\" : { \"host\" : \"db1.example.com\" , \"port\" : 5432 } } } # Safe configuration access with defaults db_host = get ( config , \"database.primary.host\" ) or \"localhost\" db_port = get ( config , \"database.primary.port\" ) or 5432 db_user = get ( config , \"database.primary.user\" ) or \"postgres\" JSON Data Processing \u00b6 import json # Load JSON data with open ( \"data.json\" ) as f : data = json . load ( f ) # Safely extract nested values for i in range ( 100 ): # Don't know how many items name = get ( data , f \"items. { i } .name\" ) if name is None : break # No more items print ( name ) Design Philosophy \u00b6 dotget embodies the principle of graceful degradation : - Never raises exceptions for missing paths - Returns None for any navigation failure - Simple, predictable behavior - Zero dependencies Performance \u00b6 dotget is optimized for simplicity and safety, not speed: - O(n) where n is the depth of the path - Minimal memory overhead - No caching or memoization For performance-critical applications with known schemas, direct dictionary access is faster. Related Tools \u00b6 dotstar - Pattern matching with wildcards dotexists - Check if path exists dotmod - Modify values at paths","title":"dotget"},{"location":"tools/depth/dotget/#dotget","text":"Simple, exact addressing for nested data The foundational tool of the Depth pillar, dotget safely extracts values from nested data structures using dot notation paths.","title":"dotget"},{"location":"tools/depth/dotget/#overview","text":"dotget is the tool that started it all - a simple function to safely navigate nested dictionaries and lists without worrying about KeyErrors or IndexErrors.","title":"Overview"},{"location":"tools/depth/dotget/#basic-usage","text":"from depth.dotget import get data = { \"user\" : { \"name\" : \"Alice\" , \"contacts\" : { \"email\" : \"alice@example.com\" , \"phone\" : \"+1-555-0100\" } } } # Get nested values name = get ( data , \"user.name\" ) # \"Alice\" email = get ( data , \"user.contacts.email\" ) # \"alice@example.com\" missing = get ( data , \"user.contacts.fax\" ) # None","title":"Basic Usage"},{"location":"tools/depth/dotget/#safe-navigation","text":"Unlike direct dictionary access, dotget never raises exceptions: # This would raise KeyError: # value = data[\"user\"][\"settings\"][\"theme\"] # This returns None safely: value = get ( data , \"user.settings.theme\" ) # None","title":"Safe Navigation"},{"location":"tools/depth/dotget/#list-access","text":"Navigate through lists using numeric indices: data = { \"users\" : [ { \"name\" : \"Alice\" , \"age\" : 30 }, { \"name\" : \"Bob\" , \"age\" : 25 }, { \"name\" : \"Charlie\" , \"age\" : 35 } ] } # Access by index first_user = get ( data , \"users.0.name\" ) # \"Alice\" second_age = get ( data , \"users.1.age\" ) # 25 # Negative indices work too last_user = get ( data , \"users.-1.name\" ) # \"Charlie\" # Out of bounds returns None missing = get ( data , \"users.10.name\" ) # None","title":"List Access"},{"location":"tools/depth/dotget/#mixed-structures","text":"Navigate seamlessly through mixed dictionaries and lists: data = { \"company\" : { \"departments\" : [ { \"name\" : \"Engineering\" , \"teams\" : [ { \"name\" : \"Backend\" , \"size\" : 5 }, { \"name\" : \"Frontend\" , \"size\" : 3 } ] } ] } } # Deep navigation team_size = get ( data , \"company.departments.0.teams.1.size\" ) # 3","title":"Mixed Structures"},{"location":"tools/depth/dotget/#real-world-examples","text":"","title":"Real-World Examples"},{"location":"tools/depth/dotget/#api-response-parsing","text":"response = { \"data\" : { \"user\" : { \"id\" : 123 , \"profile\" : { \"firstName\" : \"Alice\" , \"lastName\" : \"Smith\" } } }, \"meta\" : { \"timestamp\" : \"2024-01-01T12:00:00Z\" } } user_id = get ( response , \"data.user.id\" ) # 123 full_name = f \" { get ( response , 'data.user.profile.firstName' ) } { get ( response , 'data.user.profile.lastName' ) } \"","title":"API Response Parsing"},{"location":"tools/depth/dotget/#configuration-access","text":"config = { \"database\" : { \"primary\" : { \"host\" : \"db1.example.com\" , \"port\" : 5432 } } } # Safe configuration access with defaults db_host = get ( config , \"database.primary.host\" ) or \"localhost\" db_port = get ( config , \"database.primary.port\" ) or 5432 db_user = get ( config , \"database.primary.user\" ) or \"postgres\"","title":"Configuration Access"},{"location":"tools/depth/dotget/#json-data-processing","text":"import json # Load JSON data with open ( \"data.json\" ) as f : data = json . load ( f ) # Safely extract nested values for i in range ( 100 ): # Don't know how many items name = get ( data , f \"items. { i } .name\" ) if name is None : break # No more items print ( name )","title":"JSON Data Processing"},{"location":"tools/depth/dotget/#design-philosophy","text":"dotget embodies the principle of graceful degradation : - Never raises exceptions for missing paths - Returns None for any navigation failure - Simple, predictable behavior - Zero dependencies","title":"Design Philosophy"},{"location":"tools/depth/dotget/#performance","text":"dotget is optimized for simplicity and safety, not speed: - O(n) where n is the depth of the path - Minimal memory overhead - No caching or memoization For performance-critical applications with known schemas, direct dictionary access is faster.","title":"Performance"},{"location":"tools/depth/dotget/#related-tools","text":"dotstar - Pattern matching with wildcards dotexists - Check if path exists dotmod - Modify values at paths","title":"Related Tools"},{"location":"tools/depth/dotstar/","text":"dotstar \u00b6 Pattern matching with wildcards for nested data Part of the Depth pillar, dotstar extends dotget with wildcard support, enabling you to search for multiple values matching a pattern. Overview \u00b6 While dotget retrieves a single value at an exact path, dotstar can find all values matching a pattern with wildcards, making it perfect for data exploration and bulk operations. Wildcard Patterns \u00b6 The * wildcard matches any key or index: from depth.dotstar import search data = { \"users\" : [ { \"name\" : \"Alice\" , \"age\" : 30 }, { \"name\" : \"Bob\" , \"age\" : 25 }, { \"name\" : \"Charlie\" , \"age\" : 35 } ] } # Get all user names names = search ( data , \"users.*.name\" ) # [\"Alice\", \"Bob\", \"Charlie\"] # Get all ages ages = search ( data , \"users.*.age\" ) # [30, 25, 35] Multiple Wildcards \u00b6 Use multiple wildcards to search deeper: data = { \"departments\" : { \"engineering\" : { \"teams\" : { \"backend\" : { \"members\" : 5 }, \"frontend\" : { \"members\" : 3 } } }, \"sales\" : { \"teams\" : { \"inbound\" : { \"members\" : 4 }, \"outbound\" : { \"members\" : 6 } } } } } # Get all team member counts counts = search ( data , \"departments.*.teams.*.members\" ) # [5, 3, 4, 6] Dictionary Wildcards \u00b6 Wildcards work with dictionary keys: data = { \"server1\" : { \"status\" : \"active\" , \"cpu\" : 45 }, \"server2\" : { \"status\" : \"active\" , \"cpu\" : 67 }, \"server3\" : { \"status\" : \"inactive\" , \"cpu\" : 12 } } # Get all server statuses statuses = search ( data , \"*.status\" ) # [\"active\", \"active\", \"inactive\"] # Get all CPU values cpus = search ( data , \"*.cpu\" ) # [45, 67, 12] Finding Paths with find_all \u00b6 Get both paths and values: from depth.dotstar import find_all data = { \"users\" : [ { \"name\" : \"Alice\" , \"role\" : \"admin\" }, { \"name\" : \"Bob\" , \"role\" : \"user\" } ] } # Get paths and values results = find_all ( data , \"users.*.role\" ) # [ # (\"users.0.role\", \"admin\"), # (\"users.1.role\", \"user\") # ] # Useful for updates for path , value in results : if value == \"admin\" : print ( f \"Admin found at: { path } \" ) Pattern Class \u00b6 Build reusable patterns: from depth.dotstar import Pattern # Create reusable patterns user_emails = Pattern ( \"users.*.email\" ) user_names = Pattern ( \"users.*.name\" ) # Apply to different datasets emails1 = user_emails . search ( dataset1 ) emails2 = user_emails . search ( dataset2 ) # Compose patterns admins = Pattern ( \"users.*[role=admin]\" ) # Future feature Real-World Examples \u00b6 Extract All Email Addresses \u00b6 organization = { \"departments\" : [ { \"name\" : \"Engineering\" , \"employees\" : [ { \"name\" : \"Alice\" , \"email\" : \"alice@example.com\" }, { \"name\" : \"Bob\" , \"email\" : \"bob@example.com\" } ] }, { \"name\" : \"Sales\" , \"employees\" : [ { \"name\" : \"Charlie\" , \"email\" : \"charlie@example.com\" } ] } ] } # Get all employee emails emails = search ( organization , \"departments.*.employees.*.email\" ) # [\"alice@example.com\", \"bob@example.com\", \"charlie@example.com\"] Aggregate Metrics \u00b6 metrics = { \"services\" : { \"api\" : { \"endpoints\" : { \"users\" : { \"requests\" : 1000 , \"errors\" : 5 }, \"posts\" : { \"requests\" : 500 , \"errors\" : 2 } } }, \"web\" : { \"endpoints\" : { \"home\" : { \"requests\" : 5000 , \"errors\" : 10 }, \"about\" : { \"requests\" : 200 , \"errors\" : 0 } } } } } # Get all request counts total_requests = sum ( search ( metrics , \"services.*.endpoints.*.requests\" )) # 6700 # Get all error counts total_errors = sum ( search ( metrics , \"services.*.endpoints.*.errors\" )) # 17 Find Configuration Values \u00b6 config = { \"environments\" : { \"dev\" : { \"database\" : { \"host\" : \"localhost\" , \"port\" : 5432 }, \"cache\" : { \"host\" : \"localhost\" , \"port\" : 6379 } }, \"prod\" : { \"database\" : { \"host\" : \"db.prod.com\" , \"port\" : 5432 }, \"cache\" : { \"host\" : \"cache.prod.com\" , \"port\" : 6379 } } } } # Find all database hosts db_hosts = search ( config , \"environments.*.database.host\" ) # [\"localhost\", \"db.prod.com\"] # Find all ports all_ports = search ( config , \"environments.*.*.port\" ) # [5432, 6379, 5432, 6379] Data Validation \u00b6 # Check if all required fields exist products = [ { \"id\" : 1 , \"name\" : \"Widget\" , \"price\" : 9.99 }, { \"id\" : 2 , \"name\" : \"Gadget\" , \"price\" : 19.99 }, { \"id\" : 3 , \"name\" : \"Gizmo\" } # Missing price! ] prices = search ({ \"products\" : products }, \"products.*.price\" ) if len ( prices ) != len ( products ): print ( \"Warning: Some products missing prices!\" ) Performance Considerations \u00b6 Linear search : O(n) where n is total number of nodes No indexing : Each search traverses the entire structure Memory efficient : Returns list of values, not full paths Use find_all : When you need paths for later updates Comparison with dotget \u00b6 Feature dotget dotstar Purpose Single value Multiple values Wildcards No Yes (*) Return type Single value or None List of values Performance O(depth) O(nodes) Use case Known paths Pattern search Advanced Patterns (Future) \u00b6 Planned enhancements: - ** for recursive descent - [n:m] for slice notation - [?filter] for inline filtering - {key1,key2} for multiple specific keys Related Tools \u00b6 dotget - Simple exact path access dotselect - Advanced selection with predicates dotpath - Underlying path engine dotmod - Modify values found by patterns","title":"dotstar"},{"location":"tools/depth/dotstar/#dotstar","text":"Pattern matching with wildcards for nested data Part of the Depth pillar, dotstar extends dotget with wildcard support, enabling you to search for multiple values matching a pattern.","title":"dotstar"},{"location":"tools/depth/dotstar/#overview","text":"While dotget retrieves a single value at an exact path, dotstar can find all values matching a pattern with wildcards, making it perfect for data exploration and bulk operations.","title":"Overview"},{"location":"tools/depth/dotstar/#wildcard-patterns","text":"The * wildcard matches any key or index: from depth.dotstar import search data = { \"users\" : [ { \"name\" : \"Alice\" , \"age\" : 30 }, { \"name\" : \"Bob\" , \"age\" : 25 }, { \"name\" : \"Charlie\" , \"age\" : 35 } ] } # Get all user names names = search ( data , \"users.*.name\" ) # [\"Alice\", \"Bob\", \"Charlie\"] # Get all ages ages = search ( data , \"users.*.age\" ) # [30, 25, 35]","title":"Wildcard Patterns"},{"location":"tools/depth/dotstar/#multiple-wildcards","text":"Use multiple wildcards to search deeper: data = { \"departments\" : { \"engineering\" : { \"teams\" : { \"backend\" : { \"members\" : 5 }, \"frontend\" : { \"members\" : 3 } } }, \"sales\" : { \"teams\" : { \"inbound\" : { \"members\" : 4 }, \"outbound\" : { \"members\" : 6 } } } } } # Get all team member counts counts = search ( data , \"departments.*.teams.*.members\" ) # [5, 3, 4, 6]","title":"Multiple Wildcards"},{"location":"tools/depth/dotstar/#dictionary-wildcards","text":"Wildcards work with dictionary keys: data = { \"server1\" : { \"status\" : \"active\" , \"cpu\" : 45 }, \"server2\" : { \"status\" : \"active\" , \"cpu\" : 67 }, \"server3\" : { \"status\" : \"inactive\" , \"cpu\" : 12 } } # Get all server statuses statuses = search ( data , \"*.status\" ) # [\"active\", \"active\", \"inactive\"] # Get all CPU values cpus = search ( data , \"*.cpu\" ) # [45, 67, 12]","title":"Dictionary Wildcards"},{"location":"tools/depth/dotstar/#finding-paths-with-find_all","text":"Get both paths and values: from depth.dotstar import find_all data = { \"users\" : [ { \"name\" : \"Alice\" , \"role\" : \"admin\" }, { \"name\" : \"Bob\" , \"role\" : \"user\" } ] } # Get paths and values results = find_all ( data , \"users.*.role\" ) # [ # (\"users.0.role\", \"admin\"), # (\"users.1.role\", \"user\") # ] # Useful for updates for path , value in results : if value == \"admin\" : print ( f \"Admin found at: { path } \" )","title":"Finding Paths with find_all"},{"location":"tools/depth/dotstar/#pattern-class","text":"Build reusable patterns: from depth.dotstar import Pattern # Create reusable patterns user_emails = Pattern ( \"users.*.email\" ) user_names = Pattern ( \"users.*.name\" ) # Apply to different datasets emails1 = user_emails . search ( dataset1 ) emails2 = user_emails . search ( dataset2 ) # Compose patterns admins = Pattern ( \"users.*[role=admin]\" ) # Future feature","title":"Pattern Class"},{"location":"tools/depth/dotstar/#real-world-examples","text":"","title":"Real-World Examples"},{"location":"tools/depth/dotstar/#extract-all-email-addresses","text":"organization = { \"departments\" : [ { \"name\" : \"Engineering\" , \"employees\" : [ { \"name\" : \"Alice\" , \"email\" : \"alice@example.com\" }, { \"name\" : \"Bob\" , \"email\" : \"bob@example.com\" } ] }, { \"name\" : \"Sales\" , \"employees\" : [ { \"name\" : \"Charlie\" , \"email\" : \"charlie@example.com\" } ] } ] } # Get all employee emails emails = search ( organization , \"departments.*.employees.*.email\" ) # [\"alice@example.com\", \"bob@example.com\", \"charlie@example.com\"]","title":"Extract All Email Addresses"},{"location":"tools/depth/dotstar/#aggregate-metrics","text":"metrics = { \"services\" : { \"api\" : { \"endpoints\" : { \"users\" : { \"requests\" : 1000 , \"errors\" : 5 }, \"posts\" : { \"requests\" : 500 , \"errors\" : 2 } } }, \"web\" : { \"endpoints\" : { \"home\" : { \"requests\" : 5000 , \"errors\" : 10 }, \"about\" : { \"requests\" : 200 , \"errors\" : 0 } } } } } # Get all request counts total_requests = sum ( search ( metrics , \"services.*.endpoints.*.requests\" )) # 6700 # Get all error counts total_errors = sum ( search ( metrics , \"services.*.endpoints.*.errors\" )) # 17","title":"Aggregate Metrics"},{"location":"tools/depth/dotstar/#find-configuration-values","text":"config = { \"environments\" : { \"dev\" : { \"database\" : { \"host\" : \"localhost\" , \"port\" : 5432 }, \"cache\" : { \"host\" : \"localhost\" , \"port\" : 6379 } }, \"prod\" : { \"database\" : { \"host\" : \"db.prod.com\" , \"port\" : 5432 }, \"cache\" : { \"host\" : \"cache.prod.com\" , \"port\" : 6379 } } } } # Find all database hosts db_hosts = search ( config , \"environments.*.database.host\" ) # [\"localhost\", \"db.prod.com\"] # Find all ports all_ports = search ( config , \"environments.*.*.port\" ) # [5432, 6379, 5432, 6379]","title":"Find Configuration Values"},{"location":"tools/depth/dotstar/#data-validation","text":"# Check if all required fields exist products = [ { \"id\" : 1 , \"name\" : \"Widget\" , \"price\" : 9.99 }, { \"id\" : 2 , \"name\" : \"Gadget\" , \"price\" : 19.99 }, { \"id\" : 3 , \"name\" : \"Gizmo\" } # Missing price! ] prices = search ({ \"products\" : products }, \"products.*.price\" ) if len ( prices ) != len ( products ): print ( \"Warning: Some products missing prices!\" )","title":"Data Validation"},{"location":"tools/depth/dotstar/#performance-considerations","text":"Linear search : O(n) where n is total number of nodes No indexing : Each search traverses the entire structure Memory efficient : Returns list of values, not full paths Use find_all : When you need paths for later updates","title":"Performance Considerations"},{"location":"tools/depth/dotstar/#comparison-with-dotget","text":"Feature dotget dotstar Purpose Single value Multiple values Wildcards No Yes (*) Return type Single value or None List of values Performance O(depth) O(nodes) Use case Known paths Pattern search","title":"Comparison with dotget"},{"location":"tools/depth/dotstar/#advanced-patterns-future","text":"Planned enhancements: - ** for recursive descent - [n:m] for slice notation - [?filter] for inline filtering - {key1,key2} for multiple specific keys","title":"Advanced Patterns (Future)"},{"location":"tools/depth/dotstar/#related-tools","text":"dotget - Simple exact path access dotselect - Advanced selection with predicates dotpath - Underlying path engine dotmod - Modify values found by patterns","title":"Related Tools"},{"location":"tools/shape/dotbatch/","text":"dotbatch \u00b6 Atomic batch operations with rollback support Part of the Shape pillar, dotbatch provides transactional semantics for multiple modifications, ensuring all changes succeed or none are applied. Overview \u00b6 dotbatch brings database-like ACID properties to nested data structure modifications. It executes a batch of operations atomically - if any operation fails, all changes are rolled back. Core Concepts \u00b6 Atomic Transactions \u00b6 from shape.dotbatch import Batch data = { \"account\" : { \"balance\" : 100 , \"transactions\" : [] } } # Create a batch of operations batch = Batch ( data ) batch . set ( \"account.balance\" , 50 ) batch . append ( \"account.transactions\" , { \"amount\" : - 50 , \"type\" : \"withdrawal\" }) batch . set ( \"account.last_modified\" , \"2024-01-01\" ) # Apply all at once (atomic) result = batch . commit () # If any operation would fail, nothing is applied try : batch = Batch ( data ) batch . set ( \"account.balance\" , - 100 ) # Would fail validation batch . delete ( \"required.field\" ) # Would fail result = batch . commit () # Rolls back, returns original except BatchError : # Original data unchanged pass Operation Types \u00b6 Basic Operations \u00b6 batch = Batch ( data ) # Set values batch . set ( \"user.name\" , \"Alice\" ) batch . set ( \"user.email\" , \"alice@example.com\" ) # Update with functions batch . update ( \"counter\" , lambda x : x + 1 ) batch . update ( \"prices\" , lambda p : [ x * 1.1 for x in p ]) # Delete paths batch . delete ( \"temp.data\" ) batch . delete ( \"user.old_field\" ) # Append to lists batch . append ( \"logs\" , { \"timestamp\" : now (), \"action\" : \"login\" }) batch . extend ( \"tags\" , [ \"new\" , \"updated\" ]) # Apply all result = batch . commit () Conditional Operations \u00b6 batch = Batch ( data ) # Only apply if condition is met batch . set_if ( \"user.role\" , \"admin\" , lambda d : get ( d , \"user.verified\" )) batch . delete_if ( \"cache\" , lambda d : time () - get ( d , \"cache.timestamp\" ) > 3600 ) # Conditional batch execution if should_update : batch . commit () else : batch . rollback () # Explicitly discard changes Validation and Constraints \u00b6 Add validation to ensure data integrity: from shape.dotbatch import Batch , ValidationError def validate_balance ( batch , path , value ): \"\"\"Ensure balance never goes negative.\"\"\" if value < 0 : raise ValidationError ( f \"Balance cannot be negative: { value } \" ) return value batch = Batch ( data ) batch . set ( \"account.balance\" , new_balance , validate = validate_balance ) # Or add global validation batch . add_validator ( lambda d : d . get ( \"account.balance\" , 0 ) >= 0 ) Real-World Examples \u00b6 Bank Transfer (Classic Two-Phase Commit) \u00b6 def transfer_funds ( accounts , from_id , to_id , amount ): \"\"\"Transfer funds between accounts atomically.\"\"\" batch = Batch ( accounts ) # Debit from source from_balance = get ( accounts , f \" { from_id } .balance\" ) if from_balance < amount : raise InsufficientFunds () batch . update ( f \" { from_id } .balance\" , lambda b : b - amount ) batch . append ( f \" { from_id } .transactions\" , { \"type\" : \"debit\" , \"amount\" : - amount , \"to\" : to_id , \"timestamp\" : now () }) # Credit to destination batch . update ( f \" { to_id } .balance\" , lambda b : b + amount ) batch . append ( f \" { to_id } .transactions\" , { \"type\" : \"credit\" , \"amount\" : amount , \"from\" : from_id , \"timestamp\" : now () }) # Atomic commit - both succeed or both fail return batch . commit () Shopping Cart Checkout \u00b6 def checkout_cart ( store_data , user_id , cart_items ): \"\"\"Process checkout atomically.\"\"\" batch = Batch ( store_data ) total = 0 for item in cart_items : product_path = f \"products. { item [ 'product_id' ] } \" # Check inventory current_stock = get ( store_data , f \" { product_path } .stock\" ) if current_stock < item [ 'quantity' ]: raise OutOfStock ( item [ 'product_id' ]) # Update inventory batch . update ( f \" { product_path } .stock\" , lambda s : s - item [ 'quantity' ]) # Track sales batch . update ( f \" { product_path } .sold\" , lambda s : s + item [ 'quantity' ]) total += item [ 'quantity' ] * get ( store_data , f \" { product_path } .price\" ) # Create order order = { \"id\" : generate_id (), \"user_id\" : user_id , \"items\" : cart_items , \"total\" : total , \"status\" : \"pending\" , \"created_at\" : now () } batch . append ( \"orders\" , order ) batch . set ( f \"users. { user_id } .cart\" , []) # Clear cart # All succeed or all fail return batch . commit (), order [ 'id' ] Configuration Update with Rollback \u00b6 def update_config ( config , changes , test_fn ): \"\"\"Update configuration with automatic rollback on failure.\"\"\" batch = Batch ( config ) # Apply all changes for path , value in changes . items (): batch . set ( path , value ) # Test configuration new_config = batch . preview () # See changes without committing if test_fn ( new_config ): return batch . commit () # Tests passed, apply else : batch . rollback () # Tests failed, discard raise ConfigTestFailed () Transaction Log \u00b6 Track all operations for audit: batch = Batch ( data , track_operations = True ) batch . set ( \"user.name\" , \"Alice\" ) batch . update ( \"user.login_count\" , lambda x : x + 1 ) # Get operation log log = batch . get_operations () # [ # {\"op\": \"set\", \"path\": \"user.name\", \"value\": \"Alice\"}, # {\"op\": \"update\", \"path\": \"user.login_count\", \"fn\": \"<lambda>\"} # ] # Replay operations on different data other_data = {} for op in log : apply_operation ( other_data , op ) Nested Batches \u00b6 Create savepoints with nested batches: outer = Batch ( data ) outer . set ( \"status\" , \"processing\" ) # Nested batch for risky operations inner = outer . nested () try : inner . set ( \"risky.operation\" , compute_value ()) inner . set ( \"another.risky\" , external_api_call ()) inner . commit () # Commit to outer batch except Exception : inner . rollback () # Only rolls back inner changes outer . set ( \"status\" , \"partial_failure\" ) outer . commit () # Apply outer changes Mathematical Foundation \u00b6 dotbatch implements a transaction monad with: - Atomicity : All operations succeed or all fail - Consistency : Validation ensures invariants - Isolation : Changes invisible until commit - Durability : Immutable structures preserve history The batch forms a monoid under composition: - Identity : Empty batch - Associativity : Batch composition is associative - Closure : Composing batches yields a batch Performance Considerations \u00b6 Lazy evaluation : Operations are queued, not executed until commit Single pass application : All changes applied in one traversal Structural sharing : Unchanged parts share memory Rollback cost : O(1) - just return original data Related Tools \u00b6 dotmod - Individual modifications dotpipe - Sequential transformations dotget - Read values for validation","title":"dotbatch"},{"location":"tools/shape/dotbatch/#dotbatch","text":"Atomic batch operations with rollback support Part of the Shape pillar, dotbatch provides transactional semantics for multiple modifications, ensuring all changes succeed or none are applied.","title":"dotbatch"},{"location":"tools/shape/dotbatch/#overview","text":"dotbatch brings database-like ACID properties to nested data structure modifications. It executes a batch of operations atomically - if any operation fails, all changes are rolled back.","title":"Overview"},{"location":"tools/shape/dotbatch/#core-concepts","text":"","title":"Core Concepts"},{"location":"tools/shape/dotbatch/#atomic-transactions","text":"from shape.dotbatch import Batch data = { \"account\" : { \"balance\" : 100 , \"transactions\" : [] } } # Create a batch of operations batch = Batch ( data ) batch . set ( \"account.balance\" , 50 ) batch . append ( \"account.transactions\" , { \"amount\" : - 50 , \"type\" : \"withdrawal\" }) batch . set ( \"account.last_modified\" , \"2024-01-01\" ) # Apply all at once (atomic) result = batch . commit () # If any operation would fail, nothing is applied try : batch = Batch ( data ) batch . set ( \"account.balance\" , - 100 ) # Would fail validation batch . delete ( \"required.field\" ) # Would fail result = batch . commit () # Rolls back, returns original except BatchError : # Original data unchanged pass","title":"Atomic Transactions"},{"location":"tools/shape/dotbatch/#operation-types","text":"","title":"Operation Types"},{"location":"tools/shape/dotbatch/#basic-operations","text":"batch = Batch ( data ) # Set values batch . set ( \"user.name\" , \"Alice\" ) batch . set ( \"user.email\" , \"alice@example.com\" ) # Update with functions batch . update ( \"counter\" , lambda x : x + 1 ) batch . update ( \"prices\" , lambda p : [ x * 1.1 for x in p ]) # Delete paths batch . delete ( \"temp.data\" ) batch . delete ( \"user.old_field\" ) # Append to lists batch . append ( \"logs\" , { \"timestamp\" : now (), \"action\" : \"login\" }) batch . extend ( \"tags\" , [ \"new\" , \"updated\" ]) # Apply all result = batch . commit ()","title":"Basic Operations"},{"location":"tools/shape/dotbatch/#conditional-operations","text":"batch = Batch ( data ) # Only apply if condition is met batch . set_if ( \"user.role\" , \"admin\" , lambda d : get ( d , \"user.verified\" )) batch . delete_if ( \"cache\" , lambda d : time () - get ( d , \"cache.timestamp\" ) > 3600 ) # Conditional batch execution if should_update : batch . commit () else : batch . rollback () # Explicitly discard changes","title":"Conditional Operations"},{"location":"tools/shape/dotbatch/#validation-and-constraints","text":"Add validation to ensure data integrity: from shape.dotbatch import Batch , ValidationError def validate_balance ( batch , path , value ): \"\"\"Ensure balance never goes negative.\"\"\" if value < 0 : raise ValidationError ( f \"Balance cannot be negative: { value } \" ) return value batch = Batch ( data ) batch . set ( \"account.balance\" , new_balance , validate = validate_balance ) # Or add global validation batch . add_validator ( lambda d : d . get ( \"account.balance\" , 0 ) >= 0 )","title":"Validation and Constraints"},{"location":"tools/shape/dotbatch/#real-world-examples","text":"","title":"Real-World Examples"},{"location":"tools/shape/dotbatch/#bank-transfer-classic-two-phase-commit","text":"def transfer_funds ( accounts , from_id , to_id , amount ): \"\"\"Transfer funds between accounts atomically.\"\"\" batch = Batch ( accounts ) # Debit from source from_balance = get ( accounts , f \" { from_id } .balance\" ) if from_balance < amount : raise InsufficientFunds () batch . update ( f \" { from_id } .balance\" , lambda b : b - amount ) batch . append ( f \" { from_id } .transactions\" , { \"type\" : \"debit\" , \"amount\" : - amount , \"to\" : to_id , \"timestamp\" : now () }) # Credit to destination batch . update ( f \" { to_id } .balance\" , lambda b : b + amount ) batch . append ( f \" { to_id } .transactions\" , { \"type\" : \"credit\" , \"amount\" : amount , \"from\" : from_id , \"timestamp\" : now () }) # Atomic commit - both succeed or both fail return batch . commit ()","title":"Bank Transfer (Classic Two-Phase Commit)"},{"location":"tools/shape/dotbatch/#shopping-cart-checkout","text":"def checkout_cart ( store_data , user_id , cart_items ): \"\"\"Process checkout atomically.\"\"\" batch = Batch ( store_data ) total = 0 for item in cart_items : product_path = f \"products. { item [ 'product_id' ] } \" # Check inventory current_stock = get ( store_data , f \" { product_path } .stock\" ) if current_stock < item [ 'quantity' ]: raise OutOfStock ( item [ 'product_id' ]) # Update inventory batch . update ( f \" { product_path } .stock\" , lambda s : s - item [ 'quantity' ]) # Track sales batch . update ( f \" { product_path } .sold\" , lambda s : s + item [ 'quantity' ]) total += item [ 'quantity' ] * get ( store_data , f \" { product_path } .price\" ) # Create order order = { \"id\" : generate_id (), \"user_id\" : user_id , \"items\" : cart_items , \"total\" : total , \"status\" : \"pending\" , \"created_at\" : now () } batch . append ( \"orders\" , order ) batch . set ( f \"users. { user_id } .cart\" , []) # Clear cart # All succeed or all fail return batch . commit (), order [ 'id' ]","title":"Shopping Cart Checkout"},{"location":"tools/shape/dotbatch/#configuration-update-with-rollback","text":"def update_config ( config , changes , test_fn ): \"\"\"Update configuration with automatic rollback on failure.\"\"\" batch = Batch ( config ) # Apply all changes for path , value in changes . items (): batch . set ( path , value ) # Test configuration new_config = batch . preview () # See changes without committing if test_fn ( new_config ): return batch . commit () # Tests passed, apply else : batch . rollback () # Tests failed, discard raise ConfigTestFailed ()","title":"Configuration Update with Rollback"},{"location":"tools/shape/dotbatch/#transaction-log","text":"Track all operations for audit: batch = Batch ( data , track_operations = True ) batch . set ( \"user.name\" , \"Alice\" ) batch . update ( \"user.login_count\" , lambda x : x + 1 ) # Get operation log log = batch . get_operations () # [ # {\"op\": \"set\", \"path\": \"user.name\", \"value\": \"Alice\"}, # {\"op\": \"update\", \"path\": \"user.login_count\", \"fn\": \"<lambda>\"} # ] # Replay operations on different data other_data = {} for op in log : apply_operation ( other_data , op )","title":"Transaction Log"},{"location":"tools/shape/dotbatch/#nested-batches","text":"Create savepoints with nested batches: outer = Batch ( data ) outer . set ( \"status\" , \"processing\" ) # Nested batch for risky operations inner = outer . nested () try : inner . set ( \"risky.operation\" , compute_value ()) inner . set ( \"another.risky\" , external_api_call ()) inner . commit () # Commit to outer batch except Exception : inner . rollback () # Only rolls back inner changes outer . set ( \"status\" , \"partial_failure\" ) outer . commit () # Apply outer changes","title":"Nested Batches"},{"location":"tools/shape/dotbatch/#mathematical-foundation","text":"dotbatch implements a transaction monad with: - Atomicity : All operations succeed or all fail - Consistency : Validation ensures invariants - Isolation : Changes invisible until commit - Durability : Immutable structures preserve history The batch forms a monoid under composition: - Identity : Empty batch - Associativity : Batch composition is associative - Closure : Composing batches yields a batch","title":"Mathematical Foundation"},{"location":"tools/shape/dotbatch/#performance-considerations","text":"Lazy evaluation : Operations are queued, not executed until commit Single pass application : All changes applied in one traversal Structural sharing : Unchanged parts share memory Rollback cost : O(1) - just return original data","title":"Performance Considerations"},{"location":"tools/shape/dotbatch/#related-tools","text":"dotmod - Individual modifications dotpipe - Sequential transformations dotget - Read values for validation","title":"Related Tools"},{"location":"tools/shape/dotmod/","text":"dotmod \u00b6 Immutable modifications to nested data structures Part of the Shape pillar, dotmod provides surgical, immutable modifications to nested data structures using dot notation paths. Overview \u00b6 dotmod enables you to modify values deep within nested structures without mutating the original data, following functional programming principles. Core Operations \u00b6 set_ - Set a value at a path \u00b6 from shape.dotmod import set_ data = { \"user\" : { \"name\" : \"Alice\" , \"role\" : \"user\" } } # Create a new structure with modified value new_data = set_ ( data , \"user.role\" , \"admin\" ) # Original unchanged print ( data [ \"user\" ][ \"role\" ]) # \"user\" print ( new_data [ \"user\" ][ \"role\" ]) # \"admin\" delete - Remove a path \u00b6 from shape.dotmod import delete data = { \"user\" : { \"name\" : \"Alice\" , \"email\" : \"alice@example.com\" , \"temp_token\" : \"xyz123\" } } # Remove temporary token clean_data = delete ( data , \"user.temp_token\" ) # {\"user\": {\"name\": \"Alice\", \"email\": \"alice@example.com\"}} update - Apply a function to a value \u00b6 from shape.dotmod import update data = { \"product\" : { \"name\" : \"Widget\" , \"price\" : 10.00 } } # Apply discount discounted = update ( data , \"product.price\" , lambda p : p * 0.9 ) # {\"product\": {\"name\": \"Widget\", \"price\": 9.00}} Creating Nested Structures \u00b6 dotmod automatically creates intermediate structures as needed: from shape.dotmod import set_ data = {} # Creates nested structure result = set_ ( data , \"user.profile.settings.theme\" , \"dark\" ) # { # \"user\": { # \"profile\": { # \"settings\": { # \"theme\": \"dark\" # } # } # } # } Working with Lists \u00b6 Modify list elements by index: data = { \"items\" : [ { \"id\" : 1 , \"status\" : \"pending\" }, { \"id\" : 2 , \"status\" : \"pending\" }, { \"id\" : 3 , \"status\" : \"pending\" } ] } # Update second item's status result = set_ ( data , \"items.1.status\" , \"completed\" ) # Extend lists automatically result = set_ ( data , \"items.3.status\" , \"new\" ) # Automatically extends the list Immutability Guarantees \u00b6 All operations return new structures with shared, unchanged parts: original = { \"a\" : { \"x\" : 1 , \"y\" : 2 }, \"b\" : { \"x\" : 3 , \"y\" : 4 } } # Modify a.x modified = set_ ( original , \"a.x\" , 10 ) # Only 'a' is cloned, 'b' is shared assert original [ \"b\" ] is modified [ \"b\" ] # True (shared) assert original [ \"a\" ] is not modified [ \"a\" ] # True (cloned) Real-World Examples \u00b6 Configuration Updates \u00b6 config = { \"server\" : { \"host\" : \"localhost\" , \"port\" : 8080 , \"ssl\" : False } } # Update for production prod_config = ( set_ ( config , \"server.host\" , \"api.example.com\" ) |> set_ ( \"server.port\" , 443 ) |> set_ ( \"server.ssl\" , True ) ) State Management \u00b6 app_state = { \"user\" : { \"id\" : 1 , \"name\" : \"Alice\" }, \"ui\" : { \"theme\" : \"light\" , \"sidebar\" : True } } # User action: toggle theme new_state = update ( app_state , \"ui.theme\" , lambda t : \"dark\" if t == \"light\" else \"light\" ) Data Sanitization \u00b6 user_data = { \"profile\" : { \"name\" : \"Alice\" , \"email\" : \"alice@example.com\" , \"password\" : \"secret123\" , # Don't send to client! \"ssn\" : \"123-45-6789\" # Sensitive! } } # Remove sensitive fields public_data = ( delete ( user_data , \"profile.password\" ) |> delete ( \"profile.ssn\" ) ) Integration with Other Tools \u00b6 from depth.dotget import get from shape.dotmod import set_ from truth.dotexists import check def safe_increment ( data , path , amount = 1 ): \"\"\"Safely increment a numeric value.\"\"\" if check ( data , path ): current = get ( data , path ) or 0 return set_ ( data , path , current + amount ) return set_ ( data , path , amount ) Mathematical Foundation \u00b6 dotmod implements a functional update operation that preserves referential transparency: - Immutability : f(data) produces new data, original unchanged - Path-based addressing : Updates are localized to paths - Structural sharing : Unchanged parts share memory Related Tools \u00b6 dotbatch - Atomic batch operations dotpipe - Chain transformations dotget - Read values from paths","title":"dotmod"},{"location":"tools/shape/dotmod/#dotmod","text":"Immutable modifications to nested data structures Part of the Shape pillar, dotmod provides surgical, immutable modifications to nested data structures using dot notation paths.","title":"dotmod"},{"location":"tools/shape/dotmod/#overview","text":"dotmod enables you to modify values deep within nested structures without mutating the original data, following functional programming principles.","title":"Overview"},{"location":"tools/shape/dotmod/#core-operations","text":"","title":"Core Operations"},{"location":"tools/shape/dotmod/#set_-set-a-value-at-a-path","text":"from shape.dotmod import set_ data = { \"user\" : { \"name\" : \"Alice\" , \"role\" : \"user\" } } # Create a new structure with modified value new_data = set_ ( data , \"user.role\" , \"admin\" ) # Original unchanged print ( data [ \"user\" ][ \"role\" ]) # \"user\" print ( new_data [ \"user\" ][ \"role\" ]) # \"admin\"","title":"set_ - Set a value at a path"},{"location":"tools/shape/dotmod/#delete-remove-a-path","text":"from shape.dotmod import delete data = { \"user\" : { \"name\" : \"Alice\" , \"email\" : \"alice@example.com\" , \"temp_token\" : \"xyz123\" } } # Remove temporary token clean_data = delete ( data , \"user.temp_token\" ) # {\"user\": {\"name\": \"Alice\", \"email\": \"alice@example.com\"}}","title":"delete - Remove a path"},{"location":"tools/shape/dotmod/#update-apply-a-function-to-a-value","text":"from shape.dotmod import update data = { \"product\" : { \"name\" : \"Widget\" , \"price\" : 10.00 } } # Apply discount discounted = update ( data , \"product.price\" , lambda p : p * 0.9 ) # {\"product\": {\"name\": \"Widget\", \"price\": 9.00}}","title":"update - Apply a function to a value"},{"location":"tools/shape/dotmod/#creating-nested-structures","text":"dotmod automatically creates intermediate structures as needed: from shape.dotmod import set_ data = {} # Creates nested structure result = set_ ( data , \"user.profile.settings.theme\" , \"dark\" ) # { # \"user\": { # \"profile\": { # \"settings\": { # \"theme\": \"dark\" # } # } # } # }","title":"Creating Nested Structures"},{"location":"tools/shape/dotmod/#working-with-lists","text":"Modify list elements by index: data = { \"items\" : [ { \"id\" : 1 , \"status\" : \"pending\" }, { \"id\" : 2 , \"status\" : \"pending\" }, { \"id\" : 3 , \"status\" : \"pending\" } ] } # Update second item's status result = set_ ( data , \"items.1.status\" , \"completed\" ) # Extend lists automatically result = set_ ( data , \"items.3.status\" , \"new\" ) # Automatically extends the list","title":"Working with Lists"},{"location":"tools/shape/dotmod/#immutability-guarantees","text":"All operations return new structures with shared, unchanged parts: original = { \"a\" : { \"x\" : 1 , \"y\" : 2 }, \"b\" : { \"x\" : 3 , \"y\" : 4 } } # Modify a.x modified = set_ ( original , \"a.x\" , 10 ) # Only 'a' is cloned, 'b' is shared assert original [ \"b\" ] is modified [ \"b\" ] # True (shared) assert original [ \"a\" ] is not modified [ \"a\" ] # True (cloned)","title":"Immutability Guarantees"},{"location":"tools/shape/dotmod/#real-world-examples","text":"","title":"Real-World Examples"},{"location":"tools/shape/dotmod/#configuration-updates","text":"config = { \"server\" : { \"host\" : \"localhost\" , \"port\" : 8080 , \"ssl\" : False } } # Update for production prod_config = ( set_ ( config , \"server.host\" , \"api.example.com\" ) |> set_ ( \"server.port\" , 443 ) |> set_ ( \"server.ssl\" , True ) )","title":"Configuration Updates"},{"location":"tools/shape/dotmod/#state-management","text":"app_state = { \"user\" : { \"id\" : 1 , \"name\" : \"Alice\" }, \"ui\" : { \"theme\" : \"light\" , \"sidebar\" : True } } # User action: toggle theme new_state = update ( app_state , \"ui.theme\" , lambda t : \"dark\" if t == \"light\" else \"light\" )","title":"State Management"},{"location":"tools/shape/dotmod/#data-sanitization","text":"user_data = { \"profile\" : { \"name\" : \"Alice\" , \"email\" : \"alice@example.com\" , \"password\" : \"secret123\" , # Don't send to client! \"ssn\" : \"123-45-6789\" # Sensitive! } } # Remove sensitive fields public_data = ( delete ( user_data , \"profile.password\" ) |> delete ( \"profile.ssn\" ) )","title":"Data Sanitization"},{"location":"tools/shape/dotmod/#integration-with-other-tools","text":"from depth.dotget import get from shape.dotmod import set_ from truth.dotexists import check def safe_increment ( data , path , amount = 1 ): \"\"\"Safely increment a numeric value.\"\"\" if check ( data , path ): current = get ( data , path ) or 0 return set_ ( data , path , current + amount ) return set_ ( data , path , amount )","title":"Integration with Other Tools"},{"location":"tools/shape/dotmod/#mathematical-foundation","text":"dotmod implements a functional update operation that preserves referential transparency: - Immutability : f(data) produces new data, original unchanged - Path-based addressing : Updates are localized to paths - Structural sharing : Unchanged parts share memory","title":"Mathematical Foundation"},{"location":"tools/shape/dotmod/#related-tools","text":"dotbatch - Atomic batch operations dotpipe - Chain transformations dotget - Read values from paths","title":"Related Tools"},{"location":"tools/shape/dotpipe/","text":"dotpipe \u00b6 Composable transformation pipelines Part of the Shape pillar, dotpipe enables building complex data transformations through function composition. Overview \u00b6 dotpipe provides a clean, functional approach to chaining data transformations, making complex operations readable and maintainable. Basic Usage \u00b6 from shape.dotpipe import pipe , compose # Create a pipeline pipeline = pipe ( lambda x : x * 2 , # Double lambda x : x + 10 , # Add 10 lambda x : x / 2 # Halve ) result = pipeline ( 5 ) # ((5 * 2) + 10) / 2 = 10 Working with Nested Data \u00b6 Combine with other dotsuite tools: from shape.dotpipe import pipe from shape.dotmod import set_ , update from depth.dotget import get # Complex transformation pipeline process_user = pipe ( lambda d : set_ ( d , \"user.verified\" , True ), lambda d : update ( d , \"user.name\" , str . upper ), lambda d : set_ ( d , \"user.processed_at\" , \"2024-01-01\" ), lambda d : delete ( d , \"user.temp_data\" ) ) data = { \"user\" : { \"name\" : \"alice\" , \"verified\" : False , \"temp_data\" : \"cleanup\" } } result = process_user ( data ) # { # \"user\": { # \"name\": \"ALICE\", # \"verified\": True, # \"processed_at\": \"2024-01-01\" # } # } Compose vs Pipe \u00b6 pipe : Left-to-right composition (first \u2192 last) compose : Right-to-left composition (last \u2192 first) from shape.dotpipe import pipe , compose # These are equivalent: pipeline1 = pipe ( f , g , h ) # h(g(f(x))) pipeline2 = compose ( h , g , f ) # h(g(f(x))) Partial Pipelines \u00b6 Build reusable transformation components: # Reusable transformations normalize_user = pipe ( lambda d : update ( d , \"email\" , str . lower ), lambda d : update ( d , \"name\" , str . title ) ) add_timestamps = pipe ( lambda d : set_ ( d , \"created_at\" , now ()), lambda d : set_ ( d , \"updated_at\" , now ()) ) validate_user = pipe ( lambda d : d if get ( d , \"email\" ) else raise_error ( \"Email required\" ), lambda d : d if get ( d , \"name\" ) else raise_error ( \"Name required\" ) ) # Combine into full pipeline process_new_user = pipe ( normalize_user , validate_user , add_timestamps ) Real-World Examples \u00b6 Data Cleaning Pipeline \u00b6 clean_product_data = pipe ( # Normalize strings lambda d : update ( d , \"name\" , lambda n : n . strip () . title ()), lambda d : update ( d , \"sku\" , lambda s : s . upper () . replace ( \"-\" , \"\" )), # Validate price lambda d : set_ ( d , \"price\" , max ( 0 , get ( d , \"price\" ) or 0 )), # Add computed fields lambda d : set_ ( d , \"display_price\" , f \"$ { get ( d , 'price' ) : .2f } \" ), # Remove internal fields lambda d : delete ( d , \"_internal_id\" ), lambda d : delete ( d , \"_raw_import\" ) ) API Response Transformation \u00b6 transform_api_response = pipe ( # Extract data envelope lambda r : get ( r , \"data\" ) or {}, # Rename fields lambda d : set_ ( d , \"userId\" , get ( d , \"user_id\" )), lambda d : delete ( d , \"user_id\" ), # Flatten nested structure lambda d : { ** d , ** get ( d , \"attributes\" , {})}, lambda d : delete ( d , \"attributes\" ), # Add metadata lambda d : set_ ( d , \"fetched_at\" , datetime . now () . isoformat ()) ) Form Processing \u00b6 process_form_submission = pipe ( # Sanitize inputs lambda f : { k : v . strip () if isinstance ( v , str ) else v for k , v in f . items ()}, # Validate required fields lambda f : f if all ( get ( f , field ) for field in [ \"email\" , \"name\" ]) else raise_error ( \"Missing required fields\" ), # Normalize email lambda f : update ( f , \"email\" , str . lower ), # Hash password if present lambda f : update ( f , \"password\" , hash_password ) if get ( f , \"password\" ) else f , # Add metadata lambda f : set_ ( f , \"submitted_at\" , datetime . now ()), lambda f : set_ ( f , \"ip_address\" , get_client_ip ()) ) Async Pipelines \u00b6 For async transformations: from shape.dotpipe import async_pipe process_async = async_pipe ( fetch_user_data , # async function enrich_with_api , # async function save_to_database # async function ) result = await process_async ( user_id ) Mathematical Foundation \u00b6 dotpipe implements function composition from category theory: - Associativity : pipe(f, pipe(g, h)) = pipe(pipe(f, g), h) - Identity : pipe(identity, f) = f = pipe(f, identity) - Functorial : Preserves structure of transformations Related Tools \u00b6 dotmod - Individual modifications dotbatch - Atomic batch operations dotpluck - Extract and reshape data","title":"dotpipe"},{"location":"tools/shape/dotpipe/#dotpipe","text":"Composable transformation pipelines Part of the Shape pillar, dotpipe enables building complex data transformations through function composition.","title":"dotpipe"},{"location":"tools/shape/dotpipe/#overview","text":"dotpipe provides a clean, functional approach to chaining data transformations, making complex operations readable and maintainable.","title":"Overview"},{"location":"tools/shape/dotpipe/#basic-usage","text":"from shape.dotpipe import pipe , compose # Create a pipeline pipeline = pipe ( lambda x : x * 2 , # Double lambda x : x + 10 , # Add 10 lambda x : x / 2 # Halve ) result = pipeline ( 5 ) # ((5 * 2) + 10) / 2 = 10","title":"Basic Usage"},{"location":"tools/shape/dotpipe/#working-with-nested-data","text":"Combine with other dotsuite tools: from shape.dotpipe import pipe from shape.dotmod import set_ , update from depth.dotget import get # Complex transformation pipeline process_user = pipe ( lambda d : set_ ( d , \"user.verified\" , True ), lambda d : update ( d , \"user.name\" , str . upper ), lambda d : set_ ( d , \"user.processed_at\" , \"2024-01-01\" ), lambda d : delete ( d , \"user.temp_data\" ) ) data = { \"user\" : { \"name\" : \"alice\" , \"verified\" : False , \"temp_data\" : \"cleanup\" } } result = process_user ( data ) # { # \"user\": { # \"name\": \"ALICE\", # \"verified\": True, # \"processed_at\": \"2024-01-01\" # } # }","title":"Working with Nested Data"},{"location":"tools/shape/dotpipe/#compose-vs-pipe","text":"pipe : Left-to-right composition (first \u2192 last) compose : Right-to-left composition (last \u2192 first) from shape.dotpipe import pipe , compose # These are equivalent: pipeline1 = pipe ( f , g , h ) # h(g(f(x))) pipeline2 = compose ( h , g , f ) # h(g(f(x)))","title":"Compose vs Pipe"},{"location":"tools/shape/dotpipe/#partial-pipelines","text":"Build reusable transformation components: # Reusable transformations normalize_user = pipe ( lambda d : update ( d , \"email\" , str . lower ), lambda d : update ( d , \"name\" , str . title ) ) add_timestamps = pipe ( lambda d : set_ ( d , \"created_at\" , now ()), lambda d : set_ ( d , \"updated_at\" , now ()) ) validate_user = pipe ( lambda d : d if get ( d , \"email\" ) else raise_error ( \"Email required\" ), lambda d : d if get ( d , \"name\" ) else raise_error ( \"Name required\" ) ) # Combine into full pipeline process_new_user = pipe ( normalize_user , validate_user , add_timestamps )","title":"Partial Pipelines"},{"location":"tools/shape/dotpipe/#real-world-examples","text":"","title":"Real-World Examples"},{"location":"tools/shape/dotpipe/#data-cleaning-pipeline","text":"clean_product_data = pipe ( # Normalize strings lambda d : update ( d , \"name\" , lambda n : n . strip () . title ()), lambda d : update ( d , \"sku\" , lambda s : s . upper () . replace ( \"-\" , \"\" )), # Validate price lambda d : set_ ( d , \"price\" , max ( 0 , get ( d , \"price\" ) or 0 )), # Add computed fields lambda d : set_ ( d , \"display_price\" , f \"$ { get ( d , 'price' ) : .2f } \" ), # Remove internal fields lambda d : delete ( d , \"_internal_id\" ), lambda d : delete ( d , \"_raw_import\" ) )","title":"Data Cleaning Pipeline"},{"location":"tools/shape/dotpipe/#api-response-transformation","text":"transform_api_response = pipe ( # Extract data envelope lambda r : get ( r , \"data\" ) or {}, # Rename fields lambda d : set_ ( d , \"userId\" , get ( d , \"user_id\" )), lambda d : delete ( d , \"user_id\" ), # Flatten nested structure lambda d : { ** d , ** get ( d , \"attributes\" , {})}, lambda d : delete ( d , \"attributes\" ), # Add metadata lambda d : set_ ( d , \"fetched_at\" , datetime . now () . isoformat ()) )","title":"API Response Transformation"},{"location":"tools/shape/dotpipe/#form-processing","text":"process_form_submission = pipe ( # Sanitize inputs lambda f : { k : v . strip () if isinstance ( v , str ) else v for k , v in f . items ()}, # Validate required fields lambda f : f if all ( get ( f , field ) for field in [ \"email\" , \"name\" ]) else raise_error ( \"Missing required fields\" ), # Normalize email lambda f : update ( f , \"email\" , str . lower ), # Hash password if present lambda f : update ( f , \"password\" , hash_password ) if get ( f , \"password\" ) else f , # Add metadata lambda f : set_ ( f , \"submitted_at\" , datetime . now ()), lambda f : set_ ( f , \"ip_address\" , get_client_ip ()) )","title":"Form Processing"},{"location":"tools/shape/dotpipe/#async-pipelines","text":"For async transformations: from shape.dotpipe import async_pipe process_async = async_pipe ( fetch_user_data , # async function enrich_with_api , # async function save_to_database # async function ) result = await process_async ( user_id )","title":"Async Pipelines"},{"location":"tools/shape/dotpipe/#mathematical-foundation","text":"dotpipe implements function composition from category theory: - Associativity : pipe(f, pipe(g, h)) = pipe(pipe(f, g), h) - Identity : pipe(identity, f) = f = pipe(f, identity) - Functorial : Preserves structure of transformations","title":"Mathematical Foundation"},{"location":"tools/shape/dotpipe/#related-tools","text":"dotmod - Individual modifications dotbatch - Atomic batch operations dotpluck - Extract and reshape data","title":"Related Tools"},{"location":"tools/shape/dotpluck/","text":"dotpluck \u00b6 Project data into new shapes - the Shape pillar's primitive Overview \u00b6 dotpluck is the foundational tool in the Shape pillar. Unlike dotget which navigates to values, dotpluck RESHAPES data by projecting selected parts into new structures. It's not about extraction, but about creating new shapes from existing data - the \"Hello World\" of data transformation. Installation \u00b6 # As part of dotsuite pip install dotsuite # Or from source cd src/shape/dotpluck pip install -e . Core Functions \u00b6 pluck(data, shape) \u00b6 Project data into a new shape by extracting and restructuring selected paths. from shape.dotpluck.core import pluck data = { \"user\" : { \"firstName\" : \"Alice\" , \"lastName\" : \"Smith\" , \"age\" : 30 , \"email\" : \"alice@example.com\" }, \"settings\" : { \"theme\" : \"dark\" } } # Create a new shape result = pluck ( data , { \"name\" : \"user.firstName\" , \"years\" : \"user.age\" , \"contact\" : \"user.email\" }) # Returns: {'name': 'Alice', 'years': 30, 'contact': 'alice@example.com'} # Nested reshaping result = pluck ( data , { \"person\" : { \"first\" : \"user.firstName\" , \"last\" : \"user.lastName\" }, \"preferences\" : { \"display\" : \"settings.theme\" } }) # Returns: {'person': {'first': 'Alice', 'last': 'Smith'}, 'preferences': {'display': 'dark'}} pluck_simple(data, **paths) \u00b6 Simple projection - convenience wrapper for flat reshaping. from shape.dotpluck.core import pluck_simple data = { \"customer\" : { \"firstName\" : \"Alice\" , \"lastName\" : \"Smith\" , \"yearsOld\" : 30 } } # Create new flat structure result = pluck_simple ( data , name = \"customer.firstName\" , surname = \"customer.lastName\" , age = \"customer.yearsOld\" ) # Returns: {'name': 'Alice', 'surname': 'Smith', 'age': 30} pluck_subset(data, path, *keys) \u00b6 Project a subset of an object's fields. from shape.dotpluck.core import pluck_subset data = { \"user\" : { \"id\" : 123 , \"name\" : \"Alice\" , \"email\" : \"alice@example.com\" , \"password\" : \"secret\" , \"created_at\" : \"2024-01-01\" } } # Extract only public fields public_info = pluck_subset ( data , \"user\" , \"id\" , \"name\" , \"email\" ) # Returns: {'id': 123, 'name': 'Alice', 'email': 'alice@example.com'} pluck_list(data, *paths) \u00b6 Project values into a simple list (no keys). from shape.dotpluck.core import pluck_list data = { \"user\" : { \"name\" : \"Alice\" , \"age\" : 30 }} # When you just need values, not structure values = pluck_list ( data , \"user.name\" , \"user.age\" , \"user.role\" ) # Returns: ['Alice', 30, None] Command Line Usage \u00b6 # Reshape data with a shape specification echo '{\"user\": {\"name\": \"Alice\", \"age\": 30}}' | dotpluck - '{\"name\": \"user.name\", \"years\": \"user.age\"}' # Extract specific fields as a list dotpluck data.json --list user.name user.email user.role # Project a subset of fields dotpluck data.json --subset user id name email Common Use Cases \u00b6 1. API Response Reshaping \u00b6 Transform API responses into the shape your application needs: api_response = { \"data\" : { \"user\" : { \"id\" : 123 , \"name\" : \"Alice\" , \"email\" : \"alice@example.com\" , \"internal_id\" : \"xyz789\" , \"created_at\" : \"2024-01-01T00:00:00Z\" , \"last_login\" : \"2024-01-15T10:30:00Z\" , \"_metadata\" : { ... } }, \"subscription\" : { \"plan\" : \"premium\" , \"expires\" : \"2025-01-01\" } } } # Reshape for your UI component ui_data = pluck ( api_response , { \"user\" : { \"id\" : \"data.user.id\" , \"name\" : \"data.user.name\" , \"email\" : \"data.user.email\" }, \"subscription\" : \"data.subscription.plan\" , \"isPremium\" : True # Static value }) # Returns: structured data ready for your UI 2. Configuration Reshaping \u00b6 Create deployment-specific configurations: full_config = { \"database\" : { \"host\" : \"localhost\" , \"port\" : 5432 , \"name\" : \"myapp\" , \"pool_size\" : 10 }, \"cache\" : { \"host\" : \"localhost\" , \"port\" : 6379 }, \"logging\" : { \"level\" : \"debug\" , \"file\" : \"/var/log/app.log\" } } # Create environment-specific config production_config = pluck ( full_config , { \"connections\" : { \"db\" : \"database.host\" , \"cache\" : \"cache.host\" }, \"database\" : { \"name\" : \"database.name\" , \"pool\" : \"database.pool_size\" }, \"log_level\" : \"warning\" # Override for production }) 3. Data Schema Migration \u00b6 Migrate between different data schemas: old_format = { \"customer_info\" : { \"personal\" : { \"first_name\" : \"Alice\" , \"last_name\" : \"Smith\" }, \"contact\" : { \"email_address\" : \"alice@example.com\" , \"phone\" : \"+1234567890\" }, \"account\" : { \"created\" : \"2020-01-01\" , \"type\" : \"premium\" } } } # Migrate to new nested schema new_format = pluck ( old_format , { \"profile\" : { \"name\" : { \"first\" : \"customer_info.personal.first_name\" , \"last\" : \"customer_info.personal.last_name\" }, \"contactMethods\" : { \"primary\" : \"customer_info.contact.email_address\" , \"phone\" : \"customer_info.contact.phone\" } }, \"metadata\" : { \"accountType\" : \"customer_info.account.type\" , \"customerSince\" : \"customer_info.account.created\" } }) Philosophy \u00b6 dotpluck represents the Shape pillar's core concept: reshaping data into new forms. While it uses dotget internally, its purpose is fundamentally different - it's about projection and transformation, not just extraction. The implementation is pedagogically simple but conceptually powerful: def pluck ( data , shape ): \"\"\"Project data into a new shape.\"\"\" if isinstance ( shape , dict ): return { k : pluck ( data , v ) for k , v in shape . items ()} elif isinstance ( shape , str ): return get ( data , shape ) # Path to extract else : return shape # Static value This recursive structure allows arbitrary reshaping while maintaining simplicity. Comparison with Other Tools \u00b6 Tool Purpose Philosophy Returns dotget Navigate to single value Depth pillar - finding data Single value dotpluck Reshape/project data Shape pillar - transformation New structure dotstar Search with patterns Depth pillar - pattern matching List of matches dotmod Modify in place Shape pillar - surgical edits Modified document The key distinction: dotget and dotstar are about FINDING data (Depth pillar), while dotpluck and dotmod are about RESHAPING data (Shape pillar). See Also \u00b6 dotget - Simple single value extraction dotmod - Modify documents dotpipe - Transform documents","title":"dotpluck"},{"location":"tools/shape/dotpluck/#dotpluck","text":"Project data into new shapes - the Shape pillar's primitive","title":"dotpluck"},{"location":"tools/shape/dotpluck/#overview","text":"dotpluck is the foundational tool in the Shape pillar. Unlike dotget which navigates to values, dotpluck RESHAPES data by projecting selected parts into new structures. It's not about extraction, but about creating new shapes from existing data - the \"Hello World\" of data transformation.","title":"Overview"},{"location":"tools/shape/dotpluck/#installation","text":"# As part of dotsuite pip install dotsuite # Or from source cd src/shape/dotpluck pip install -e .","title":"Installation"},{"location":"tools/shape/dotpluck/#core-functions","text":"","title":"Core Functions"},{"location":"tools/shape/dotpluck/#pluckdata-shape","text":"Project data into a new shape by extracting and restructuring selected paths. from shape.dotpluck.core import pluck data = { \"user\" : { \"firstName\" : \"Alice\" , \"lastName\" : \"Smith\" , \"age\" : 30 , \"email\" : \"alice@example.com\" }, \"settings\" : { \"theme\" : \"dark\" } } # Create a new shape result = pluck ( data , { \"name\" : \"user.firstName\" , \"years\" : \"user.age\" , \"contact\" : \"user.email\" }) # Returns: {'name': 'Alice', 'years': 30, 'contact': 'alice@example.com'} # Nested reshaping result = pluck ( data , { \"person\" : { \"first\" : \"user.firstName\" , \"last\" : \"user.lastName\" }, \"preferences\" : { \"display\" : \"settings.theme\" } }) # Returns: {'person': {'first': 'Alice', 'last': 'Smith'}, 'preferences': {'display': 'dark'}}","title":"pluck(data, shape)"},{"location":"tools/shape/dotpluck/#pluck_simpledata-paths","text":"Simple projection - convenience wrapper for flat reshaping. from shape.dotpluck.core import pluck_simple data = { \"customer\" : { \"firstName\" : \"Alice\" , \"lastName\" : \"Smith\" , \"yearsOld\" : 30 } } # Create new flat structure result = pluck_simple ( data , name = \"customer.firstName\" , surname = \"customer.lastName\" , age = \"customer.yearsOld\" ) # Returns: {'name': 'Alice', 'surname': 'Smith', 'age': 30}","title":"pluck_simple(data, **paths)"},{"location":"tools/shape/dotpluck/#pluck_subsetdata-path-keys","text":"Project a subset of an object's fields. from shape.dotpluck.core import pluck_subset data = { \"user\" : { \"id\" : 123 , \"name\" : \"Alice\" , \"email\" : \"alice@example.com\" , \"password\" : \"secret\" , \"created_at\" : \"2024-01-01\" } } # Extract only public fields public_info = pluck_subset ( data , \"user\" , \"id\" , \"name\" , \"email\" ) # Returns: {'id': 123, 'name': 'Alice', 'email': 'alice@example.com'}","title":"pluck_subset(data, path, *keys)"},{"location":"tools/shape/dotpluck/#pluck_listdata-paths","text":"Project values into a simple list (no keys). from shape.dotpluck.core import pluck_list data = { \"user\" : { \"name\" : \"Alice\" , \"age\" : 30 }} # When you just need values, not structure values = pluck_list ( data , \"user.name\" , \"user.age\" , \"user.role\" ) # Returns: ['Alice', 30, None]","title":"pluck_list(data, *paths)"},{"location":"tools/shape/dotpluck/#command-line-usage","text":"# Reshape data with a shape specification echo '{\"user\": {\"name\": \"Alice\", \"age\": 30}}' | dotpluck - '{\"name\": \"user.name\", \"years\": \"user.age\"}' # Extract specific fields as a list dotpluck data.json --list user.name user.email user.role # Project a subset of fields dotpluck data.json --subset user id name email","title":"Command Line Usage"},{"location":"tools/shape/dotpluck/#common-use-cases","text":"","title":"Common Use Cases"},{"location":"tools/shape/dotpluck/#1-api-response-reshaping","text":"Transform API responses into the shape your application needs: api_response = { \"data\" : { \"user\" : { \"id\" : 123 , \"name\" : \"Alice\" , \"email\" : \"alice@example.com\" , \"internal_id\" : \"xyz789\" , \"created_at\" : \"2024-01-01T00:00:00Z\" , \"last_login\" : \"2024-01-15T10:30:00Z\" , \"_metadata\" : { ... } }, \"subscription\" : { \"plan\" : \"premium\" , \"expires\" : \"2025-01-01\" } } } # Reshape for your UI component ui_data = pluck ( api_response , { \"user\" : { \"id\" : \"data.user.id\" , \"name\" : \"data.user.name\" , \"email\" : \"data.user.email\" }, \"subscription\" : \"data.subscription.plan\" , \"isPremium\" : True # Static value }) # Returns: structured data ready for your UI","title":"1. API Response Reshaping"},{"location":"tools/shape/dotpluck/#2-configuration-reshaping","text":"Create deployment-specific configurations: full_config = { \"database\" : { \"host\" : \"localhost\" , \"port\" : 5432 , \"name\" : \"myapp\" , \"pool_size\" : 10 }, \"cache\" : { \"host\" : \"localhost\" , \"port\" : 6379 }, \"logging\" : { \"level\" : \"debug\" , \"file\" : \"/var/log/app.log\" } } # Create environment-specific config production_config = pluck ( full_config , { \"connections\" : { \"db\" : \"database.host\" , \"cache\" : \"cache.host\" }, \"database\" : { \"name\" : \"database.name\" , \"pool\" : \"database.pool_size\" }, \"log_level\" : \"warning\" # Override for production })","title":"2. Configuration Reshaping"},{"location":"tools/shape/dotpluck/#3-data-schema-migration","text":"Migrate between different data schemas: old_format = { \"customer_info\" : { \"personal\" : { \"first_name\" : \"Alice\" , \"last_name\" : \"Smith\" }, \"contact\" : { \"email_address\" : \"alice@example.com\" , \"phone\" : \"+1234567890\" }, \"account\" : { \"created\" : \"2020-01-01\" , \"type\" : \"premium\" } } } # Migrate to new nested schema new_format = pluck ( old_format , { \"profile\" : { \"name\" : { \"first\" : \"customer_info.personal.first_name\" , \"last\" : \"customer_info.personal.last_name\" }, \"contactMethods\" : { \"primary\" : \"customer_info.contact.email_address\" , \"phone\" : \"customer_info.contact.phone\" } }, \"metadata\" : { \"accountType\" : \"customer_info.account.type\" , \"customerSince\" : \"customer_info.account.created\" } })","title":"3. Data Schema Migration"},{"location":"tools/shape/dotpluck/#philosophy","text":"dotpluck represents the Shape pillar's core concept: reshaping data into new forms. While it uses dotget internally, its purpose is fundamentally different - it's about projection and transformation, not just extraction. The implementation is pedagogically simple but conceptually powerful: def pluck ( data , shape ): \"\"\"Project data into a new shape.\"\"\" if isinstance ( shape , dict ): return { k : pluck ( data , v ) for k , v in shape . items ()} elif isinstance ( shape , str ): return get ( data , shape ) # Path to extract else : return shape # Static value This recursive structure allows arbitrary reshaping while maintaining simplicity.","title":"Philosophy"},{"location":"tools/shape/dotpluck/#comparison-with-other-tools","text":"Tool Purpose Philosophy Returns dotget Navigate to single value Depth pillar - finding data Single value dotpluck Reshape/project data Shape pillar - transformation New structure dotstar Search with patterns Depth pillar - pattern matching List of matches dotmod Modify in place Shape pillar - surgical edits Modified document The key distinction: dotget and dotstar are about FINDING data (Depth pillar), while dotpluck and dotmod are about RESHAPING data (Shape pillar).","title":"Comparison with Other Tools"},{"location":"tools/shape/dotpluck/#see-also","text":"dotget - Simple single value extraction dotmod - Modify documents dotpipe - Transform documents","title":"See Also"},{"location":"tools/truth/dotall/","text":"dotall \u00b6 Universal quantifier for collections Part of the Truth pillar, dotall checks if all items in a collection satisfy a condition. Overview \u00b6 dotall implements the universal quantifier (\u2200) from mathematical logic, returning True if every item in a collection matches a specified value at a given path. Basic Usage \u00b6 from truth.dotall import all_match users = [ { \"name\" : \"Alice\" , \"verified\" : True }, { \"name\" : \"Bob\" , \"verified\" : True }, { \"name\" : \"Charlie\" , \"verified\" : True } ] # Check if all users are verified all_verified = all_match ( users , \"verified\" , True ) # True # Add an unverified user users . append ({ \"name\" : \"David\" , \"verified\" : False }) all_verified = all_match ( users , \"verified\" , True ) # False Nested Paths \u00b6 Works with nested data structures: data = [ { \"user\" : { \"status\" : { \"active\" : True }}}, { \"user\" : { \"status\" : { \"active\" : True }}}, { \"user\" : { \"status\" : { \"active\" : True }}} ] # Check if all users are active all_active = all_match ( data , \"user.status.active\" , True ) # True Edge Cases \u00b6 Empty Collections (Vacuous Truth) \u00b6 Returns True for empty collections (vacuous truth in logic): empty = [] result = all_match ( empty , \"any.path\" , \"value\" ) # True # \"All items in an empty set satisfy any condition\" Missing Paths \u00b6 Items with missing paths are treated as non-matching: data = [ { \"name\" : \"Alice\" , \"age\" : 30 }, { \"name\" : \"Bob\" } # Missing age ] # Bob doesn't have age field all_age_30 = all_match ( data , \"age\" , 30 ) # False Mathematical Properties \u00b6 Vacuous truth : Empty collections always return True Universal quantification : \u2200x \u2208 collection : predicate(x) Dual of dotany : all and any form a duality in boolean logic De Morgan's laws : not(all(p)) \u2261 any(not(p)) Integration with dotquery \u00b6 dotall is used internally by dotquery for collection queries: from truth.dotquery import Query # These are equivalent: q = Query ( \"all users.verified equals true\" ) # vs from truth.dotall import all_match result = all_match ( users , \"verified\" , True ) Real-World Examples \u00b6 Data Validation \u00b6 # Ensure all products have required fields products = [ { \"name\" : \"Widget\" , \"price\" : 9.99 , \"sku\" : \"W001\" }, { \"name\" : \"Gadget\" , \"price\" : 19.99 , \"sku\" : \"G001\" } ] # All products must have positive prices valid = all_match ( products , \"price\" , lambda x : x > 0 ) Permission Checking \u00b6 # Check if all team members have access team = [ { \"name\" : \"Alice\" , \"permissions\" : [ \"read\" , \"write\" ]}, { \"name\" : \"Bob\" , \"permissions\" : [ \"read\" , \"write\" ]} ] # All must have write permission can_edit = all_match ( team , \"permissions\" , lambda p : \"write\" in p ) Related Tools \u00b6 dotany - Existential quantifier (at least one matches) dotexists - Check path existence dotquery - Complex boolean queries dotfilter - Filter collections","title":"dotall"},{"location":"tools/truth/dotall/#dotall","text":"Universal quantifier for collections Part of the Truth pillar, dotall checks if all items in a collection satisfy a condition.","title":"dotall"},{"location":"tools/truth/dotall/#overview","text":"dotall implements the universal quantifier (\u2200) from mathematical logic, returning True if every item in a collection matches a specified value at a given path.","title":"Overview"},{"location":"tools/truth/dotall/#basic-usage","text":"from truth.dotall import all_match users = [ { \"name\" : \"Alice\" , \"verified\" : True }, { \"name\" : \"Bob\" , \"verified\" : True }, { \"name\" : \"Charlie\" , \"verified\" : True } ] # Check if all users are verified all_verified = all_match ( users , \"verified\" , True ) # True # Add an unverified user users . append ({ \"name\" : \"David\" , \"verified\" : False }) all_verified = all_match ( users , \"verified\" , True ) # False","title":"Basic Usage"},{"location":"tools/truth/dotall/#nested-paths","text":"Works with nested data structures: data = [ { \"user\" : { \"status\" : { \"active\" : True }}}, { \"user\" : { \"status\" : { \"active\" : True }}}, { \"user\" : { \"status\" : { \"active\" : True }}} ] # Check if all users are active all_active = all_match ( data , \"user.status.active\" , True ) # True","title":"Nested Paths"},{"location":"tools/truth/dotall/#edge-cases","text":"","title":"Edge Cases"},{"location":"tools/truth/dotall/#empty-collections-vacuous-truth","text":"Returns True for empty collections (vacuous truth in logic): empty = [] result = all_match ( empty , \"any.path\" , \"value\" ) # True # \"All items in an empty set satisfy any condition\"","title":"Empty Collections (Vacuous Truth)"},{"location":"tools/truth/dotall/#missing-paths","text":"Items with missing paths are treated as non-matching: data = [ { \"name\" : \"Alice\" , \"age\" : 30 }, { \"name\" : \"Bob\" } # Missing age ] # Bob doesn't have age field all_age_30 = all_match ( data , \"age\" , 30 ) # False","title":"Missing Paths"},{"location":"tools/truth/dotall/#mathematical-properties","text":"Vacuous truth : Empty collections always return True Universal quantification : \u2200x \u2208 collection : predicate(x) Dual of dotany : all and any form a duality in boolean logic De Morgan's laws : not(all(p)) \u2261 any(not(p))","title":"Mathematical Properties"},{"location":"tools/truth/dotall/#integration-with-dotquery","text":"dotall is used internally by dotquery for collection queries: from truth.dotquery import Query # These are equivalent: q = Query ( \"all users.verified equals true\" ) # vs from truth.dotall import all_match result = all_match ( users , \"verified\" , True )","title":"Integration with dotquery"},{"location":"tools/truth/dotall/#real-world-examples","text":"","title":"Real-World Examples"},{"location":"tools/truth/dotall/#data-validation","text":"# Ensure all products have required fields products = [ { \"name\" : \"Widget\" , \"price\" : 9.99 , \"sku\" : \"W001\" }, { \"name\" : \"Gadget\" , \"price\" : 19.99 , \"sku\" : \"G001\" } ] # All products must have positive prices valid = all_match ( products , \"price\" , lambda x : x > 0 )","title":"Data Validation"},{"location":"tools/truth/dotall/#permission-checking","text":"# Check if all team members have access team = [ { \"name\" : \"Alice\" , \"permissions\" : [ \"read\" , \"write\" ]}, { \"name\" : \"Bob\" , \"permissions\" : [ \"read\" , \"write\" ]} ] # All must have write permission can_edit = all_match ( team , \"permissions\" , lambda p : \"write\" in p )","title":"Permission Checking"},{"location":"tools/truth/dotall/#related-tools","text":"dotany - Existential quantifier (at least one matches) dotexists - Check path existence dotquery - Complex boolean queries dotfilter - Filter collections","title":"Related Tools"},{"location":"tools/truth/dotany/","text":"dotany \u00b6 Existential quantifier for collections Part of the Truth pillar, dotany checks if at least one item in a collection satisfies a condition. Overview \u00b6 dotany implements the existential quantifier (\u2203) from mathematical logic, returning True if any item in a collection matches a specified value at a given path. Basic Usage \u00b6 from truth.dotany import any_match users = [ { \"name\" : \"Alice\" , \"role\" : \"admin\" }, { \"name\" : \"Bob\" , \"role\" : \"user\" }, { \"name\" : \"Charlie\" , \"role\" : \"user\" } ] # Check if any user is an admin has_admin = any_match ( users , \"role\" , \"admin\" ) # True # Check if any user is named \"David\" has_david = any_match ( users , \"name\" , \"David\" ) # False Nested Paths \u00b6 Works with nested data structures: data = [ { \"user\" : { \"profile\" : { \"age\" : 25 }}}, { \"user\" : { \"profile\" : { \"age\" : 30 }}}, { \"user\" : { \"profile\" : { \"age\" : 35 }}} ] # Check if any user is exactly 30 has_thirty = any_match ( data , \"user.profile.age\" , 30 ) # True Edge Cases \u00b6 Empty Collections \u00b6 Returns False for empty collections (no items to match): empty = [] result = any_match ( empty , \"any.path\" , \"value\" ) # False Missing Paths \u00b6 Items with missing paths are treated as non-matching: data = [ { \"name\" : \"Alice\" }, { \"name\" : \"Bob\" , \"age\" : 30 } ] # Only Bob has age field has_age_30 = any_match ( data , \"age\" , 30 ) # True has_age_25 = any_match ( data , \"age\" , 25 ) # False Mathematical Properties \u00b6 Short-circuit evaluation : Stops as soon as a match is found Existential quantification : \u2203x \u2208 collection : predicate(x) Dual of dotall : any and all form a duality in boolean logic Integration with dotquery \u00b6 dotany is used internally by dotquery for collection queries: from truth.dotquery import Query # These are equivalent: q = Query ( \"any users.role equals admin\" ) # vs from truth.dotany import any_match result = any_match ( users , \"role\" , \"admin\" ) Related Tools \u00b6 dotall - Universal quantifier (all items must match) dotexists - Check path existence dotquery - Complex boolean queries dotfilter - Filter collections","title":"dotany"},{"location":"tools/truth/dotany/#dotany","text":"Existential quantifier for collections Part of the Truth pillar, dotany checks if at least one item in a collection satisfies a condition.","title":"dotany"},{"location":"tools/truth/dotany/#overview","text":"dotany implements the existential quantifier (\u2203) from mathematical logic, returning True if any item in a collection matches a specified value at a given path.","title":"Overview"},{"location":"tools/truth/dotany/#basic-usage","text":"from truth.dotany import any_match users = [ { \"name\" : \"Alice\" , \"role\" : \"admin\" }, { \"name\" : \"Bob\" , \"role\" : \"user\" }, { \"name\" : \"Charlie\" , \"role\" : \"user\" } ] # Check if any user is an admin has_admin = any_match ( users , \"role\" , \"admin\" ) # True # Check if any user is named \"David\" has_david = any_match ( users , \"name\" , \"David\" ) # False","title":"Basic Usage"},{"location":"tools/truth/dotany/#nested-paths","text":"Works with nested data structures: data = [ { \"user\" : { \"profile\" : { \"age\" : 25 }}}, { \"user\" : { \"profile\" : { \"age\" : 30 }}}, { \"user\" : { \"profile\" : { \"age\" : 35 }}} ] # Check if any user is exactly 30 has_thirty = any_match ( data , \"user.profile.age\" , 30 ) # True","title":"Nested Paths"},{"location":"tools/truth/dotany/#edge-cases","text":"","title":"Edge Cases"},{"location":"tools/truth/dotany/#empty-collections","text":"Returns False for empty collections (no items to match): empty = [] result = any_match ( empty , \"any.path\" , \"value\" ) # False","title":"Empty Collections"},{"location":"tools/truth/dotany/#missing-paths","text":"Items with missing paths are treated as non-matching: data = [ { \"name\" : \"Alice\" }, { \"name\" : \"Bob\" , \"age\" : 30 } ] # Only Bob has age field has_age_30 = any_match ( data , \"age\" , 30 ) # True has_age_25 = any_match ( data , \"age\" , 25 ) # False","title":"Missing Paths"},{"location":"tools/truth/dotany/#mathematical-properties","text":"Short-circuit evaluation : Stops as soon as a match is found Existential quantification : \u2203x \u2208 collection : predicate(x) Dual of dotall : any and all form a duality in boolean logic","title":"Mathematical Properties"},{"location":"tools/truth/dotany/#integration-with-dotquery","text":"dotany is used internally by dotquery for collection queries: from truth.dotquery import Query # These are equivalent: q = Query ( \"any users.role equals admin\" ) # vs from truth.dotany import any_match result = any_match ( users , \"role\" , \"admin\" )","title":"Integration with dotquery"},{"location":"tools/truth/dotany/#related-tools","text":"dotall - Universal quantifier (all items must match) dotexists - Check path existence dotquery - Complex boolean queries dotfilter - Filter collections","title":"Related Tools"},{"location":"tools/truth/dotequals/","text":"dotequals \u00b6 Check if a path has a specific value - Truth pillar's pattern layer Overview \u00b6 dotequals bridges the gap between simple existence checks ( dotexists ) and complex boolean queries ( dotquery ). It answers the question: \"Does this path exist AND have this specific value?\" Part of the Truth pillar's pattern layer, it's pedagogically positioned to introduce value checking after users master path existence. Installation \u00b6 # As part of dotsuite pip install dotsuite # Or from source cd src/truth/dotequals pip install -e . Core Functions \u00b6 equals(data, path, value) \u00b6 Check if a path exists and has a specific value. from truth.dotequals.core import equals data = { \"user\" : { \"name\" : \"Alice\" , \"role\" : \"admin\" , \"active\" : True } } # Check exact values equals ( data , \"user.name\" , \"Alice\" ) # True equals ( data , \"user.name\" , \"Bob\" ) # False equals ( data , \"user.role\" , \"admin\" ) # True equals ( data , \"user.active\" , True ) # True # Missing paths return False equals ( data , \"user.email\" , \"alice@example.com\" ) # False not_equals(data, path, value) \u00b6 Check if a path exists and does NOT have a specific value. from truth.dotequals.core import not_equals data = { \"status\" : \"active\" , \"count\" : 42 } not_equals ( data , \"status\" , \"inactive\" ) # True not_equals ( data , \"status\" , \"active\" ) # False not_equals ( data , \"count\" , 0 ) # True # Note: Missing paths return True (None != value) not_equals ( data , \"missing\" , \"anything\" ) # True not_equals ( data , \"missing\" , None ) # False equals_any(data, path, *values) \u00b6 Check if a path equals any of the provided values. from truth.dotequals.core import equals_any data = { \"user\" : { \"role\" : \"moderator\" }} # Check against multiple possibilities equals_any ( data , \"user.role\" , \"admin\" , \"moderator\" , \"superuser\" ) # True equals_any ( data , \"user.role\" , \"user\" , \"guest\" ) # False Command Line Usage \u00b6 # Basic equality check dotequals data.json user.role admin echo $? # 0 if true, 1 if false # Check if NOT equal dotequals data.json status inactive --not # Check if equals any of several values dotequals data.json user.role admin --any moderator superuser # Verbose output dotequals data.json user.active true --verbose # \u2713 Path 'user.active' equals true Exit codes: - 0 - Condition is true - 1 - Condition is false Common Use Cases \u00b6 1. Configuration Validation \u00b6 config = { \"environment\" : \"production\" , \"debug\" : False , \"database\" : { \"driver\" : \"postgresql\" , \"host\" : \"localhost\" } } # Validate critical settings if equals ( config , \"environment\" , \"production\" ): assert equals ( config , \"debug\" , False ), \"Debug must be off in production!\" assert equals_any ( config , \"database.driver\" , \"postgresql\" , \"mysql\" ) 2. User Authorization \u00b6 user = { \"id\" : 123 , \"role\" : \"admin\" , \"permissions\" : [ \"read\" , \"write\" , \"delete\" ], \"active\" : True } def can_delete ( user_data ): return ( equals ( user_data , \"active\" , True ) and equals_any ( user_data , \"role\" , \"admin\" , \"superuser\" ) ) 3. State Machine Validation \u00b6 order = { \"id\" : \"ORD-123\" , \"status\" : \"pending\" , \"payment\" : { \"status\" : \"authorized\" } } # Check if order can be shipped can_ship = ( equals ( order , \"status\" , \"pending\" ) and equals ( order , \"payment.status\" , \"authorized\" ) ) 4. Shell Script Conditions \u00b6 #!/bin/bash # Check environment before deployment if dotequals config.json environment production ; then if ! dotequals config.json debug false ; then echo \"ERROR: Debug mode is on in production!\" exit 1 fi fi # Check service status if dotequals status.json service.state running ; then echo \"Service is running\" else echo \"Service is not running\" systemctl start myservice fi Design Decisions \u00b6 Missing Paths \u00b6 When a path doesn't exist: - equals returns False (can't equal a value if it doesn't exist) - not_equals returns True (None != any non-None value) - equals_any returns False (can't match any value if it doesn't exist) This behavior is consistent with dotget returning None for missing paths. Type Sensitivity \u00b6 Comparisons are type-sensitive: data = { \"count\" : 42 } equals ( data , \"count\" , 42 ) # True equals ( data , \"count\" , \"42\" ) # False - different types Philosophy \u00b6 dotequals follows the \"steal this code\" philosophy. It's essentially: def equals ( data , path , value ): return get ( data , path ) == value But with proper handling of missing paths and consistent behavior across the ecosystem. Comparison with Other Truth Tools \u00b6 Tool Question Example dotexists Does path exist? check(data, \"user.email\") dotequals Does path have value? equals(data, \"status\", \"active\") dotany Does any item match? any_match(data, \"users.*.role\", \"admin\") dotall Do all items match? all_match(data, \"users.*.active\", True) dotquery Complex boolean logic Query(\"age > 18 and role == admin\") See Also \u00b6 dotexists - Check path existence dotquery - Complex boolean queries dotany - Existential quantifier dotall - Universal quantifier","title":"dotequals"},{"location":"tools/truth/dotequals/#dotequals","text":"Check if a path has a specific value - Truth pillar's pattern layer","title":"dotequals"},{"location":"tools/truth/dotequals/#overview","text":"dotequals bridges the gap between simple existence checks ( dotexists ) and complex boolean queries ( dotquery ). It answers the question: \"Does this path exist AND have this specific value?\" Part of the Truth pillar's pattern layer, it's pedagogically positioned to introduce value checking after users master path existence.","title":"Overview"},{"location":"tools/truth/dotequals/#installation","text":"# As part of dotsuite pip install dotsuite # Or from source cd src/truth/dotequals pip install -e .","title":"Installation"},{"location":"tools/truth/dotequals/#core-functions","text":"","title":"Core Functions"},{"location":"tools/truth/dotequals/#equalsdata-path-value","text":"Check if a path exists and has a specific value. from truth.dotequals.core import equals data = { \"user\" : { \"name\" : \"Alice\" , \"role\" : \"admin\" , \"active\" : True } } # Check exact values equals ( data , \"user.name\" , \"Alice\" ) # True equals ( data , \"user.name\" , \"Bob\" ) # False equals ( data , \"user.role\" , \"admin\" ) # True equals ( data , \"user.active\" , True ) # True # Missing paths return False equals ( data , \"user.email\" , \"alice@example.com\" ) # False","title":"equals(data, path, value)"},{"location":"tools/truth/dotequals/#not_equalsdata-path-value","text":"Check if a path exists and does NOT have a specific value. from truth.dotequals.core import not_equals data = { \"status\" : \"active\" , \"count\" : 42 } not_equals ( data , \"status\" , \"inactive\" ) # True not_equals ( data , \"status\" , \"active\" ) # False not_equals ( data , \"count\" , 0 ) # True # Note: Missing paths return True (None != value) not_equals ( data , \"missing\" , \"anything\" ) # True not_equals ( data , \"missing\" , None ) # False","title":"not_equals(data, path, value)"},{"location":"tools/truth/dotequals/#equals_anydata-path-values","text":"Check if a path equals any of the provided values. from truth.dotequals.core import equals_any data = { \"user\" : { \"role\" : \"moderator\" }} # Check against multiple possibilities equals_any ( data , \"user.role\" , \"admin\" , \"moderator\" , \"superuser\" ) # True equals_any ( data , \"user.role\" , \"user\" , \"guest\" ) # False","title":"equals_any(data, path, *values)"},{"location":"tools/truth/dotequals/#command-line-usage","text":"# Basic equality check dotequals data.json user.role admin echo $? # 0 if true, 1 if false # Check if NOT equal dotequals data.json status inactive --not # Check if equals any of several values dotequals data.json user.role admin --any moderator superuser # Verbose output dotequals data.json user.active true --verbose # \u2713 Path 'user.active' equals true Exit codes: - 0 - Condition is true - 1 - Condition is false","title":"Command Line Usage"},{"location":"tools/truth/dotequals/#common-use-cases","text":"","title":"Common Use Cases"},{"location":"tools/truth/dotequals/#1-configuration-validation","text":"config = { \"environment\" : \"production\" , \"debug\" : False , \"database\" : { \"driver\" : \"postgresql\" , \"host\" : \"localhost\" } } # Validate critical settings if equals ( config , \"environment\" , \"production\" ): assert equals ( config , \"debug\" , False ), \"Debug must be off in production!\" assert equals_any ( config , \"database.driver\" , \"postgresql\" , \"mysql\" )","title":"1. Configuration Validation"},{"location":"tools/truth/dotequals/#2-user-authorization","text":"user = { \"id\" : 123 , \"role\" : \"admin\" , \"permissions\" : [ \"read\" , \"write\" , \"delete\" ], \"active\" : True } def can_delete ( user_data ): return ( equals ( user_data , \"active\" , True ) and equals_any ( user_data , \"role\" , \"admin\" , \"superuser\" ) )","title":"2. User Authorization"},{"location":"tools/truth/dotequals/#3-state-machine-validation","text":"order = { \"id\" : \"ORD-123\" , \"status\" : \"pending\" , \"payment\" : { \"status\" : \"authorized\" } } # Check if order can be shipped can_ship = ( equals ( order , \"status\" , \"pending\" ) and equals ( order , \"payment.status\" , \"authorized\" ) )","title":"3. State Machine Validation"},{"location":"tools/truth/dotequals/#4-shell-script-conditions","text":"#!/bin/bash # Check environment before deployment if dotequals config.json environment production ; then if ! dotequals config.json debug false ; then echo \"ERROR: Debug mode is on in production!\" exit 1 fi fi # Check service status if dotequals status.json service.state running ; then echo \"Service is running\" else echo \"Service is not running\" systemctl start myservice fi","title":"4. Shell Script Conditions"},{"location":"tools/truth/dotequals/#design-decisions","text":"","title":"Design Decisions"},{"location":"tools/truth/dotequals/#missing-paths","text":"When a path doesn't exist: - equals returns False (can't equal a value if it doesn't exist) - not_equals returns True (None != any non-None value) - equals_any returns False (can't match any value if it doesn't exist) This behavior is consistent with dotget returning None for missing paths.","title":"Missing Paths"},{"location":"tools/truth/dotequals/#type-sensitivity","text":"Comparisons are type-sensitive: data = { \"count\" : 42 } equals ( data , \"count\" , 42 ) # True equals ( data , \"count\" , \"42\" ) # False - different types","title":"Type Sensitivity"},{"location":"tools/truth/dotequals/#philosophy","text":"dotequals follows the \"steal this code\" philosophy. It's essentially: def equals ( data , path , value ): return get ( data , path ) == value But with proper handling of missing paths and consistent behavior across the ecosystem.","title":"Philosophy"},{"location":"tools/truth/dotequals/#comparison-with-other-truth-tools","text":"Tool Question Example dotexists Does path exist? check(data, \"user.email\") dotequals Does path have value? equals(data, \"status\", \"active\") dotany Does any item match? any_match(data, \"users.*.role\", \"admin\") dotall Do all items match? all_match(data, \"users.*.active\", True) dotquery Complex boolean logic Query(\"age > 18 and role == admin\")","title":"Comparison with Other Truth Tools"},{"location":"tools/truth/dotequals/#see-also","text":"dotexists - Check path existence dotquery - Complex boolean queries dotany - Existential quantifier dotall - Universal quantifier","title":"See Also"},{"location":"tools/truth/dotexists/","text":"dotexists \u00b6 Check if a path exists in nested data Part of the Truth pillar, dotexists is the most fundamental boolean operation - checking whether a path exists in a data structure. Overview \u00b6 dotexists safely navigates through nested dictionaries and lists to determine if a path exists, regardless of the value at that path. Basic Usage \u00b6 from truth.dotexists import check data = { \"user\" : { \"name\" : \"Alice\" , \"email\" : \"alice@example.com\" , \"age\" : None } } # Check if paths exist check ( data , \"user.name\" ) # True check ( data , \"user.email\" ) # True check ( data , \"user.age\" ) # True (even though value is None) check ( data , \"user.phone\" ) # False Important: Existence vs Truthiness \u00b6 dotexists returns True if the path exists, even if the value is falsy: data = { \"count\" : 0 , \"active\" : False , \"name\" : \"\" , \"value\" : None , \"items\" : [] } # All these return True (paths exist) check ( data , \"count\" ) # True (even though 0 is falsy) check ( data , \"active\" ) # True (even though False) check ( data , \"name\" ) # True (even though empty string) check ( data , \"value\" ) # True (even though None) check ( data , \"items\" ) # True (even though empty list) List Access \u00b6 Works with list indices: data = { \"users\" : [ { \"name\" : \"Alice\" }, { \"name\" : \"Bob\" }, { \"name\" : \"Charlie\" } ] } check ( data , \"users.0\" ) # True check ( data , \"users.2.name\" ) # True check ( data , \"users.3\" ) # False (out of bounds) check ( data , \"users.-1\" ) # True (negative indexing) Safe Navigation Pattern \u00b6 Use dotexists for safe navigation before accessing values: from depth.dotget import get from truth.dotexists import check def safe_get ( data , path , default = None ): \"\"\"Get value if path exists, otherwise return default.\"\"\" if check ( data , path ): return get ( data , path ) return default # Usage config = { \"database\" : { \"host\" : \"localhost\" }} port = safe_get ( config , \"database.port\" , 5432 ) # Returns 5432 (default) Real-World Examples \u00b6 Optional Configuration \u00b6 config = { \"server\" : { \"host\" : \"localhost\" , \"port\" : 8080 # SSL config is optional } } # Check for optional settings if check ( config , \"server.ssl.enabled\" ): # Configure SSL pass else : # Use default (no SSL) pass Feature Detection \u00b6 user_data = { \"profile\" : { \"name\" : \"Alice\" , \"premium_features\" : { \"advanced_analytics\" : True } } } # Check if user has premium features has_premium = check ( user_data , \"profile.premium_features\" ) has_analytics = check ( user_data , \"profile.premium_features.advanced_analytics\" ) Mathematical Foundation \u00b6 dotexists implements the membership test (\u2208) for paths in nested structures: - Returns True \u27fa path \u2208 structure - Returns False \u27fa path \u2209 structure Related Tools \u00b6 dotget - Extract values from paths dotequals - Check if path has specific value dotquery - Complex boolean queries","title":"dotexists"},{"location":"tools/truth/dotexists/#dotexists","text":"Check if a path exists in nested data Part of the Truth pillar, dotexists is the most fundamental boolean operation - checking whether a path exists in a data structure.","title":"dotexists"},{"location":"tools/truth/dotexists/#overview","text":"dotexists safely navigates through nested dictionaries and lists to determine if a path exists, regardless of the value at that path.","title":"Overview"},{"location":"tools/truth/dotexists/#basic-usage","text":"from truth.dotexists import check data = { \"user\" : { \"name\" : \"Alice\" , \"email\" : \"alice@example.com\" , \"age\" : None } } # Check if paths exist check ( data , \"user.name\" ) # True check ( data , \"user.email\" ) # True check ( data , \"user.age\" ) # True (even though value is None) check ( data , \"user.phone\" ) # False","title":"Basic Usage"},{"location":"tools/truth/dotexists/#important-existence-vs-truthiness","text":"dotexists returns True if the path exists, even if the value is falsy: data = { \"count\" : 0 , \"active\" : False , \"name\" : \"\" , \"value\" : None , \"items\" : [] } # All these return True (paths exist) check ( data , \"count\" ) # True (even though 0 is falsy) check ( data , \"active\" ) # True (even though False) check ( data , \"name\" ) # True (even though empty string) check ( data , \"value\" ) # True (even though None) check ( data , \"items\" ) # True (even though empty list)","title":"Important: Existence vs Truthiness"},{"location":"tools/truth/dotexists/#list-access","text":"Works with list indices: data = { \"users\" : [ { \"name\" : \"Alice\" }, { \"name\" : \"Bob\" }, { \"name\" : \"Charlie\" } ] } check ( data , \"users.0\" ) # True check ( data , \"users.2.name\" ) # True check ( data , \"users.3\" ) # False (out of bounds) check ( data , \"users.-1\" ) # True (negative indexing)","title":"List Access"},{"location":"tools/truth/dotexists/#safe-navigation-pattern","text":"Use dotexists for safe navigation before accessing values: from depth.dotget import get from truth.dotexists import check def safe_get ( data , path , default = None ): \"\"\"Get value if path exists, otherwise return default.\"\"\" if check ( data , path ): return get ( data , path ) return default # Usage config = { \"database\" : { \"host\" : \"localhost\" }} port = safe_get ( config , \"database.port\" , 5432 ) # Returns 5432 (default)","title":"Safe Navigation Pattern"},{"location":"tools/truth/dotexists/#real-world-examples","text":"","title":"Real-World Examples"},{"location":"tools/truth/dotexists/#optional-configuration","text":"config = { \"server\" : { \"host\" : \"localhost\" , \"port\" : 8080 # SSL config is optional } } # Check for optional settings if check ( config , \"server.ssl.enabled\" ): # Configure SSL pass else : # Use default (no SSL) pass","title":"Optional Configuration"},{"location":"tools/truth/dotexists/#feature-detection","text":"user_data = { \"profile\" : { \"name\" : \"Alice\" , \"premium_features\" : { \"advanced_analytics\" : True } } } # Check if user has premium features has_premium = check ( user_data , \"profile.premium_features\" ) has_analytics = check ( user_data , \"profile.premium_features.advanced_analytics\" )","title":"Feature Detection"},{"location":"tools/truth/dotexists/#mathematical-foundation","text":"dotexists implements the membership test (\u2208) for paths in nested structures: - Returns True \u27fa path \u2208 structure - Returns False \u27fa path \u2209 structure","title":"Mathematical Foundation"},{"location":"tools/truth/dotexists/#related-tools","text":"dotget - Extract values from paths dotequals - Check if path has specific value dotquery - Complex boolean queries","title":"Related Tools"},{"location":"tools/truth/dotquery/","text":"dotquery \u00b6 Compositional logic engine for complex boolean queries Part of the Truth pillar, dotquery provides a powerful, composable system for building and evaluating complex boolean queries on nested data structures. Overview \u00b6 dotquery offers two complementary APIs: 1. Programmatic API - Build queries using Python objects 2. DSL (Domain Specific Language) - Write queries as human-readable strings DSL Syntax \u00b6 The DSL provides an intuitive way to express complex queries: from truth.dotquery import Query # Simple equality check q = Query ( \"status equals active\" ) # Comparison operators q = Query ( \"age greater 18\" ) q = Query ( \"price less 100\" ) # Boolean logic q = Query ( \"(role equals admin) and (active equals true)\" ) q = Query ( \"(status equals pending) or (status equals processing)\" ) q = Query ( \"not deleted equals true\" ) # Nested paths q = Query ( \"user.profile.age greater 21\" ) # Quantifiers for collections q = Query ( \"any items.price greater 100\" ) q = Query ( \"all users.verified equals true\" ) Supported Operators \u00b6 Comparison Operators \u00b6 equals , eq , = , == - Equality not_equals , ne , != - Inequality greater , gt , > - Greater than greater_equal , ge , >= - Greater or equal less , lt , < - Less than less_equal , le , <= - Less or equal contains , in - Contains (for lists/strings) matches , regex - Regular expression matching exists - Path exists and has truthy value Logical Operators \u00b6 and - Both conditions must be true or - At least one condition must be true not - Negates the condition Quantifiers \u00b6 any - At least one item matches (default for collections) all - All items must match (vacuous truth for empty collections) Programmatic API \u00b6 Build queries programmatically using the Q builder: from truth.dotquery import Q # Simple queries q = Q ( \"status\" ) . equals ( \"active\" ) q = Q ( \"age\" ) . greater ( 18 ) # Combine with logical operators q = Q ( \"role\" ) . equals ( \"admin\" ) & Q ( \"active\" ) . equals ( True ) q = Q ( \"status\" ) . equals ( \"pending\" ) | Q ( \"status\" ) . equals ( \"processing\" ) q = ~ Q ( \"deleted\" ) . equals ( True ) # Quantifiers q = Q ( \"scores\" ) . all () . greater ( 60 ) # All scores > 60 q = Q ( \"tags\" ) . contains ( \"python\" ) # Any tag equals \"python\" (default) Real-World Examples \u00b6 User Authorization \u00b6 # Can user perform action? can_edit = Query ( \"\"\" (role equals admin) or ((role equals editor) and (verified equals true)) \"\"\" ) user = { \"role\" : \"editor\" , \"verified\" : True } if can_edit . check ( user ): # Allow edit pass Data Validation \u00b6 # Validate configuration valid_config = Query ( \"\"\" (database.host exists) and (database.port greater 0) and (database.port less 65536) \"\"\" ) config = { \"database\" : { \"host\" : \"localhost\" , \"port\" : 5432 }} assert valid_config . check ( config ) Filtering Collections \u00b6 from collections.dotfilter import dotfilter users = [ { \"name\" : \"Alice\" , \"age\" : 30 , \"role\" : \"admin\" }, { \"name\" : \"Bob\" , \"age\" : 25 , \"role\" : \"user\" }, { \"name\" : \"Charlie\" , \"age\" : 35 , \"role\" : \"user\" } ] # Find admin users over 25 admins = dotfilter ( users , Query ( \"(role equals admin) and (age greater 25)\" )) Error Handling \u00b6 The DSL parser provides specific exception types for better error handling: from truth.dotquery.core import DSLError , DSLSyntaxError , UnknownOperatorError try : q = Query ( \"status unknownop value\" ) except UnknownOperatorError as e : print ( f \"Unknown operator: { e } \" ) except DSLSyntaxError as e : print ( f \"Syntax error: { e } \" ) except DSLError as e : print ( f \"General DSL error: { e } \" ) Mathematical Foundation \u00b6 dotquery implements a complete boolean algebra with: - Expressions : Abstract syntax trees (AST) for query composition - Operators : Closed under boolean operations - Quantifiers : Universal (\u2200) and existential (\u2203) quantification - Homomorphism : Queries lift to set operations on collections Related Tools \u00b6 dotexists - Simple path existence checking dotequals - Direct equality comparisons dotany / dotall - Collection quantifiers dotfilter - Filter collections using queries","title":"dotquery"},{"location":"tools/truth/dotquery/#dotquery","text":"Compositional logic engine for complex boolean queries Part of the Truth pillar, dotquery provides a powerful, composable system for building and evaluating complex boolean queries on nested data structures.","title":"dotquery"},{"location":"tools/truth/dotquery/#overview","text":"dotquery offers two complementary APIs: 1. Programmatic API - Build queries using Python objects 2. DSL (Domain Specific Language) - Write queries as human-readable strings","title":"Overview"},{"location":"tools/truth/dotquery/#dsl-syntax","text":"The DSL provides an intuitive way to express complex queries: from truth.dotquery import Query # Simple equality check q = Query ( \"status equals active\" ) # Comparison operators q = Query ( \"age greater 18\" ) q = Query ( \"price less 100\" ) # Boolean logic q = Query ( \"(role equals admin) and (active equals true)\" ) q = Query ( \"(status equals pending) or (status equals processing)\" ) q = Query ( \"not deleted equals true\" ) # Nested paths q = Query ( \"user.profile.age greater 21\" ) # Quantifiers for collections q = Query ( \"any items.price greater 100\" ) q = Query ( \"all users.verified equals true\" )","title":"DSL Syntax"},{"location":"tools/truth/dotquery/#supported-operators","text":"","title":"Supported Operators"},{"location":"tools/truth/dotquery/#comparison-operators","text":"equals , eq , = , == - Equality not_equals , ne , != - Inequality greater , gt , > - Greater than greater_equal , ge , >= - Greater or equal less , lt , < - Less than less_equal , le , <= - Less or equal contains , in - Contains (for lists/strings) matches , regex - Regular expression matching exists - Path exists and has truthy value","title":"Comparison Operators"},{"location":"tools/truth/dotquery/#logical-operators","text":"and - Both conditions must be true or - At least one condition must be true not - Negates the condition","title":"Logical Operators"},{"location":"tools/truth/dotquery/#quantifiers","text":"any - At least one item matches (default for collections) all - All items must match (vacuous truth for empty collections)","title":"Quantifiers"},{"location":"tools/truth/dotquery/#programmatic-api","text":"Build queries programmatically using the Q builder: from truth.dotquery import Q # Simple queries q = Q ( \"status\" ) . equals ( \"active\" ) q = Q ( \"age\" ) . greater ( 18 ) # Combine with logical operators q = Q ( \"role\" ) . equals ( \"admin\" ) & Q ( \"active\" ) . equals ( True ) q = Q ( \"status\" ) . equals ( \"pending\" ) | Q ( \"status\" ) . equals ( \"processing\" ) q = ~ Q ( \"deleted\" ) . equals ( True ) # Quantifiers q = Q ( \"scores\" ) . all () . greater ( 60 ) # All scores > 60 q = Q ( \"tags\" ) . contains ( \"python\" ) # Any tag equals \"python\" (default)","title":"Programmatic API"},{"location":"tools/truth/dotquery/#real-world-examples","text":"","title":"Real-World Examples"},{"location":"tools/truth/dotquery/#user-authorization","text":"# Can user perform action? can_edit = Query ( \"\"\" (role equals admin) or ((role equals editor) and (verified equals true)) \"\"\" ) user = { \"role\" : \"editor\" , \"verified\" : True } if can_edit . check ( user ): # Allow edit pass","title":"User Authorization"},{"location":"tools/truth/dotquery/#data-validation","text":"# Validate configuration valid_config = Query ( \"\"\" (database.host exists) and (database.port greater 0) and (database.port less 65536) \"\"\" ) config = { \"database\" : { \"host\" : \"localhost\" , \"port\" : 5432 }} assert valid_config . check ( config )","title":"Data Validation"},{"location":"tools/truth/dotquery/#filtering-collections","text":"from collections.dotfilter import dotfilter users = [ { \"name\" : \"Alice\" , \"age\" : 30 , \"role\" : \"admin\" }, { \"name\" : \"Bob\" , \"age\" : 25 , \"role\" : \"user\" }, { \"name\" : \"Charlie\" , \"age\" : 35 , \"role\" : \"user\" } ] # Find admin users over 25 admins = dotfilter ( users , Query ( \"(role equals admin) and (age greater 25)\" ))","title":"Filtering Collections"},{"location":"tools/truth/dotquery/#error-handling","text":"The DSL parser provides specific exception types for better error handling: from truth.dotquery.core import DSLError , DSLSyntaxError , UnknownOperatorError try : q = Query ( \"status unknownop value\" ) except UnknownOperatorError as e : print ( f \"Unknown operator: { e } \" ) except DSLSyntaxError as e : print ( f \"Syntax error: { e } \" ) except DSLError as e : print ( f \"General DSL error: { e } \" )","title":"Error Handling"},{"location":"tools/truth/dotquery/#mathematical-foundation","text":"dotquery implements a complete boolean algebra with: - Expressions : Abstract syntax trees (AST) for query composition - Operators : Closed under boolean operations - Quantifiers : Universal (\u2200) and existential (\u2203) quantification - Homomorphism : Queries lift to set operations on collections","title":"Mathematical Foundation"},{"location":"tools/truth/dotquery/#related-tools","text":"dotexists - Simple path existence checking dotequals - Direct equality comparisons dotany / dotall - Collection quantifiers dotfilter - Filter collections using queries","title":"Related Tools"}]}